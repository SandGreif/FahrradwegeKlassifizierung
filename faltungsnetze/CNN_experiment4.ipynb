{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faltungsnetz Versuch 4: Unterschiedliche Strecken\n",
    "\n",
    "## Einleitung\n",
    "\n",
    "In diesen Versuch werden Faltungsnetze mit den Daten aus dem Datensatz 37 bis 42 trainiert. Die Daten wurden auf unterschiedlichen Routen erfasst. Beim Start und Ende der Datenerfassung zu einer Strecke überschneiden sich einige befahrene Wege. Diese Wege wurden also mehr als einmal befahren. Gelabelt wurden die Daten mit Fuzzy-Logik (siehe Notebook daten_labeln/fuzzyLogic.ipynb). \n",
    "\n",
    "## Versuchbeschreibung \n",
    "\n",
    "Zum Trainieren des Netzes ist es nötig das nur ein Teil der Bilder in den Hauptspeicher geladen wird, weil ansonsten der Speicherplatz nicht ausreicht bei 8GB RAM. Dafür wird die Keras Methode fit_generator() genutzt mit welchem eine Generator Methode Implementiert werden kann, welche so viele Bilder in der Anzahl der batch size (Stapelgröße) läd für einen Trainingsschritt. Die Daten sind so aufgeteilt und gemischt, dass 10% der Gesamtdaten zum Testen genutzt werden und die übrigen 90% werden aufgeteilt in 80% Trainingsdaten sowie 20% Validierungsdaten. Die Validierungsdaten werden als Performance Metrik genutzt am Ende des Trainings einer Epoche. Mit den Testdaten wird dann nochmals unabhängig von den Validierungsdaten das Faltungsnetz getestet.  \n",
    "\n",
    "### Versuch 4.1 Versuchsbeschreibung: Unterteilung der Fahrqualität in 4 Klassen\n",
    "\n",
    "Die Trainingsdaten wurden klassifiziert in 4 Klassen nach der Fahrqualität. Für weitere Informationen zur Einordnung der Daten siehe Fuzzy Logik Versuch 2. Als Parameter für das Faltungsnetz wird als Vorlage das Model aus Faltungsnetz Versuch 1.9 genutzt. Die Anzahl der Epochen beträgt 20. Wenn sich nach Validierung Accuracy nach 3 Epochen nicht mehr erhöht wird das Training abgebrochen. \n",
    "\n",
    "### Versuch 4.1 Ergebnis:\n",
    "\n",
    "Wie in Tab. 1 zu sehen war der Versuch nicht sehr erfolgreich. Auf Abb. 1 rechte Seite ist zu sehen das die Trainings und Validierung Accuracy mit $\\approx 0.33$ bzw. $\\approx 33%$ nicht sehr hoch ist. Das Faltungsnetz könnte nicht komplex genug sein oder die Trainingsdaten sind nicht aussagekräftig genug.\n",
    "\n",
    "| | \n",
    " --- | --- |\n",
    " <img src=\"../daten/abbildungen/trainingshistorieLossVersuch4_1.png\" alt\"Loss Trainingshistorie Versuch 4.1\" /> | <img src=\"../daten/abbildungen/trainingshistorieAccuracyVersuch4_1.png\" alt\"Accuracy Trainingshistorie Versuch 4.1\" />\n",
    "Abbildung 1:  Trainingshistorie Versuch 4.1\n",
    "\n",
    "### Versuch 4.2 Versuchbeschreibung: Gleiche Anzahl an Trainingsdaten für jede Klasse\n",
    "\n",
    "Es gibt eine unterschiedliche Anzahl an Repräsentanten für jede Klasse siehe Abb. 2. In diesen Versuch soll untersucht werden ob eine Verbesserung der Accuracy erzielt werden kann, wenn die Anzahl der Daten pro Klasse normiert werden. Für das Faltungsnetz werden die Parameter aus Versuch 4.1 genutzt.\n",
    "\n",
    "<img src=\"../daten/abbildungen/histogrammKlassenVersuch4_2.png\" alt=\"Histogramm Klassen Versuch 4.2\" />\n",
    "Abbildung 2: Histogramm der Klassen\n",
    "\n",
    "### Versuch 4.2 Ergebnis:\n",
    "\n",
    "Auf Tab. 1 ist das relativ schlechte Ergebnis zu sehen von $\\approx 25%$ Accuracy. Ein Blick auf die Konfusionsmatrix aus Versuch 4.1 und 4.2 verrät, dass die Modelle vor allem die Klasse \"sehr gut\" voraussagen. Dies ist so zu interpretieren, dass das Faltungsnetz nicht geeignet ist für diese Aufgabe. Mit der Normierten Anzahl der Daten pro Klasse wurden auch andere Klassen vorrausgesagt. \n",
    "\n",
    "| | \n",
    " --- | --- |\n",
    " <img src=\"../daten/abbildungen/konfmatrixVersuch4_1.png\" alt\"Konfusionsmatrix aus Versuch 4.1\" /> | <img src=\"../daten/abbildungen/konfmatrixVersuch4_2.png\" alt\"Konfusionsmatrix aus Versuch 4.2\" />\n",
    "Abbildung 3: Konfusionsmatrix Versuch 4.1 und 4.2\n",
    "\n",
    "### Versuch 4.3 Versuchbeschreibung:  Hypertuning\n",
    "\n",
    "In diesem Versuch wurden die Daten wie in Versuch 4.2 beschrieben normiert damit die Anzahl an Daten pro Klasse gleich ist. \n",
    "Ziel ist es mit Hypertuning die Parameter des Faltungsnetzes zu optimieren. Dabei wird die Dropout Rate, die Anzahl der Faltungsschichten von 2 bis 4 und die Optimierungsfunktion sowie weitere Parameter mit Hyperopt gesucht. Die Anzahl an Durchläufen mit Hyperopt sind 100-mal. Mit jeweils 10 möglichen Epochen und Early Stopping.\n",
    "\n",
    "### Versuch 4.3 Ergebnis: \n",
    "\n",
    "Nach 67 Durchläufen mit Hyperopt kam es zu folgenden out of memory (OOM) Speicherfehler. \n",
    "\n",
    "         OOM when allocating tensor with shape[32,64,184,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
    "         \n",
    "Die Ausführungszeit dauerte 11 Stunden und 53 Minuten. Durch den OOM Fehler ist es nicht möglich gewesen die besten gefundenen Parameter vollständig auszuwerten. Die beste erreichte validierungs Accuracy ist $0.4257$ (Trainings Accuracy gleich $0.396$). Mit 3 Faltungsschichten, ELU als Aktivierungsfunktionn und Adam als Optimierungsfunktion. Für die nächsten Versuche werden immer alle Parameter auf der Konsole ausgegeben.       \n",
    " \n",
    "\n",
    "### Ergebnisse\n",
    "\n",
    "Versuch Nr. | Trainings Accuracy | Trainings Loss | Validierungs Accuracy | Validierungs Loss | Test Accuracy | Test Loss |\n",
    "--- | --- | --- | --- | --- |\n",
    "4.1 | 0.3303 | 1.3376 | 0.3306 | 1.339 | 0.3321 | 1.3378 |\n",
    "4.2 | 0.2492 | 1.3933 | 0.2492 | 1.3889 | 0.2464 | 1.3886 | \n",
    "Tabelle 1: Ergebnisse der Versuche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T09:11:40.071667Z",
     "start_time": "2018-06-26T09:11:40.055670Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, rand\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import uniform, choice\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T09:11:43.637540Z",
     "start_time": "2018-06-26T09:11:43.630505Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n",
    "import keras.callbacks as cb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T16:19:10.651464Z",
     "start_time": "2018-06-25T16:19:08.593003Z"
    }
   },
   "outputs": [],
   "source": [
    "featuresDf = pandas.read_csv(filepath_or_buffer=\"../daten/merkmale_datensatz_37_bis_42/merkmaleMitLabeln.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T16:19:14.337555Z",
     "start_time": "2018-06-25T16:19:14.333557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nummer des aktuellen Versuchs\n",
    "experimentNumber = \"3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:34:16.585897Z",
     "start_time": "2018-06-25T15:34:16.577901Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hier können die Datensätze ausgewählt werden\n",
    "datasets = ['37','38','39','40','41','42']\n",
    "# Die Pfade zu den Ordnern in welchem sich die Bilder befinden\n",
    "paths = []\n",
    "# Liste mit Pfaden zu den Bildern\n",
    "imagePaths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:34:21.774932Z",
     "start_time": "2018-06-25T15:34:21.494372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/morro/Documents/datenRoh/37/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "Ordner der geladen wird: 11\n",
      "Ordner der geladen wird: 12\n",
      "Ordner der geladen wird: 13\n",
      "Ordner der geladen wird: 14\n",
      "C:/Users/morro/Documents/datenRoh/38/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "Ordner der geladen wird: 11\n",
      "Ordner der geladen wird: 12\n",
      "Ordner der geladen wird: 13\n",
      "Ordner der geladen wird: 14\n",
      "Ordner der geladen wird: 15\n",
      "Ordner der geladen wird: 16\n",
      "Ordner der geladen wird: 17\n",
      "Ordner der geladen wird: 18\n",
      "Ordner der geladen wird: 19\n",
      "Ordner der geladen wird: 20\n",
      "Ordner der geladen wird: 21\n",
      "Ordner der geladen wird: 22\n",
      "C:/Users/morro/Documents/datenRoh/39/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "C:/Users/morro/Documents/datenRoh/40/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "C:/Users/morro/Documents/datenRoh/41/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "C:/Users/morro/Documents/datenRoh/42/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets: # Für jeden Datensatz merke Pfad\n",
    "    paths.append(\"C:/Users/morro/Documents/datenRoh/\" + dataset + \"/zugeschnitten/\")\n",
    "for path in paths: # Für jeden Pfad hole die Namen der Ordner\n",
    "    folders = os.listdir(path)\n",
    "    folders = sorted(folders, key=int) #sortiert die Reihenfolge de Ordner aufsteifend\n",
    "    print(path)\n",
    "    print(\"Bilder aus folgenden Ordnern werden geladen: \" + str(folders))\n",
    "    for folder in folders: # Aus der Liste der Ordner wird ein Ordner ausgewählt\n",
    "        filesPath = path + folder + \"/\"\n",
    "        files = os.listdir(filesPath)\n",
    "        print(\"Ordner der geladen wird: \" + str(folder))\n",
    "        for name in files: # Ein Dateiname aus diesem Ordner\n",
    "            if \"jpg\" not in name:\n",
    "                continue\n",
    "            imagePaths.append(filesPath + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:34:26.842526Z",
     "start_time": "2018-06-25T15:34:26.815834Z"
    }
   },
   "outputs": [],
   "source": [
    "numberOfChannels  = 3           # Anzahl der Farbkanäle\n",
    "numberOfClasses   = 4           # Anzahl der Klassen\n",
    "classNames = ['sehr gut','gut','schlecht','sehr schlecht'] # Namen der Klassen\n",
    "yLabels           = np.array(0) # Labels / Klassen zuordnung\n",
    "yShuffle          = np.array(0) # Labels mit der Methode shuffle() vermischt \n",
    "xShuffle          = np.array(0) # Bilder zum trainieren mit shuffle() vermischt\n",
    "xTrain            = np.array(0) # Trainingsdaten (Bilder) \n",
    "xTest             = np.array(0) # Testdaten (Bilder)\n",
    "yTrain            = np.array(0) # Klassen zuordnungen (Labels) für xTrain\n",
    "yTest             = np.array(0) # Klassen zuordnung (Lables) für xTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:34:31.812328Z",
     "start_time": "2018-06-25T15:34:31.803976Z"
    }
   },
   "outputs": [],
   "source": [
    "yLabels = np_utils.to_categorical(featuresDf['Klasse'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:34:36.549626Z",
     "start_time": "2018-06-25T15:34:36.545627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setzten des RandomState um reproduzierbare Ergebnisse zu erzielen.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:36:53.112173Z",
     "start_time": "2018-06-25T15:36:53.088023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mischen der Trainingsdaten\n",
    "xShuffle, yShuffle = shuffle(imagePaths,yLabels)\n",
    "# Aufteilung in Trainings und Testdaten\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(xShuffle, yShuffle, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:36:58.026834Z",
     "start_time": "2018-06-25T15:36:57.995771Z"
    }
   },
   "outputs": [],
   "source": [
    "xTrain, xVal, yTain, yVal = train_test_split(xTrain, yTrain, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:37:03.357672Z",
     "start_time": "2018-06-25T15:37:03.349676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Diese Funktion läd Bilder in den Hauptspeicher\n",
    "# imagesPaths: Liste mit Pfaden zu den Bildern != null\n",
    "def imageLoader(imagePaths):\n",
    "    images = []\n",
    "    for path in imagePaths:\n",
    "        images.append(cv2.imread(path))\n",
    "    imagesNp = np.array(images)\n",
    "    imagesNp = imagesNp.astype('float32')\n",
    "    # Transfomierung der Bildpunkte auf den Wetebereich von 0 bis 1\n",
    "    imagesNp /= 255\n",
    "    return imagesNp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:37:08.283452Z",
     "start_time": "2018-06-25T15:37:08.276065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Läd Trainingsdaten in batches\n",
    "def dataLoader(imagePaths, features, batchSize):\n",
    "    imagesCount= len(imagePaths)  \n",
    "    while True:\n",
    "        batchStart = 0\n",
    "        batchEnd = batchSize\n",
    "        while batchStart < imagesCount:\n",
    "            limit = min(batchEnd, imagesCount)\n",
    "            x = imageLoader(imagePaths[batchStart:limit])\n",
    "            y = features[batchStart:limit]\n",
    "            yield (x,y) \n",
    "            batchStart += batchSize   \n",
    "            batchEnd += batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:37:13.005951Z",
     "start_time": "2018-06-25T15:37:12.997954Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter für das CNN\n",
    "inputShape     = (368, 70, 3)   # Eingangs Array-Form \n",
    "numNeuronsC1   = 32                # Anzahl der Filter / 1 Faltungsschicht\n",
    "numNeuronsC2   = 32                # Anzahl der Filter / 2 Faltungsschicht\n",
    "numNeuronsC3   = 64                # Anzahl der Filter / 3 Faltungsschicht\n",
    "numNeuronsD1   = 64                # Anzahl der Neuronen des Fully connected layer - vollverbundene Schicht\n",
    "poolSize       = 2                 # Größe der Pooling-Layer\n",
    "convKernelSize = 3                 # Größe des Faltungskern n*n\n",
    "batchSize      = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:01:32.855936Z",
     "start_time": "2018-06-25T10:01:32.535494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Modell Historie Loss und Accuracy\n",
    "plt.figure(1)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Trainingshistorie: Loss')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.xlim(0,3)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"trainingshistorieLossVersuch4_\" + experimentNumber + \".png\")\n",
    "plt.xticks(np.arange(0, 3.1, step=1))\n",
    "plt.figure(2)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Trainingshistorie: Accuracy')\n",
    "plt.xticks()\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.legend(['Training', 'Validation'], loc='right')\n",
    "plt.xlim(0,3)\n",
    "plt.xticks(np.arange(0, 3.1, step=1))\n",
    "plt.grid(True)\n",
    "plt.savefig(\"trainingshistorieAccuracyVersuch4_\" + experimentNumber + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:05:00.790815Z",
     "start_time": "2018-06-25T15:05:00.786816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Läd Testdaten\n",
    "def testDataLoader(imagePaths, batchSize):\n",
    "    imagesCount= len(imagePaths)  \n",
    "    while True:\n",
    "        batchStart = 0\n",
    "        batchEnd = batchSize\n",
    "        while batchStart < imagesCount:\n",
    "            limit = min(batchEnd, imagesCount)\n",
    "            x = imageLoader(imagePaths[batchStart:limit])\n",
    "            yield (x) \n",
    "            batchStart += batchSize   \n",
    "            batchEnd += batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:37:20.316966Z",
     "start_time": "2018-06-25T15:37:18.487161Z"
    }
   },
   "outputs": [],
   "source": [
    "# Läd Modell\n",
    "modell1 = load_model('ergebnisse_versuch4/modell_versuch4_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:37:33.420559Z",
     "start_time": "2018-06-25T15:37:25.671099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3886494045540438, 0.2464247881355932]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modell1.evaluate_generator( dataLoader(xTest, yTest, 32), steps=int(len(xTest)/32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:38:03.121037Z",
     "start_time": "2018-06-25T15:37:38.151570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bei der Verwendung von predict_generator werden die daten gemischt \n",
    "validPreds = []\n",
    "imageList = []\n",
    "for path in xTest:\n",
    "    imageList = []   \n",
    "    img = cv2.imread(path)\n",
    "    img = np.array(img)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255\n",
    "    imageList.append(img)\n",
    "    validPreds.append(modell1.predict(np.asarray(imageList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:38:06.651456Z",
     "start_time": "2018-06-25T15:38:06.440103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1786    0    0   78]\n",
      " [1841    1    0   60]\n",
      " [1864    0    0   66]\n",
      " [1795    0    1   78]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Konfusionsmatrix\n",
    "validPredArray = np.argmax(np.vstack(validPreds), axis=1)\n",
    "yTestMax = np.argmax(yTest,axis=1)\n",
    "cnfMatrix = confusion_matrix(yTestMax, validPredArray)\n",
    "print(cnfMatrix)\n",
    "fig, ax = plt.subplots(figsize=(6,6)) \n",
    "ax = sns.heatmap(cnfMatrix, fmt=\"d\", cmap=plt.cm.Blues, ax=ax , annot=True)\n",
    "ax.set_xticklabels(classNames)\n",
    "ax.set_yticklabels(classNames)\n",
    "plt.title('Konfusionsmatrix Versuch 4.2')\n",
    "plt.ylabel('Wahre Klasse')\n",
    "plt.xlabel('Vorhergesagte Klasse')\n",
    "plt.savefig('konfmatrixVersuch4_' +  experimentNumber + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:34:33.941772Z",
     "start_time": "2018-06-25T10:34:33.930795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38644\n",
       "1    37656\n",
       "2    20566\n",
       "3    18924\n",
       "Name: Klasse, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDf[\"Klasse\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T10:49:32.670532Z",
     "start_time": "2018-06-25T10:49:32.528735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xticks(np.arange(0, 3.1, step=1))\n",
    "plt.xlim(0,4)\n",
    "plt.xlabel(\"Klasse\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.title(\"Histogramm der Klassen\")\n",
    "featuresDf[\"Klasse\"].hist(bins=[0,1,2,3,4])\n",
    "plt.savefig(\"histogrammKlassenVersuch4_2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T15:34:46.927336Z",
     "start_time": "2018-06-25T15:34:46.469018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Die Zelle Normiert die Anzahl der Repräsentanten pro Klasse\n",
    "class1Number = 0\n",
    "class2Number = 0 \n",
    "class3Number = 0\n",
    "class4Number = 0\n",
    "maxClasses = featuresDf[\"Klasse\"].value_counts().min()\n",
    "indexToDelete = [] \n",
    "i = -1\n",
    "for label in yShuffle:\n",
    "    i = i + 1\n",
    "    labelNumber = np.argmax(label,axis=0)\n",
    "    if labelNumber == 0 and class1Number < maxClasses:\n",
    "        class1Number = class1Number + 1\n",
    "        continue\n",
    "    elif labelNumber == 0:\n",
    "        indexToDelete.append(i)\n",
    "    if labelNumber == 1 and class2Number < maxClasses:\n",
    "        class2Number = class2Number + 1\n",
    "        continue\n",
    "    elif labelNumber == 1:\n",
    "        indexToDelete.append(i)\n",
    "    if labelNumber == 2 and class3Number < maxClasses:\n",
    "        class3Number = class3Number + 1\n",
    "        continue\n",
    "    elif labelNumber == 2:\n",
    "        indexToDelete.append(i)\n",
    "    if labelNumber == 3 and class4Number < maxClasses:\n",
    "        class4Number = class4Number + 1\n",
    "        continue        \n",
    "    elif labelNumber == 3:\n",
    "        indexToDelete.append(i)\n",
    "xShuffle = [i for j, i in enumerate(xShuffle) if j not in indexToDelete]\n",
    "yShuffle = [i for j, i in enumerate(yShuffle) if j not in indexToDelete]\n",
    "yShuffle = np.asarray(yShuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T16:21:11.120000Z",
     "start_time": "2018-06-25T16:21:11.089340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Eine Funktion die das zu optimierende Keras-Modell beschreibt\n",
    "# Die vorgehensweise mit einer Funktion ist nach der Dokumentation von Hyperas vorgegeben \n",
    "# siehe https://github.com/maxpumperla/hyperas\n",
    "def model(xTrain, xVal, yTrain, yVal):\n",
    "    # Parameter für das CNN\n",
    "    inputShape     = (368, 70, 3)   # Eingangs Array-Form \n",
    "    numNeuronsC1   = 32                # Anzahl der Filter / 1 Faltungsschicht\n",
    "    numNeuronsC2   = 32                # Anzahl der Filter / 2 Faltungsschicht\n",
    "    numNeuronsC3   = 64                # Anzahl der Filter / 3 Faltungsschicht\n",
    "    numNeuronsD1   = 64                # Anzahl der Neuronen des Fully connected layer - vollverbundene Schicht\n",
    "    poolSize       = 2                 # Größe der Pooling-Layer\n",
    "    convKernelSize = 3                 # Größe des Faltungskern n*n\n",
    "    batchSize      = 32\n",
    "    \n",
    "    model = Sequential()\n",
    "    layerCountTuning = {{choice(['2Layer', '3Layer','4Layer'])}}\n",
    "    print(\"Anzahl der Faltungsschichten: \" + layerCountTuning)\n",
    "    af = {{choice(['relu', 'elu'])}}\n",
    "    print(\"Aktivierungsfunktion: \" + af)\n",
    "    optf = {{choice(['RMSprop','Adam'])}}\n",
    "    print(\"Optimierungsfunktion: \" + optf)\n",
    "    model.add(Conv2D(numNeuronsC1, (convKernelSize, convKernelSize), padding='same', input_shape=inputShape))\n",
    "    model.add(Activation(af))\n",
    "    model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "    dropoutrate1 = {{uniform(0, 1)}}\n",
    "    print(\"Dropout-Rate Faltungsschicht 1: \" + str(dropoutrate1))\n",
    "    model.add(Dropout(dropoutrate1))\n",
    "    \n",
    "    if layerCountTuning == '2Layer' or '3Layer' or '4Layer':\n",
    "        filterCount2 = {{choice([32, 64])}}\n",
    "        print(\"Anzahl der Filter-Maps: \" + str(filterCount2))\n",
    "        model.add(Conv2D(filterCount2, (convKernelSize, convKernelSize), padding='same'))\n",
    "        model.add(Activation(af))\n",
    "        model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "        dropoutrate2 = {{uniform(0, 1)}}        \n",
    "        print(\"Dropout-Rate Faltungsschicht 2: \" + str(dropoutrate2))\n",
    "        model.add(Dropout(dropoutrate2))\n",
    "    \n",
    "    if layerCountTuning == '3Layer' or '4Layer':\n",
    "        filterCount3 = {{choice([64, 128])}}\n",
    "        print(\"Anzahl der Filter-Maps: \" + str(filterCount3))\n",
    "        model.add(Conv2D(filterCount3, (convKernelSize, convKernelSize), padding='same'))\n",
    "        model.add(Activation(af))\n",
    "        model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "        dropoutrate3 = {{uniform(0, 1)}}        \n",
    "        print(\"Dropout-Rate Faltungsschicht 3: \" + str(dropoutrate3))\n",
    "        model.add(Dropout(dropoutrate3))\n",
    "\n",
    "    if layerCountTuning == '4Layer':\n",
    "        filterCount4 = {{choice([128, 256])}}\n",
    "        print(\"Anzahl der Filter-Maps: \" + str(filterCount4))\n",
    "        model.add(Conv2D(filterCount4, (convKernelSize, convKernelSize), padding='same'))\n",
    "        model.add(Activation(af))\n",
    "        model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "        dropoutrate4 = {{uniform(0, 1)}}        \n",
    "        print(\"Dropout-Rate Faltungsschicht 4: \" + str(dropoutrate4))\n",
    "        model.add(Dropout(dropoutrate4)) \n",
    "\n",
    "    model.add(Flatten())\n",
    "    dims4 = {{choice([64, 128, 256])}}\n",
    "    model.add(Dense(dims4))\n",
    "    model.add(Activation(af))\n",
    "    dropoutFull = {{uniform(0, 1)}}  \n",
    "    print(\"Dropout-Rate Fully Connected Layer: \" + str(dropoutFull))\n",
    "    model.add(Dropout(dropoutFull)) \n",
    "\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # Diese Funktion läd Bilder in den Hauptspeicher\n",
    "    # imagesPaths: Liste mit Pfaden zu den Bildern != null\n",
    "    def imageLoader(imagePaths):\n",
    "        images = []\n",
    "        for path in imagePaths:\n",
    "            images.append(cv2.imread(path))\n",
    "        \n",
    "        imagesNp = np.array(images)\n",
    "        imagesNp = imagesNp.astype('float32')\n",
    "        imagesNp /= 255\n",
    "        return imagesNp\n",
    "\n",
    "    # Läd Trainingsdaten in batches\n",
    "    def dataLoader(imagePaths, features, batchSize):\n",
    "        imagesCount= len(imagePaths)  \n",
    "        while True:\n",
    "            batchStart = 0\n",
    "            batchEnd = batchSize\n",
    "            while batchStart < imagesCount:\n",
    "                limit = min(batchEnd, imagesCount)\n",
    "                x = imageLoader(imagePaths[batchStart:limit])\n",
    "                y = features[batchStart:limit]\n",
    "                yield (x,y) \n",
    "                batchStart += batchSize   \n",
    "                batchEnd += batchSize\n",
    "                \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optf, metrics=[\"accuracy\"])\n",
    "    print('Train...')\n",
    "    # Early Stopping unterbricht das Training, wenn nach 3 Epochen die Kostenfunktion nicht weiter minimiert werden konnte \n",
    "    earlyStopping = cb.EarlyStopping(monitor='val_acc', patience=3, verbose=1, mode='max')\n",
    "    checkpointSafe = cb.ModelCheckpoint('ergebnisse_versuch4/modell_versuch4_3', monitor='val_acc', save_best_only=True)   \n",
    "    model.fit_generator(dataLoader(xTrain, yTrain, batchSize), epochs=10, steps_per_epoch=(int(len(xTrain)/batchSize)),\n",
    "              validation_data=dataLoader(xVal, yVal, batchSize), validation_steps=(int(len(xVal)/batchSize)), callbacks=[earlyStopping,checkpointSafe])\n",
    "    score, acc = model.evaluate_generator( dataLoader(xVal, yVal, batchSize), steps=(int(len(xVal)/batchSize)))\n",
    "    print('Test score: ' + str(score))\n",
    "    print('Test accuracy: ' +  str(acc))\n",
    "    # Die Rückgabewerte werden verarbeitet von Hyperas\n",
    "    # loss ist die Kostenfunktion welche minimiert werden soll mit Hyperas\n",
    "    # status (STATUS_OK) gibt an das, dass Modell erfolgreich ausgeführt wurde\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-25T16:21:52.284211Z",
     "start_time": "2018-06-25T16:21:52.272216Z"
    }
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    # Hier können die Datensätze ausgewählt werden\n",
    "    datasets = ['37','38','39','40','41','42']\n",
    "    # Die Pfade zu den Ordnern in welchem sich die Bilder befinden\n",
    "    paths = []\n",
    "    # Liste mit Pfaden zu den Bildern\n",
    "    imagePaths = []\n",
    "    for dataset in datasets: # Für jeden Datensatz merke Pfad\n",
    "        paths.append(\"C:/Users/morro/Documents/datenRoh/\" + dataset + \"/zugeschnitten/\")\n",
    "    for path in paths: # Für jeden Pfad hole die Namen der Ordner\n",
    "        folders = os.listdir(path)\n",
    "        folders = sorted(folders, key=int) #sortiert die Reihenfolge de Ordner aufsteifend\n",
    "        print(path)\n",
    "        print(\"Bilder aus folgenden Ordnern werden geladen: \" + str(folders))\n",
    "        for folder in folders: # Aus der Liste der Ordner wird ein Ordner ausgewählt\n",
    "            filesPath = path + folder + \"/\"\n",
    "            files = os.listdir(filesPath)\n",
    "            print(\"Ordner der geladen wird: \" + str(folder))\n",
    "            for name in files: # Ein Dateiname aus diesem Ordner\n",
    "                if \"jpg\" not in name:\n",
    "                    continue\n",
    "                imagePaths.append(filesPath + name)\n",
    "    # Y Klassen Labels zuweisen\n",
    "    featuresDf = pandas.read_csv(filepath_or_buffer=\"../daten/merkmale_datensatz_37_bis_42/merkmaleMitLabeln.csv\")\n",
    "    yLabels = np_utils.to_categorical(featuresDf['Klasse'], 0)\n",
    "    # Setzten des RandomState um reproduzierbare Ergebnisse zu erzielen.\n",
    "    np.random.seed(42)\n",
    "    # Mischen der Trainingsdaten\n",
    "    xShuffle, yShuffle = shuffle(imagePaths,yLabels)\n",
    "    # Normierung Anzahl der Daten pro Klasse\n",
    "    class1Number = 0\n",
    "    class2Number = 0 \n",
    "    class3Number = 0\n",
    "    class4Number = 0\n",
    "    maxClasses = featuresDf[\"Klasse\"].value_counts().min()\n",
    "    indexToDelete = [] \n",
    "    i = -1\n",
    "    for label in yShuffle:\n",
    "        i = i + 1\n",
    "        labelNumber = np.argmax(label,axis=0)\n",
    "        if labelNumber == 0 and class1Number < maxClasses:\n",
    "            class1Number = class1Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 0:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 1 and class2Number < maxClasses:\n",
    "            class2Number = class2Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 1:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 2 and class3Number < maxClasses:\n",
    "            class3Number = class3Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 2:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 3 and class4Number < maxClasses:\n",
    "            class4Number = class4Number + 1\n",
    "            continue        \n",
    "        elif labelNumber == 3:\n",
    "            indexToDelete.append(i)\n",
    "    xShuffle = [i for j, i in enumerate(xShuffle) if j not in indexToDelete]\n",
    "    yShuffle = [i for j, i in enumerate(yShuffle) if j not in indexToDelete]\n",
    "    yShuffle = np.asarray(yShuffle)\n",
    "    # Aufteilung in Trainings und Testdaten\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(xShuffle, yShuffle, test_size=0.1)\n",
    "    xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.2)\n",
    "    return xTrain, xVal, yTrain, yVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T04:15:14.780479Z",
     "start_time": "2018-06-25T16:21:55.721727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, rand\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform, choice\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.lines as mlines\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import cv2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras.callbacks as cb\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.utils import shuffle\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import accuracy_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'layerCountTuning': hp.choice('layerCountTuning', ['2Layer', '3Layer','4Layer']),\n",
      "        'af': hp.choice('af', ['relu', 'elu']),\n",
      "        'optf': hp.choice('optf', ['RMSprop','Adam']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'filterCount2': hp.choice('filterCount2', [32, 64]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'filterCount3': hp.choice('filterCount3', [64, 128]),\n",
      "        'Dropout_2': hp.uniform('Dropout_2', 0, 1),\n",
      "        'filterCount4': hp.choice('filterCount4', [128, 256]),\n",
      "        'Dropout_3': hp.uniform('Dropout_3', 0, 1),\n",
      "        'dims4': hp.choice('dims4', [64, 128, 256]),\n",
      "        'Dropout_4': hp.uniform('Dropout_4', 0, 1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: # Hier können die Datensätze ausgewählt werden\n",
      "   3: datasets = ['37','38','39','40','41','42']\n",
      "   4: # Die Pfade zu den Ordnern in welchem sich die Bilder befinden\n",
      "   5: paths = []\n",
      "   6: # Liste mit Pfaden zu den Bildern\n",
      "   7: imagePaths = []\n",
      "   8: for dataset in datasets: # Für jeden Datensatz merke Pfad\n",
      "   9:     paths.append(\"C:/Users/morro/Documents/datenRoh/\" + dataset + \"/zugeschnitten/\")\n",
      "  10: for path in paths: # Für jeden Pfad hole die Namen der Ordner\n",
      "  11:     folders = os.listdir(path)\n",
      "  12:     folders = sorted(folders, key=int) #sortiert die Reihenfolge de Ordner aufsteifend\n",
      "  13:     print(path)\n",
      "  14:     print(\"Bilder aus folgenden Ordnern werden geladen: \" + str(folders))\n",
      "  15:     for folder in folders: # Aus der Liste der Ordner wird ein Ordner ausgewählt\n",
      "  16:         filesPath = path + folder + \"/\"\n",
      "  17:         files = os.listdir(filesPath)\n",
      "  18:         print(\"Ordner der geladen wird: \" + str(folder))\n",
      "  19:         for name in files: # Ein Dateiname aus diesem Ordner\n",
      "  20:             if \"jpg\" not in name:\n",
      "  21:                 continue\n",
      "  22:             imagePaths.append(filesPath + name)\n",
      "  23: # Y Klassen Labels zuweisen\n",
      "  24: featuresDf = pandas.read_csv(filepath_or_buffer=\"../daten/merkmale_datensatz_37_bis_42/merkmaleMitLabeln.csv\")\n",
      "  25: yLabels = np_utils.to_categorical(featuresDf['Klasse'], 0)\n",
      "  26: # Setzten des RandomState um reproduzierbare Ergebnisse zu erzielen.\n",
      "  27: np.random.seed(42)\n",
      "  28: # Mischen der Trainingsdaten\n",
      "  29: xShuffle, yShuffle = shuffle(imagePaths,yLabels)\n",
      "  30: # Normierung Anzahl der Daten pro Klasse\n",
      "  31: class1Number = 0\n",
      "  32: class2Number = 0 \n",
      "  33: class3Number = 0\n",
      "  34: class4Number = 0\n",
      "  35: maxClasses = featuresDf[\"Klasse\"].value_counts().min()\n",
      "  36: indexToDelete = [] \n",
      "  37: i = -1\n",
      "  38: for label in yShuffle:\n",
      "  39:     i = i + 1\n",
      "  40:     labelNumber = np.argmax(label,axis=0)\n",
      "  41:     if labelNumber == 0 and class1Number < maxClasses:\n",
      "  42:         class1Number = class1Number + 1\n",
      "  43:         continue\n",
      "  44:     elif labelNumber == 0:\n",
      "  45:         indexToDelete.append(i)\n",
      "  46:     if labelNumber == 1 and class2Number < maxClasses:\n",
      "  47:         class2Number = class2Number + 1\n",
      "  48:         continue\n",
      "  49:     elif labelNumber == 1:\n",
      "  50:         indexToDelete.append(i)\n",
      "  51:     if labelNumber == 2 and class3Number < maxClasses:\n",
      "  52:         class3Number = class3Number + 1\n",
      "  53:         continue\n",
      "  54:     elif labelNumber == 2:\n",
      "  55:         indexToDelete.append(i)\n",
      "  56:     if labelNumber == 3 and class4Number < maxClasses:\n",
      "  57:         class4Number = class4Number + 1\n",
      "  58:         continue        \n",
      "  59:     elif labelNumber == 3:\n",
      "  60:         indexToDelete.append(i)\n",
      "  61: xShuffle = [i for j, i in enumerate(xShuffle) if j not in indexToDelete]\n",
      "  62: yShuffle = [i for j, i in enumerate(yShuffle) if j not in indexToDelete]\n",
      "  63: yShuffle = np.asarray(yShuffle)\n",
      "  64: # Aufteilung in Trainings und Testdaten\n",
      "  65: xTrain, xTest, yTrain, yTest = train_test_split(xShuffle, yShuffle, test_size=0.1)\n",
      "  66: xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.2)\n",
      "  67: \n",
      "  68: \n",
      "  69: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     # Parameter für das CNN\n",
      "   4:     inputShape     = (368, 70, 3)   # Eingangs Array-Form \n",
      "   5:     numNeuronsC1   = 32                # Anzahl der Filter / 1 Faltungsschicht\n",
      "   6:     numNeuronsC2   = 32                # Anzahl der Filter / 2 Faltungsschicht\n",
      "   7:     numNeuronsC3   = 64                # Anzahl der Filter / 3 Faltungsschicht\n",
      "   8:     numNeuronsD1   = 64                # Anzahl der Neuronen des Fully connected layer - vollverbundene Schicht\n",
      "   9:     poolSize       = 2                 # Größe der Pooling-Layer\n",
      "  10:     convKernelSize = 3                 # Größe des Faltungskern n*n\n",
      "  11:     batchSize      = 32\n",
      "  12:     \n",
      "  13:     model = Sequential()\n",
      "  14:     layerCountTuning = space['layerCountTuning']\n",
      "  15:     print(layerCountTuning)\n",
      "  16:     af = space['af']\n",
      "  17:     print(af)\n",
      "  18:     optf = space['optf']\n",
      "  19:     print(optf)\n",
      "  20:     model.add(Conv2D(numNeuronsC1, (convKernelSize, convKernelSize), padding='same', input_shape=inputShape))\n",
      "  21:     model.add(Activation(af))\n",
      "  22:     model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  23:     model.add(Dropout(space['Dropout']))\n",
      "  24:     \n",
      "  25:     if layerCountTuning == '2Layer' or '3Layer' or '4Layer':\n",
      "  26:         filterCount2 = space['filterCount2']\n",
      "  27:         model.add(Conv2D(filterCount2, (convKernelSize, convKernelSize), padding='same'))\n",
      "  28:         model.add(Activation(af))\n",
      "  29:         model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  30:         model.add(Dropout(space['Dropout_1']))\n",
      "  31:     \n",
      "  32:     if layerCountTuning == '3Layer' or '4Layer':\n",
      "  33:         filterCount3 = space['filterCount3']\n",
      "  34:         model.add(Conv2D(filterCount3, (convKernelSize, convKernelSize), padding='same'))\n",
      "  35:         model.add(Activation(af))\n",
      "  36:         model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  37:         model.add(Dropout(space['Dropout_2']))\n",
      "  38: \n",
      "  39:     if layerCountTuning == '4Layer':\n",
      "  40:         filterCount4 = space['filterCount4']\n",
      "  41:         model.add(Conv2D(filterCount4, (convKernelSize, convKernelSize), padding='same'))\n",
      "  42:         model.add(Activation(af))\n",
      "  43:         model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  44:         model.add(Dropout(space['Dropout_3']))       \n",
      "  45: \n",
      "  46:     model.add(Flatten())\n",
      "  47:     dims4 = space['dims4']\n",
      "  48:     model.add(Dense(dims4))\n",
      "  49:     model.add(Activation(af))\n",
      "  50:     model.add(Dropout(space['Dropout_4']))\n",
      "  51: \n",
      "  52:     model.add(Dense(4))\n",
      "  53:     model.add(Activation('softmax'))\n",
      "  54:     \n",
      "  55:     # Diese Funktion läd Bilder in den Hauptspeicher\n",
      "  56:     # imagesPaths: Liste mit Pfaden zu den Bildern != null\n",
      "  57:     def imageLoader(imagePaths):\n",
      "  58:         images = []\n",
      "  59:         for path in imagePaths:\n",
      "  60:             images.append(cv2.imread(path))\n",
      "  61:         \n",
      "  62:         imagesNp = np.array(images)\n",
      "  63:         imagesNp = imagesNp.astype('float32')\n",
      "  64:         imagesNp /= 255\n",
      "  65:         return imagesNp\n",
      "  66: \n",
      "  67:     # Läd Trainingsdaten in batches\n",
      "  68:     def dataLoader(imagePaths, features, batchSize):\n",
      "  69:         imagesCount= len(imagePaths)  \n",
      "  70:         while True:\n",
      "  71:             batchStart = 0\n",
      "  72:             batchEnd = batchSize\n",
      "  73:             while batchStart < imagesCount:\n",
      "  74:                 limit = min(batchEnd, imagesCount)\n",
      "  75:                 x = imageLoader(imagePaths[batchStart:limit])\n",
      "  76:                 y = features[batchStart:limit]\n",
      "  77:                 yield (x,y) \n",
      "  78:                 batchStart += batchSize   \n",
      "  79:                 batchEnd += batchSize\n",
      "  80:                 \n",
      "  81:     model.compile(loss='categorical_crossentropy', optimizer=optf, metrics=[\"accuracy\"])\n",
      "  82:     print('Train...')\n",
      "  83:     # Early Stopping unterbricht das Training, wenn nach 3 Epochen die Kostenfunktion nicht weiter minimiert werden konnte \n",
      "  84:     earlyStopping = cb.EarlyStopping(monitor='val_acc', patience=3, verbose=1, mode='max')\n",
      "  85:     checkpointSafe = cb.ModelCheckpoint('ergebnisse_versuch4/modell_versuch4_3', monitor='val_acc', save_best_only=True)   \n",
      "  86:     model.fit_generator(dataLoader(xTrain, yTrain, batchSize), epochs=10, steps_per_epoch=(int(len(xTrain)/batchSize)),\n",
      "  87:               validation_data=dataLoader(xVal, yVal, batchSize), validation_steps=(int(len(xVal)/batchSize)), callbacks=[earlyStopping,checkpointSafe])\n",
      "  88:     score, acc = model.evaluate_generator( dataLoader(xVal, yVal, batchSize), steps=(int(len(xVal)/batchSize)))\n",
      "  89:     print('Test score: ' + str(score))\n",
      "  90:     print('Test accuracy: ' +  str(acc))\n",
      "  91:     # Die Rückgabewerte werden verarbeitet von Hyperas\n",
      "  92:     # loss ist die Kostenfunktion welche minimiert werden soll mit Hyperas\n",
      "  93:     # status (STATUS_OK) gibt an das, dass Modell erfolgreich ausgeführt wurde\n",
      "  94:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  95: \n",
      "C:/Users/morro/Documents/datenRoh/37/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "Ordner der geladen wird: 11\n",
      "Ordner der geladen wird: 12\n",
      "Ordner der geladen wird: 13\n",
      "Ordner der geladen wird: 14\n",
      "C:/Users/morro/Documents/datenRoh/38/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "Ordner der geladen wird: 11\n",
      "Ordner der geladen wird: 12\n",
      "Ordner der geladen wird: 13\n",
      "Ordner der geladen wird: 14\n",
      "Ordner der geladen wird: 15\n",
      "Ordner der geladen wird: 16\n",
      "Ordner der geladen wird: 17\n",
      "Ordner der geladen wird: 18\n",
      "Ordner der geladen wird: 19\n",
      "Ordner der geladen wird: 20\n",
      "Ordner der geladen wird: 21\n",
      "Ordner der geladen wird: 22\n",
      "C:/Users/morro/Documents/datenRoh/39/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "C:/Users/morro/Documents/datenRoh/40/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "C:/Users/morro/Documents/datenRoh/41/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "C:/Users/morro/Documents/datenRoh/42/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "3Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 12.0676 - acc: 0.2509 - val_loss: 12.2118 - val_acc: 0.2422\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 12.0569 - acc: 0.2520 - val_loss: 12.2118 - val_acc: 0.2422\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 12.0575 - acc: 0.2519 - val_loss: 12.2118 - val_acc: 0.2422\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 12.0575 - acc: 0.2519 - val_loss: 12.2118 - val_acc: 0.2422\n",
      "Epoch 00004: early stopping\n",
      "Test score: 12.211758633781882\n",
      "Test accuracy: 0.2422058823529412\n",
      "4Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 101s 59ms/step - loss: 1.3916 - acc: 0.2574 - val_loss: 1.3759 - val_acc: 0.2726\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3778 - acc: 0.2850 - val_loss: 1.3536 - val_acc: 0.3194\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3647 - acc: 0.3061 - val_loss: 1.3289 - val_acc: 0.3571\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3393 - acc: 0.3369 - val_loss: 1.3032 - val_acc: 0.3911\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3193 - acc: 0.3576 - val_loss: 1.3847 - val_acc: 0.3165\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 100s 58ms/step - loss: 1.3061 - acc: 0.3660 - val_loss: 1.3033 - val_acc: 0.3666\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3047 - acc: 0.3665 - val_loss: 1.3158 - val_acc: 0.3326\n",
      "Epoch 00007: early stopping\n",
      "Test score: 1.3157151407354017\n",
      "Test accuracy: 0.33286764705882355\n",
      "4Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 113s 66ms/step - loss: 1.7759 - acc: 0.2494 - val_loss: 1.3945 - val_acc: 0.2566\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.4161 - acc: 0.2499 - val_loss: 1.3971 - val_acc: 0.2566\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.4008 - acc: 0.2492 - val_loss: 1.3985 - val_acc: 0.2565\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.3987 - acc: 0.2506 - val_loss: 1.4001 - val_acc: 0.2561\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.4000290548100192\n",
      "Test accuracy: 0.2565441176470588\n",
      "3Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 135s 79ms/step - loss: 12.0901 - acc: 0.2495 - val_loss: 11.8834 - val_acc: 0.2489\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 133s 78ms/step - loss: 12.0998 - acc: 0.2493 - val_loss: 11.8834 - val_acc: 0.2489\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 133s 78ms/step - loss: 12.0992 - acc: 0.2493 - val_loss: 11.8777 - val_acc: 0.2493\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 134s 79ms/step - loss: 12.0980 - acc: 0.2494 - val_loss: 11.8768 - val_acc: 0.2493\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 134s 79ms/step - loss: 12.0986 - acc: 0.2494 - val_loss: 11.8768 - val_acc: 0.2493\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 134s 78ms/step - loss: 12.0983 - acc: 0.2494 - val_loss: 11.8768 - val_acc: 0.2493\n",
      "Epoch 00006: early stopping\n",
      "Test score: 11.883398529501521\n",
      "Test accuracy: 0.24889705882352942\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 12.0877 - acc: 0.2499 - val_loss: 2.5448 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 115s 68ms/step - loss: 12.0889 - acc: 0.2500 - val_loss: 2.5448 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 12.0898 - acc: 0.2499 - val_loss: 2.5448 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 115s 68ms/step - loss: 12.0901 - acc: 0.2499 - val_loss: 2.5458 - val_acc: 0.2524\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 12.0903 - acc: 0.2499 - val_loss: 2.5458 - val_acc: 0.2524\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 12.0892 - acc: 0.2500 - val_loss: 2.5458 - val_acc: 0.2524\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 12.0898 - acc: 0.2499 - val_loss: 2.5458 - val_acc: 0.2524\n",
      "Epoch 00007: early stopping\n",
      "Test score: 2.544847551794613\n",
      "Test accuracy: 0.2523529411764706\n",
      "4Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 110s 65ms/step - loss: 12.1017 - acc: 0.2489 - val_loss: 1.7841 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 110s 64ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 1.7841 - val_acc: 0.2565\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 110s 64ms/step - loss: 12.1078 - acc: 0.2488 - val_loss: 1.7841 - val_acc: 0.2565\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 109s 64ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 1.7849 - val_acc: 0.2561\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.784084924810073\n",
      "Test accuracy: 0.2565441176470588\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.4624 - acc: 0.2718 - val_loss: 1.4091 - val_acc: 0.2557\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3799 - acc: 0.2890 - val_loss: 1.3793 - val_acc: 0.2775\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3708 - acc: 0.2974 - val_loss: 1.3517 - val_acc: 0.3176\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3675 - acc: 0.3048 - val_loss: 1.3709 - val_acc: 0.3279\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3602 - acc: 0.3176 - val_loss: 1.3482 - val_acc: 0.3480\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3157 - acc: 0.3539 - val_loss: 1.5012 - val_acc: 0.3415\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.2813 - acc: 0.3816 - val_loss: 1.3120 - val_acc: 0.3920\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.2544 - acc: 0.4014 - val_loss: 1.2882 - val_acc: 0.4115\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.2283 - acc: 0.4197 - val_loss: 1.3984 - val_acc: 0.3915\n",
      "Epoch 10/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.1974 - acc: 0.4372 - val_loss: 1.5376 - val_acc: 0.3763\n",
      "Test score: 1.5381082165942472\n",
      "Test accuracy: 0.3759558823529412\n",
      "3Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 111s 65ms/step - loss: 1.5228 - acc: 0.2487 - val_loss: 1.3862 - val_acc: 0.2489\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 110s 64ms/step - loss: 1.3867 - acc: 0.2475 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 110s 65ms/step - loss: 1.3864 - acc: 0.2495 - val_loss: 1.3862 - val_acc: 0.2517\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 110s 64ms/step - loss: 1.3865 - acc: 0.2498 - val_loss: 1.3862 - val_acc: 0.2517\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 110s 65ms/step - loss: 1.3865 - acc: 0.2492 - val_loss: 1.3862 - val_acc: 0.2517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005: early stopping\n",
      "Test score: 1.3862213404038373\n",
      "Test accuracy: 0.2523529411764706\n",
      "4Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 123s 72ms/step - loss: 12.0956 - acc: 0.2495 - val_loss: 3.5391 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 122s 71ms/step - loss: 12.0886 - acc: 0.2500 - val_loss: 3.5391 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 122s 71ms/step - loss: 12.0903 - acc: 0.2499 - val_loss: 3.5395 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 121s 71ms/step - loss: 12.0905 - acc: 0.2499 - val_loss: 3.6062 - val_acc: 0.2517\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 122s 72ms/step - loss: 12.0906 - acc: 0.2499 - val_loss: 4.4765 - val_acc: 0.2517\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 12.0898 - acc: 0.2499 - val_loss: 4.4765 - val_acc: 0.2517\n",
      "Epoch 00006: early stopping\n",
      "Test score: 4.472421714558321\n",
      "Test accuracy: 0.2523529411764706\n",
      "2Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.5449 - acc: 0.2487 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.3865 - acc: 0.2510 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.3864 - acc: 0.2488 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.3864 - acc: 0.2503 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.386260684518253\n",
      "Test accuracy: 0.2523529411764706\n",
      "3Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 12.0874 - acc: 0.2497 - val_loss: 7.2833 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 12.0889 - acc: 0.2500 - val_loss: 7.2833 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 12.0898 - acc: 0.2499 - val_loss: 7.2833 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 12.0901 - acc: 0.2499 - val_loss: 7.2833 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 7.283283965166877\n",
      "Test accuracy: 0.2523529411764706\n",
      "2Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.3898 - acc: 0.2511 - val_loss: 1.3861 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 105s 62ms/step - loss: 1.3865 - acc: 0.2484 - val_loss: 1.3862 - val_acc: 0.2490\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 105s 62ms/step - loss: 1.3864 - acc: 0.2496 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 1.3864 - acc: 0.2493 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3862126790775973\n",
      "Test accuracy: 0.2523529411764706\n",
      "3Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 134s 79ms/step - loss: 12.0979 - acc: 0.2490 - val_loss: 10.2751 - val_acc: 0.2438\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 132s 77ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 10.2713 - val_acc: 0.2439\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 132s 77ms/step - loss: 12.1078 - acc: 0.2488 - val_loss: 10.2713 - val_acc: 0.2439\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 132s 77ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 10.2713 - val_acc: 0.2439\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 132s 77ms/step - loss: 12.1084 - acc: 0.2488 - val_loss: 10.2713 - val_acc: 0.2439\n",
      "Epoch 00005: early stopping\n",
      "Test score: 10.27513453427483\n",
      "Test accuracy: 0.24382352941176472\n",
      "3Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 127s 74ms/step - loss: 12.1033 - acc: 0.2488 - val_loss: 6.1778 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 125s 73ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 6.1801 - val_acc: 0.2561\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 125s 73ms/step - loss: 12.1078 - acc: 0.2488 - val_loss: 6.1801 - val_acc: 0.2561\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 125s 73ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 6.1801 - val_acc: 0.2561\n",
      "Epoch 00004: early stopping\n",
      "Test score: 6.177807064056396\n",
      "Test accuracy: 0.2565441176470588\n",
      "2Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 121s 71ms/step - loss: 1.5486 - acc: 0.2502 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 1.3865 - acc: 0.2479 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 1.3865 - acc: 0.2486 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 1.3864 - acc: 0.2492 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 1.3864 - acc: 0.2499 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.386264178051668\n",
      "Test accuracy: 0.2523529411764706\n",
      "3Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 105s 62ms/step - loss: 1.3883 - acc: 0.2480 - val_loss: 1.3862 - val_acc: 0.2575\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 103s 61ms/step - loss: 1.3865 - acc: 0.2486 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 103s 61ms/step - loss: 1.3864 - acc: 0.2499 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 103s 61ms/step - loss: 1.3864 - acc: 0.2492 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3862643682255464\n",
      "Test accuracy: 0.2523529411764706\n",
      "3Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 1.3994 - acc: 0.2499 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2503 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2503 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2502 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2502 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.3862667560577393\n",
      "Test accuracy: 0.2523529411764706\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 1.4261 - acc: 0.2871 - val_loss: 1.3777 - val_acc: 0.2846\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3305 - acc: 0.3365 - val_loss: 1.2715 - val_acc: 0.3707\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.2723 - acc: 0.3872 - val_loss: 1.2500 - val_acc: 0.4004\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.2476 - acc: 0.4050 - val_loss: 1.3412 - val_acc: 0.3685\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.2155 - acc: 0.4324 - val_loss: 1.3226 - val_acc: 0.3872\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.1732 - acc: 0.4629 - val_loss: 1.2886 - val_acc: 0.4077\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.1139 - acc: 0.5003 - val_loss: 1.3465 - val_acc: 0.3980\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.0607 - acc: 0.5299 - val_loss: 1.3359 - val_acc: 0.4036\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.0056 - acc: 0.5596 - val_loss: 1.3940 - val_acc: 0.3755\n",
      "Epoch 00009: early stopping\n",
      "Test score: 1.3939612994474524\n",
      "Test accuracy: 0.37558823529411767\n",
      "2Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 105s 62ms/step - loss: 12.0442 - acc: 0.2521 - val_loss: 12.2139 - val_acc: 0.2422\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 103s 61ms/step - loss: 12.0569 - acc: 0.2520 - val_loss: 12.2133 - val_acc: 0.2422\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 103s 61ms/step - loss: 12.0575 - acc: 0.2519 - val_loss: 12.2133 - val_acc: 0.2422\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 103s 61ms/step - loss: 12.0575 - acc: 0.2519 - val_loss: 12.2133 - val_acc: 0.2422\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 103s 61ms/step - loss: 12.0569 - acc: 0.2520 - val_loss: 12.2133 - val_acc: 0.2422\n",
      "Epoch 00005: early stopping\n",
      "Test score: 12.21386281854966\n",
      "Test accuracy: 0.2422058823529412\n",
      "4Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 1.7915 - acc: 0.2493 - val_loss: 1.4023 - val_acc: 0.2422\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 113s 67ms/step - loss: 1.4194 - acc: 0.2508 - val_loss: 1.4173 - val_acc: 0.2422\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 113s 67ms/step - loss: 1.4494 - acc: 0.2469 - val_loss: 1.7531 - val_acc: 0.2422\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.4406 - acc: 0.2512 - val_loss: 1.4034 - val_acc: 0.2418\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.403581804668202\n",
      "Test accuracy: 0.24176470588235294\n",
      "3Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.5578 - acc: 0.2738 - val_loss: 1.3996 - val_acc: 0.2756\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3805 - acc: 0.2856 - val_loss: 1.3690 - val_acc: 0.2996\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3752 - acc: 0.2913 - val_loss: 1.3910 - val_acc: 0.2759\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3758 - acc: 0.2897 - val_loss: 1.3845 - val_acc: 0.3082\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3795 - acc: 0.2855 - val_loss: 1.3844 - val_acc: 0.2743\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3876 - acc: 0.2647 - val_loss: 1.3944 - val_acc: 0.2315\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.3915 - acc: 0.2522 - val_loss: 1.3914 - val_acc: 0.2493\n",
      "Epoch 00007: early stopping\n",
      "Test score: 1.3914255478802848\n",
      "Test accuracy: 0.24889705882352942\n",
      "4Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 96s 56ms/step - loss: 1.3874 - acc: 0.2464 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 94s 55ms/step - loss: 1.3865 - acc: 0.2473 - val_loss: 1.3862 - val_acc: 0.2493\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 94s 55ms/step - loss: 1.3864 - acc: 0.2497 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 94s 55ms/step - loss: 1.3865 - acc: 0.2501 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.3864 - acc: 0.2500 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.3864 - acc: 0.2506 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 00006: early stopping\n",
      "Test score: 1.386273097150466\n",
      "Test accuracy: 0.2523529411764706\n",
      "4Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.4849 - acc: 0.2675 - val_loss: 1.3849 - val_acc: 0.2523\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 100s 58ms/step - loss: 1.3894 - acc: 0.2748 - val_loss: 1.4147 - val_acc: 0.2493\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4037 - acc: 0.2684 - val_loss: 1.4019 - val_acc: 0.2582\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4141 - acc: 0.2669 - val_loss: 1.4242 - val_acc: 0.2884\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4183 - acc: 0.2566 - val_loss: 1.4416 - val_acc: 0.2508\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4194 - acc: 0.2511 - val_loss: 1.9398 - val_acc: 0.2422\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 100s 58ms/step - loss: 1.4205 - acc: 0.2491 - val_loss: 1.4142 - val_acc: 0.2562\n",
      "Epoch 00007: early stopping\n",
      "Test score: 1.4141110493155087\n",
      "Test accuracy: 0.25669117647058826\n",
      "4Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.5115 - acc: 0.2521 - val_loss: 1.4175 - val_acc: 0.2421\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 104s 61ms/step - loss: 1.4266 - acc: 0.2579 - val_loss: 1.3840 - val_acc: 0.2684\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.4279 - acc: 0.2567 - val_loss: 1.3942 - val_acc: 0.2759\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.4280 - acc: 0.2675 - val_loss: 1.3714 - val_acc: 0.3071\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.4263 - acc: 0.2764 - val_loss: 1.4555 - val_acc: 0.2566\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.4173 - acc: 0.2877 - val_loss: 1.3730 - val_acc: 0.3020\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.3978 - acc: 0.3161 - val_loss: 1.3444 - val_acc: 0.3332\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.3931 - acc: 0.3213 - val_loss: 1.2746 - val_acc: 0.3781\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.3981 - acc: 0.3214 - val_loss: 1.4558 - val_acc: 0.3081\n",
      "Epoch 10/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.3994 - acc: 0.3213 - val_loss: 1.2912 - val_acc: 0.3808\n",
      "Test score: 1.2911685893114875\n",
      "Test accuracy: 0.38080882352941176\n",
      "3Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 12.0606 - acc: 0.2497 - val_loss: 12.0506 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 103s 61ms/step - loss: 12.1057 - acc: 0.2488 - val_loss: 12.1063 - val_acc: 0.2489\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 104s 61ms/step - loss: 12.0992 - acc: 0.2493 - val_loss: 12.1063 - val_acc: 0.2489\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 104s 61ms/step - loss: 12.0980 - acc: 0.2494 - val_loss: 12.0998 - val_acc: 0.2493\n",
      "Epoch 00004: early stopping\n",
      "Test score: 12.106348906124339\n",
      "Test accuracy: 0.24889705882352942\n",
      "3Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 110s 64ms/step - loss: 3.1967 - acc: 0.2511 - val_loss: 6.1303 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.4114 - acc: 0.2485 - val_loss: 7.7720 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.4063 - acc: 0.2491 - val_loss: 9.3755 - val_acc: 0.2493\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.4033 - acc: 0.2506 - val_loss: 9.5369 - val_acc: 0.2493\n",
      "Epoch 00004: early stopping\n",
      "Test score: 9.543834818671732\n",
      "Test accuracy: 0.24889705882352942\n",
      "3Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 130s 76ms/step - loss: 12.1062 - acc: 0.2487 - val_loss: 3.1169 - val_acc: 0.2493\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 127s 75ms/step - loss: 12.1051 - acc: 0.2483 - val_loss: 9.9802 - val_acc: 0.2561\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 127s 75ms/step - loss: 12.1271 - acc: 0.2470 - val_loss: 11.9875 - val_acc: 0.2561\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 127s 75ms/step - loss: 12.0465 - acc: 0.2519 - val_loss: 12.0998 - val_acc: 0.2493\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 127s 75ms/step - loss: 12.0836 - acc: 0.2500 - val_loss: 12.0998 - val_acc: 0.2493\n",
      "Epoch 00005: early stopping\n",
      "Test score: 12.106348906124339\n",
      "Test accuracy: 0.24889705882352942\n",
      "4Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 99s 58ms/step - loss: 1.4455 - acc: 0.2545 - val_loss: 1.3966 - val_acc: 0.2497\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.4003 - acc: 0.2626 - val_loss: 1.3794 - val_acc: 0.2712\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 96s 57ms/step - loss: 1.3995 - acc: 0.2662 - val_loss: 1.3700 - val_acc: 0.3215\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.3995 - acc: 0.2725 - val_loss: 1.3624 - val_acc: 0.3168\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.3963 - acc: 0.2796 - val_loss: 1.3905 - val_acc: 0.2954\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.3940 - acc: 0.2861 - val_loss: 1.3407 - val_acc: 0.3410\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.3921 - acc: 0.2914 - val_loss: 1.3315 - val_acc: 0.3501\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.3860 - acc: 0.2996 - val_loss: 1.3092 - val_acc: 0.3772\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.3856 - acc: 0.3031 - val_loss: 1.3108 - val_acc: 0.3523\n",
      "Epoch 10/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.3879 - acc: 0.3037 - val_loss: 1.2901 - val_acc: 0.3775\n",
      "Test score: 1.2899995394314037\n",
      "Test accuracy: 0.3775\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 125s 73ms/step - loss: 1.4367 - acc: 0.2701 - val_loss: 1.3699 - val_acc: 0.3202\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 122s 72ms/step - loss: 1.3886 - acc: 0.2727 - val_loss: 1.3798 - val_acc: 0.2814\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 122s 72ms/step - loss: 1.4033 - acc: 0.2647 - val_loss: 1.3882 - val_acc: 0.2580\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 122s 72ms/step - loss: 1.4048 - acc: 0.2573 - val_loss: 1.3911 - val_acc: 0.2749\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3910693718405331\n",
      "Test accuracy: 0.27536764705882355\n",
      "3Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 109s 64ms/step - loss: 1.4312 - acc: 0.2753 - val_loss: 1.3834 - val_acc: 0.2954\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.3708 - acc: 0.2975 - val_loss: 1.3586 - val_acc: 0.3228\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.3511 - acc: 0.3154 - val_loss: 1.3797 - val_acc: 0.3588\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.2996 - acc: 0.3653 - val_loss: 1.4589 - val_acc: 0.3339\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.2821 - acc: 0.3773 - val_loss: 1.4194 - val_acc: 0.3509\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.2738 - acc: 0.3854 - val_loss: 1.3943 - val_acc: 0.3763\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.2701 - acc: 0.3869 - val_loss: 1.3519 - val_acc: 0.4036\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.2679 - acc: 0.3898 - val_loss: 1.2744 - val_acc: 0.4028\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.2676 - acc: 0.3862 - val_loss: 1.3522 - val_acc: 0.3781\n",
      "Epoch 10/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.2662 - acc: 0.3856 - val_loss: 1.5241 - val_acc: 0.3660\n",
      "Epoch 00010: early stopping\n",
      "Test score: 1.5239030327516443\n",
      "Test accuracy: 0.36625\n",
      "2Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 98s 58ms/step - loss: 1.3975 - acc: 0.2613 - val_loss: 1.3852 - val_acc: 0.2682\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 95s 56ms/step - loss: 1.3827 - acc: 0.2790 - val_loss: 1.3877 - val_acc: 0.2604\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 95s 56ms/step - loss: 1.3798 - acc: 0.2826 - val_loss: 1.3856 - val_acc: 0.2573\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 95s 56ms/step - loss: 1.3740 - acc: 0.2963 - val_loss: 1.3919 - val_acc: 0.2631\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3916643400753246\n",
      "Test accuracy: 0.2636029411764706\n",
      "2Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 94s 55ms/step - loss: 2.6993 - acc: 0.2547 - val_loss: 1.4147 - val_acc: 0.2424\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.4277 - acc: 0.2598 - val_loss: 4.5523 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.4016 - acc: 0.2677 - val_loss: 1.7931 - val_acc: 0.2518\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3833 - acc: 0.2867 - val_loss: 1.5005 - val_acc: 0.2526\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3764 - acc: 0.2953 - val_loss: 2.1876 - val_acc: 0.2423\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3737 - acc: 0.2964 - val_loss: 1.9635 - val_acc: 0.2424\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3720 - acc: 0.3013 - val_loss: 1.5885 - val_acc: 0.2948\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3711 - acc: 0.3028 - val_loss: 1.4360 - val_acc: 0.2759\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3694 - acc: 0.3055 - val_loss: 1.9370 - val_acc: 0.2386\n",
      "Epoch 10/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3678 - acc: 0.3076 - val_loss: 1.5633 - val_acc: 0.2542\n",
      "Epoch 00010: early stopping\n",
      "Test score: 1.5635049424451941\n",
      "Test accuracy: 0.25419117647058825\n",
      "3Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 98s 57ms/step - loss: 1.4414 - acc: 0.2661 - val_loss: 1.3735 - val_acc: 0.2836\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 95s 56ms/step - loss: 1.3883 - acc: 0.2704 - val_loss: 1.3890 - val_acc: 0.2682\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 95s 56ms/step - loss: 1.3969 - acc: 0.2668 - val_loss: 1.3748 - val_acc: 0.2695\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 95s 56ms/step - loss: 1.4019 - acc: 0.2668 - val_loss: 1.3920 - val_acc: 0.2544\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3921249633676867\n",
      "Test accuracy: 0.25426470588235295\n",
      "4Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 123s 72ms/step - loss: 1.3920 - acc: 0.2552 - val_loss: 1.3863 - val_acc: 0.2579\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3859 - acc: 0.2651 - val_loss: 1.3826 - val_acc: 0.2683\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3829 - acc: 0.2745 - val_loss: 1.3820 - val_acc: 0.2686\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3788 - acc: 0.2883 - val_loss: 1.3730 - val_acc: 0.3045\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3745 - acc: 0.2963 - val_loss: 1.3813 - val_acc: 0.2750\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3697 - acc: 0.2971 - val_loss: 1.3688 - val_acc: 0.3064\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3676 - acc: 0.2978 - val_loss: 1.3737 - val_acc: 0.2970\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3652 - acc: 0.3011 - val_loss: 1.3713 - val_acc: 0.2965\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3577 - acc: 0.3117 - val_loss: 1.3809 - val_acc: 0.2641\n",
      "Epoch 00009: early stopping\n",
      "Test score: 1.380878738235025\n",
      "Test accuracy: 0.26375\n",
      "2Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 95s 56ms/step - loss: 1.4205 - acc: 0.2603 - val_loss: 1.3853 - val_acc: 0.2656\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3779 - acc: 0.2888 - val_loss: 1.3726 - val_acc: 0.3074\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3714 - acc: 0.3004 - val_loss: 1.3844 - val_acc: 0.2707\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3679 - acc: 0.3044 - val_loss: 1.3777 - val_acc: 0.2907\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3618 - acc: 0.3122 - val_loss: 1.3992 - val_acc: 0.2668\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.3992349405849682\n",
      "Test accuracy: 0.26676470588235296\n",
      "3Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0787 - acc: 0.2502 - val_loss: 10.1249 - val_acc: 0.2526\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 104s 61ms/step - loss: 12.0998 - acc: 0.2493 - val_loss: 10.1249 - val_acc: 0.2526\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 104s 61ms/step - loss: 12.0992 - acc: 0.2493 - val_loss: 10.1249 - val_acc: 0.2526\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 104s 61ms/step - loss: 12.0980 - acc: 0.2494 - val_loss: 10.1249 - val_acc: 0.2526\n",
      "Epoch 00004: early stopping\n",
      "Test score: 10.124860658084645\n",
      "Test accuracy: 0.2525735294117647\n",
      "4Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 2.8445 - acc: 0.2484 - val_loss: 1.3890 - val_acc: 0.2415\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 113s 66ms/step - loss: 1.5069 - acc: 0.2499 - val_loss: 1.3926 - val_acc: 0.2561\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 113s 66ms/step - loss: 1.5565 - acc: 0.2513 - val_loss: 1.3934 - val_acc: 0.2561\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 113s 66ms/step - loss: 1.5849 - acc: 0.2469 - val_loss: 1.6603 - val_acc: 0.2442\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 113s 66ms/step - loss: 1.5602 - acc: 0.2506 - val_loss: 1.7461 - val_acc: 0.2459\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.747576399971457\n",
      "Test accuracy: 0.24573529411764705\n",
      "3Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 2.3832 - acc: 0.2515 - val_loss: 1.3868 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 90s 53ms/step - loss: 1.3850 - acc: 0.2688 - val_loss: 1.3894 - val_acc: 0.2565\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 90s 53ms/step - loss: 1.3803 - acc: 0.2796 - val_loss: 1.3946 - val_acc: 0.2565\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 90s 53ms/step - loss: 1.3776 - acc: 0.2858 - val_loss: 1.4032 - val_acc: 0.2565\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.403164700900807\n",
      "Test accuracy: 0.2565441176470588\n",
      "4Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 122s 71ms/step - loss: 10.2623 - acc: 0.2507 - val_loss: 12.2142 - val_acc: 0.2422\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 10.0321 - acc: 0.2519 - val_loss: 12.2137 - val_acc: 0.2422\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 10.0155 - acc: 0.2492 - val_loss: 11.9908 - val_acc: 0.2561\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 9.7882 - acc: 0.2508 - val_loss: 11.9908 - val_acc: 0.2561\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 9.7452 - acc: 0.2503 - val_loss: 11.9908 - val_acc: 0.2561\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 9.7000 - acc: 0.2521 - val_loss: 11.9908 - val_acc: 0.2561\n",
      "Epoch 00006: early stopping\n",
      "Test score: 11.983092837614171\n",
      "Test accuracy: 0.2565441176470588\n",
      "3Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 95s 56ms/step - loss: 1.3965 - acc: 0.2462 - val_loss: 1.3862 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 91s 54ms/step - loss: 1.3865 - acc: 0.2481 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 91s 54ms/step - loss: 1.3864 - acc: 0.2494 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 91s 54ms/step - loss: 1.3864 - acc: 0.2502 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3862483243381276\n",
      "Test accuracy: 0.2523529411764706\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 129s 76ms/step - loss: 12.0857 - acc: 0.2496 - val_loss: 12.0506 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 12.0889 - acc: 0.2500 - val_loss: 12.0506 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0898 - acc: 0.2499 - val_loss: 12.0500 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0901 - acc: 0.2499 - val_loss: 12.0500 - val_acc: 0.2524\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0903 - acc: 0.2499 - val_loss: 12.0500 - val_acc: 0.2524\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0892 - acc: 0.2500 - val_loss: 12.0500 - val_acc: 0.2524\n",
      "Epoch 00006: early stopping\n",
      "Test score: 12.050646636065315\n",
      "Test accuracy: 0.2523529411764706\n",
      "3Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 110s 64ms/step - loss: 1.4149 - acc: 0.2537 - val_loss: 1.3951 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.4036 - acc: 0.2513 - val_loss: 1.3954 - val_acc: 0.2581\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.4008 - acc: 0.2490 - val_loss: 1.3963 - val_acc: 0.2565\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.3993 - acc: 0.2482 - val_loss: 1.3959 - val_acc: 0.2561\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.3963 - acc: 0.2488 - val_loss: 1.3957 - val_acc: 0.2561\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.3956584907980527\n",
      "Test accuracy: 0.2565441176470588\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 97s 57ms/step - loss: 1.4087 - acc: 0.2748 - val_loss: 1.3652 - val_acc: 0.3254\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.3730 - acc: 0.2935 - val_loss: 1.3541 - val_acc: 0.3160\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.3629 - acc: 0.3074 - val_loss: 1.3620 - val_acc: 0.3378\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.3404 - acc: 0.3288 - val_loss: 1.4509 - val_acc: 0.3293\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.2857 - acc: 0.3796 - val_loss: 1.3597 - val_acc: 0.3692\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.2621 - acc: 0.3931 - val_loss: 1.2423 - val_acc: 0.4174\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.2534 - acc: 0.3981 - val_loss: 1.3141 - val_acc: 0.3978\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.2376 - acc: 0.4107 - val_loss: 1.3615 - val_acc: 0.3936\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 93s 55ms/step - loss: 1.2298 - acc: 0.4135 - val_loss: 1.3368 - val_acc: 0.3925\n",
      "Epoch 00009: early stopping\n",
      "Test score: 1.3362507444269518\n",
      "Test accuracy: 0.39279411764705885\n",
      "2Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 122s 72ms/step - loss: 12.0884 - acc: 0.2497 - val_loss: 5.7593 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 12.0889 - acc: 0.2500 - val_loss: 5.7593 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 118s 70ms/step - loss: 12.0898 - acc: 0.2499 - val_loss: 5.7593 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 118s 70ms/step - loss: 12.0901 - acc: 0.2499 - val_loss: 5.7593 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 5.759255251042983\n",
      "Test accuracy: 0.2523529411764706\n",
      "2Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 96s 56ms/step - loss: 1.5709 - acc: 0.2501 - val_loss: 1.3862 - val_acc: 0.2489\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3865 - acc: 0.2508 - val_loss: 1.3862 - val_acc: 0.2565\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 92s 54ms/step - loss: 1.3866 - acc: 0.2480 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 93s 54ms/step - loss: 1.3871 - acc: 0.2510 - val_loss: 1.3868 - val_acc: 0.2489\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 93s 54ms/step - loss: 1.3871 - acc: 0.2532 - val_loss: 1.3868 - val_acc: 0.2493\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.3868427997476915\n",
      "Test accuracy: 0.24889705882352942\n",
      "3Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 105s 62ms/step - loss: 1.5509 - acc: 0.2636 - val_loss: 1.3711 - val_acc: 0.3232\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 101s 59ms/step - loss: 1.3894 - acc: 0.2724 - val_loss: 1.3776 - val_acc: 0.2723\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 101s 59ms/step - loss: 1.3856 - acc: 0.2754 - val_loss: 1.4064 - val_acc: 0.2590\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 101s 59ms/step - loss: 1.3940 - acc: 0.2686 - val_loss: 1.3662 - val_acc: 0.2957\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3662434106714585\n",
      "Test accuracy: 0.29573529411764704\n",
      "4Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 131s 77ms/step - loss: 1.3947 - acc: 0.2552 - val_loss: 1.3824 - val_acc: 0.2718\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 127s 74ms/step - loss: 1.3839 - acc: 0.2792 - val_loss: 1.3725 - val_acc: 0.3224\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 127s 74ms/step - loss: 1.3738 - acc: 0.2890 - val_loss: 1.3839 - val_acc: 0.2715\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 127s 74ms/step - loss: 1.3640 - acc: 0.3044 - val_loss: 1.3635 - val_acc: 0.2875\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 127s 74ms/step - loss: 1.3541 - acc: 0.3130 - val_loss: 1.4343 - val_acc: 0.2754\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.4339476114160874\n",
      "Test accuracy: 0.2758088235294118\n",
      "4Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 133s 78ms/step - loss: 12.1004 - acc: 0.2489 - val_loss: 11.0087 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 129s 76ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 11.0087 - val_acc: 0.2565\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 129s 76ms/step - loss: 12.1078 - acc: 0.2488 - val_loss: 11.0087 - val_acc: 0.2565\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 130s 76ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 11.0087 - val_acc: 0.2565\n",
      "Epoch 00004: early stopping\n",
      "Test score: 11.00872585296631\n",
      "Test accuracy: 0.2565441176470588\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 111s 65ms/step - loss: 1.4767 - acc: 0.2726 - val_loss: 1.4011 - val_acc: 0.2932\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.3770 - acc: 0.2883 - val_loss: 1.4547 - val_acc: 0.2621\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.3793 - acc: 0.2883 - val_loss: 1.4358 - val_acc: 0.2688\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.3851 - acc: 0.2863 - val_loss: 1.3841 - val_acc: 0.2926\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3841360319361966\n",
      "Test accuracy: 0.29257352941176473\n",
      "3Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 125s 73ms/step - loss: 1.3895 - acc: 0.2508 - val_loss: 1.3861 - val_acc: 0.2607\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3866 - acc: 0.2488 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3864 - acc: 0.2492 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 120s 71ms/step - loss: 1.3864 - acc: 0.2496 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3862603372686049\n",
      "Test accuracy: 0.2523529411764706\n",
      "2Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 108s 64ms/step - loss: 1.8707 - acc: 0.2516 - val_loss: 1.4184 - val_acc: 0.2566\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 105s 62ms/step - loss: 1.4236 - acc: 0.2577 - val_loss: 1.3871 - val_acc: 0.2993\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 105s 62ms/step - loss: 1.4281 - acc: 0.2535 - val_loss: 1.3797 - val_acc: 0.2710\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 105s 61ms/step - loss: 1.4295 - acc: 0.2585 - val_loss: 1.3768 - val_acc: 0.2832\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 105s 62ms/step - loss: 1.4264 - acc: 0.2648 - val_loss: 1.3849 - val_acc: 0.2714\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.384851940940408\n",
      "Test accuracy: 0.27139705882352944\n",
      "4Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 120s 70ms/step - loss: 1.6544 - acc: 0.2493 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 115s 68ms/step - loss: 1.3872 - acc: 0.2492 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 115s 68ms/step - loss: 1.3872 - acc: 0.2504 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 116s 68ms/step - loss: 1.3865 - acc: 0.2508 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3862454512540032\n",
      "Test accuracy: 0.2523529411764706\n",
      "4Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 105s 62ms/step - loss: 1.3899 - acc: 0.2514 - val_loss: 1.3864 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 101s 59ms/step - loss: 1.3867 - acc: 0.2495 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 101s 59ms/step - loss: 1.3864 - acc: 0.2499 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 101s 59ms/step - loss: 1.3865 - acc: 0.2494 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3862486382091748\n",
      "Test accuracy: 0.2523529411764706\n",
      "4Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 111s 65ms/step - loss: 12.0490 - acc: 0.2519 - val_loss: 12.2142 - val_acc: 0.2422\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0569 - acc: 0.2520 - val_loss: 12.2142 - val_acc: 0.2422\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0575 - acc: 0.2519 - val_loss: 12.2142 - val_acc: 0.2422\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0575 - acc: 0.2519 - val_loss: 12.2137 - val_acc: 0.2422\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0569 - acc: 0.2520 - val_loss: 12.2137 - val_acc: 0.2422\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0569 - acc: 0.2520 - val_loss: 12.2137 - val_acc: 0.2422\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 12.0581 - acc: 0.2519 - val_loss: 12.2137 - val_acc: 0.2422\n",
      "Epoch 00007: early stopping\n",
      "Test score: 12.214197899313534\n",
      "Test accuracy: 0.2422058823529412\n",
      "4Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.3940 - acc: 0.2492 - val_loss: 1.3862 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 1.3866 - acc: 0.2501 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.3864 - acc: 0.2494 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 107s 63ms/step - loss: 1.3866 - acc: 0.2481 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3862396955490113\n",
      "Test accuracy: 0.2523529411764706\n",
      "2Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.4163 - acc: 0.2490 - val_loss: 1.3862 - val_acc: 0.2565\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 110s 64ms/step - loss: 1.3870 - acc: 0.2472 - val_loss: 1.3862 - val_acc: 0.2565\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 110s 64ms/step - loss: 1.3869 - acc: 0.2472 - val_loss: 1.3862 - val_acc: 0.2489\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 110s 64ms/step - loss: 1.3868 - acc: 0.2483 - val_loss: 1.3862 - val_acc: 0.2565\n",
      "Epoch 00004: early stopping\n",
      "Test score: 1.3862000187705545\n",
      "Test accuracy: 0.2565441176470588\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 122s 72ms/step - loss: 1.5117 - acc: 0.2645 - val_loss: 1.3771 - val_acc: 0.2974\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 118s 69ms/step - loss: 1.3830 - acc: 0.2804 - val_loss: 1.3786 - val_acc: 0.2790\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 118s 69ms/step - loss: 1.3853 - acc: 0.2799 - val_loss: 1.3738 - val_acc: 0.2990\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 118s 69ms/step - loss: 1.3991 - acc: 0.2603 - val_loss: 1.3975 - val_acc: 0.2467\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 118s 69ms/step - loss: 1.3990 - acc: 0.2503 - val_loss: 1.3897 - val_acc: 0.2432\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 118s 69ms/step - loss: 1.3990 - acc: 0.2495 - val_loss: 1.3881 - val_acc: 0.2561\n",
      "Epoch 00006: early stopping\n",
      "Test score: 1.3881063192030962\n",
      "Test accuracy: 0.2565441176470588\n",
      "4Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 104s 61ms/step - loss: 1.5616 - acc: 0.2532 - val_loss: 1.3841 - val_acc: 0.2537\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4047 - acc: 0.2569 - val_loss: 1.4213 - val_acc: 0.2565\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4109 - acc: 0.2595 - val_loss: 1.3923 - val_acc: 0.2784\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4173 - acc: 0.2602 - val_loss: 1.4145 - val_acc: 0.2675\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4248 - acc: 0.2590 - val_loss: 1.6952 - val_acc: 0.2523\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 100s 59ms/step - loss: 1.4303 - acc: 0.2559 - val_loss: 1.5315 - val_acc: 0.2506\n",
      "Epoch 00006: early stopping\n",
      "Test score: 1.5321328446444342\n",
      "Test accuracy: 0.2505147058823529\n",
      "4Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 1.3967 - acc: 0.2497 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2503 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2503 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2502 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3865 - acc: 0.2499 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.3862675523757935\n",
      "Test accuracy: 0.2523529411764706\n",
      "3Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.4450 - acc: 0.2707 - val_loss: 1.3683 - val_acc: 0.2886\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.3645 - acc: 0.3023 - val_loss: 1.3357 - val_acc: 0.3250\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.2970 - acc: 0.3700 - val_loss: 1.2931 - val_acc: 0.3618\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.2755 - acc: 0.3830 - val_loss: 1.2630 - val_acc: 0.3785\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.2675 - acc: 0.3873 - val_loss: 1.2409 - val_acc: 0.4003\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.2632 - acc: 0.3920 - val_loss: 1.2349 - val_acc: 0.4124\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.2625 - acc: 0.3915 - val_loss: 1.2286 - val_acc: 0.4154\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.2586 - acc: 0.3960 - val_loss: 1.2305 - val_acc: 0.4257\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.2486 - acc: 0.3995 - val_loss: 1.2306 - val_acc: 0.4137\n",
      "Epoch 10/10\n",
      "1703/1703 [==============================] - 102s 60ms/step - loss: 1.2459 - acc: 0.4044 - val_loss: 1.2298 - val_acc: 0.4208\n",
      "Test score: 1.229847510281731\n",
      "Test accuracy: 0.4209558823529412\n",
      "2Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 111s 65ms/step - loss: 1.4071 - acc: 0.2497 - val_loss: 1.3862 - val_acc: 0.2489\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.3877 - acc: 0.2519 - val_loss: 1.3863 - val_acc: 0.2561\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.3870 - acc: 0.2491 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.3870 - acc: 0.2474 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 106s 62ms/step - loss: 1.3868 - acc: 0.2521 - val_loss: 1.3862 - val_acc: 0.2561\n",
      "Epoch 00005: early stopping\n",
      "Test score: 1.386242392764372\n",
      "Test accuracy: 0.2565441176470588\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.5092 - acc: 0.2688 - val_loss: 1.3697 - val_acc: 0.2869\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 1.3817 - acc: 0.2804 - val_loss: 1.3913 - val_acc: 0.2721\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 1.3825 - acc: 0.2822 - val_loss: 1.3771 - val_acc: 0.2879\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 1.3895 - acc: 0.2794 - val_loss: 1.5518 - val_acc: 0.2863\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 1.4045 - acc: 0.2502 - val_loss: 1.4077 - val_acc: 0.2587\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 1.4035 - acc: 0.2498 - val_loss: 1.3955 - val_acc: 0.2535\n",
      "Epoch 00006: early stopping\n",
      "Test score: 1.3954803259232464\n",
      "Test accuracy: 0.2539705882352941\n",
      "3Layer\n",
      "relu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 119s 70ms/step - loss: 1.4117 - acc: 0.2474 - val_loss: 1.3862 - val_acc: 0.2489\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3866 - acc: 0.2506 - val_loss: 1.3863 - val_acc: 0.2493\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3868 - acc: 0.2466 - val_loss: 1.3862 - val_acc: 0.2493\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3865 - acc: 0.2476 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2483 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2480 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3864 - acc: 0.2473 - val_loss: 1.3863 - val_acc: 0.2524\n",
      "Epoch 00007: early stopping\n",
      "Test score: 1.3862724388346952\n",
      "Test accuracy: 0.2523529411764706\n",
      "2Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 115s 68ms/step - loss: 1.3960 - acc: 0.2602 - val_loss: 1.3762 - val_acc: 0.2778\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 110s 65ms/step - loss: 1.3798 - acc: 0.2915 - val_loss: 1.3618 - val_acc: 0.3070\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 110s 65ms/step - loss: 1.3666 - acc: 0.3096 - val_loss: 1.3681 - val_acc: 0.3018\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 111s 65ms/step - loss: 1.3491 - acc: 0.3231 - val_loss: 1.3274 - val_acc: 0.3388\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 110s 65ms/step - loss: 1.3282 - acc: 0.3438 - val_loss: 1.3431 - val_acc: 0.3224\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1703/1703 [==============================] - 110s 65ms/step - loss: 1.3129 - acc: 0.3589 - val_loss: 1.2944 - val_acc: 0.3704\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 124s 73ms/step - loss: 1.3058 - acc: 0.3620 - val_loss: 1.2996 - val_acc: 0.3650\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 1.3059 - acc: 0.3646 - val_loss: 1.3254 - val_acc: 0.3474\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 110s 65ms/step - loss: 1.2986 - acc: 0.3683 - val_loss: 1.2865 - val_acc: 0.3855\n",
      "Epoch 10/10\n",
      "1703/1703 [==============================] - 110s 65ms/step - loss: 1.2956 - acc: 0.3741 - val_loss: 1.2775 - val_acc: 0.3757\n",
      "Test score: 1.277304175601286\n",
      "Test accuracy: 0.37580882352941175\n",
      "2Layer\n",
      "elu\n",
      "Adam\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 112s 66ms/step - loss: 12.0997 - acc: 0.2488 - val_loss: 7.5683 - val_acc: 0.2565\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 7.5729 - val_acc: 0.2561\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 12.1078 - acc: 0.2488 - val_loss: 7.5729 - val_acc: 0.2561\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 108s 63ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 7.5729 - val_acc: 0.2561\n",
      "Epoch 00004: early stopping\n",
      "Test score: 7.56831984576057\n",
      "Test accuracy: 0.2565441176470588\n",
      "2Layer\n",
      "relu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 120s 70ms/step - loss: 1.3916 - acc: 0.2469 - val_loss: 1.3863 - val_acc: 0.2489\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3867 - acc: 0.2489 - val_loss: 1.3862 - val_acc: 0.2524\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3866 - acc: 0.2486 - val_loss: 1.3863 - val_acc: 0.2493\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 115s 67ms/step - loss: 1.3867 - acc: 0.2548 - val_loss: 1.3814 - val_acc: 0.2711\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 115s 67ms/step - loss: 1.3841 - acc: 0.2772 - val_loss: 1.3732 - val_acc: 0.2964\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3776 - acc: 0.2877 - val_loss: 1.3681 - val_acc: 0.3060\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3716 - acc: 0.2941 - val_loss: 1.3975 - val_acc: 0.2656\n",
      "Epoch 8/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3728 - acc: 0.2907 - val_loss: 1.3788 - val_acc: 0.2717\n",
      "Epoch 9/10\n",
      "1703/1703 [==============================] - 115s 67ms/step - loss: 1.3723 - acc: 0.2904 - val_loss: 1.3629 - val_acc: 0.3171\n",
      "Epoch 10/10\n",
      "1703/1703 [==============================] - 114s 67ms/step - loss: 1.3678 - acc: 0.2952 - val_loss: 1.3591 - val_acc: 0.3287\n",
      "Test score: 1.3590730319303626\n",
      "Test accuracy: 0.3286029411764706\n",
      "2Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n",
      "1703/1703 [==============================] - 104s 61ms/step - loss: 12.1008 - acc: 0.2490 - val_loss: 5.5293 - val_acc: 0.2491\n",
      "Epoch 2/10\n",
      "1703/1703 [==============================] - 99s 58ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 5.5293 - val_acc: 0.2491\n",
      "Epoch 3/10\n",
      "1703/1703 [==============================] - 99s 58ms/step - loss: 12.1078 - acc: 0.2488 - val_loss: 5.5293 - val_acc: 0.2491\n",
      "Epoch 4/10\n",
      "1703/1703 [==============================] - 99s 58ms/step - loss: 12.1087 - acc: 0.2488 - val_loss: 5.5272 - val_acc: 0.2492\n",
      "Epoch 5/10\n",
      "1703/1703 [==============================] - 99s 58ms/step - loss: 12.1084 - acc: 0.2488 - val_loss: 5.5272 - val_acc: 0.2492\n",
      "Epoch 6/10\n",
      "1703/1703 [==============================] - 99s 58ms/step - loss: 12.1099 - acc: 0.2487 - val_loss: 5.5272 - val_acc: 0.2492\n",
      "Epoch 7/10\n",
      "1703/1703 [==============================] - 99s 58ms/step - loss: 12.1084 - acc: 0.2488 - val_loss: 5.5272 - val_acc: 0.2492\n",
      "Epoch 00007: early stopping\n",
      "Test score: 5.529260607326732\n",
      "Test accuracy: 0.24911764705882353\n",
      "3Layer\n",
      "elu\n",
      "RMSprop\n",
      "Train...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,64,184,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_226/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_293/cond/Merge, conv2d_226/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_74/mul/_24339 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_940_loss_74/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv2d_226/convolution', defined at:\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tornado\\ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-85-2d4b6f60c27e>\", line 8, in <module>\n    notebook_name='CNN_experiment4')  # Der Name des Notebooks sollte als String angegeben werden\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\n    verbose=verbose)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperas\\optim.py\", line 133, in base_minimizer\n    return_argmin=True),\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"C:\\Users\\morro\\Documents\\fahrradwegeKlassifizierung\\faltungsnetze\\temp_model.py\", line 205, in keras_fmin_fnct\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\models.py\", line 492, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3335, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 780, in convolution\n    return op(input, filter)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1039, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3309, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1669, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,184,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_226/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_293/cond/Merge, conv2d_226/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_74/mul/_24339 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_940_loss_74/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1315\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1422\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1423\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,184,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_226/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_293/cond/Merge, conv2d_226/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_74/mul/_24339 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_940_loss_74/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-2d4b6f60c27e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m                                           \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                           \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m      \u001b[1;31m# eine Liste von Verzeichnissen, die alles über die Suche enthalten.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                                           notebook_name='CNN_experiment4')  # Der Name des Notebooks sollte als String angegeben werden\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbestRun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                      verbose=verbose)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m    131\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m              return_argmin=True),\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     )\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\morro\\Documents\\fahrradwegeKlassifizierung\\faltungsnetze\\temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[1;34m(space)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1274\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1275\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1276\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 908\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    909\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1143\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1324\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1325\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1343\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1345\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,64,184,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_226/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_293/cond/Merge, conv2d_226/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_74/mul/_24339 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_940_loss_74/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'conv2d_226/convolution', defined at:\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tornado\\ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-85-2d4b6f60c27e>\", line 8, in <module>\n    notebook_name='CNN_experiment4')  # Der Name des Notebooks sollte als String angegeben werden\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperas\\optim.py\", line 67, in minimize\n    verbose=verbose)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperas\\optim.py\", line 133, in base_minimizer\n    return_argmin=True),\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 307, in fmin\n    return_argmin=return_argmin,\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\base.py\", line 635, in fmin\n    return_argmin=return_argmin)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 320, in fmin\n    rval.exhaust()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 199, in exhaust\n    self.run(self.max_evals - n_done, block_until_done=self.async)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 173, in run\n    self.serial_evaluate()\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\fmin.py\", line 92, in serial_evaluate\n    result = self.domain.evaluate(spec, ctrl)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\hyperopt\\base.py\", line 840, in evaluate\n    rval = self.fn(pyll_rval)\n  File \"C:\\Users\\morro\\Documents\\fahrradwegeKlassifizierung\\faltungsnetze\\temp_model.py\", line 205, in keras_fmin_fnct\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\models.py\", line 492, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3335, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 780, in convolution\n    return op(input, filter)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1039, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3309, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1669, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,64,184,35] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: conv2d_226/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dropout_293/cond/Merge, conv2d_226/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: loss_74/mul/_24339 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_940_loss_74/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# Die Hyperas Methode optim sucht im Suchraum die Parameter \n",
    "# Bei einer Änderung des Methodenrumpf der Methode model() muss der Notebook Kernel neu gestartet werden\n",
    "bestRun, bestModel = optim.minimize(model=model,               \n",
    "                                          data=data,\n",
    "                                          algo=rand.suggest,   # Algorithmus: Random Search\n",
    "                                          max_evals=30,          \n",
    "                                          trials=Trials(),      # eine Liste von Verzeichnissen, die alles über die Suche enthalten.\n",
    "                                          notebook_name='CNN_experiment4')  # Der Name des Notebooks sollte als String angegeben werden\n",
    "print(bestRun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
