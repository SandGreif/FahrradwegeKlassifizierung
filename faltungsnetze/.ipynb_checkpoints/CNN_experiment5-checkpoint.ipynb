{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faltungsnetz Versuch 5: Daten mit Wiederholung\n",
    "\n",
    "\n",
    "## Einleitung\n",
    "\n",
    "Bei diesem Versuch wurde wiederholt die gleiche Route mit einem Fahrrad befahren. Ziel ist es durch die Wiederholung die  befahrenen unterschiedlichen Oberflächen Typen zu reduzieren und somit eine bessere Klassifizerung zu ermöglichen. \n",
    "\n",
    "## Hypothese\n",
    "\n",
    "Durch Wiederholung bei der Datenerfassung sollte sich eine höhere Accuracy erziehlen lassen als im Faltungsnetz Versuch 4. Auf der befahrenen Route gibt es mehr Unebenheiten im Vergleich zu Datensatz 37 bis 42. Dies ermöglicht mehr Daten jeder Klasse zum Trainieren, weil mehr Daten mit hoher Erschütterung zur Verfügung stehen.  \n",
    "\n",
    "## Versuchsaufbau\n",
    "\n",
    "Eine Route im Naturschutzgebiet Höltigbaum wurde 14 Mal befahren siehe Abb. 1. Dabei setzen sich die Trainingsdaten aus den Datensätzen Nummer 43 und 45 bis 51 zusammen. Die Gesamtzahl der Bilder beträgt Stück.  \n",
    "\n",
    "<img src=\"../daten/abbildungen/karteDatensatz43_45_bis_51.png\" />\n",
    "Abbildung 1: Höltigbaum Route 14 Mal wiederholt befahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuch 5.1: 3 Fahrqualitäts Klassen\n",
    "\n",
    "#### Versuchsbeschreibung\n",
    "\n",
    "Die Daten in diesem Versuch wurden in Fuzzy Logik Versuch 6 klassifiziert. Hierbei wurde unterschieden zwischen den 3 Klassen \"gut\", \"mittel\" und \"schlecht\" nach der Fahrqualität. Dieser Versuch ist eine Wiederholung des Faltungsnetz Versuchs 4.7 mit dem Unterschied, dass wie beschrieben andere Datensätze verwendet wurden. Es wurden 20 Epochen durchgeführt.  \n",
    "\n",
    "#### Ergebnis\n",
    "\n",
    "Wie auf Abb. 3 zu sehen sieht die Konfusionsmatrix der Testdaten ähnlich wie in Versuch 4.7 aus. Die Test Accuracy siehe Tab. 5.2 ist, um $2,6\\%$ höher. Eigentlich wurde eine deutlich höhere Accuracy erwartet. Auf Tab. 1 ist die Trainingshistorie abgebildet. Durch erhöhen der Anzahl der Epochen könnte sich auch das Ergebnis verbessern.   \n",
    "  \n",
    "| | \n",
    " --- | --- |\n",
    "<img src=\"../daten/abbildungen/trainingshistorieAccuracyVersuch5_1.png\" alt=\"Konfusionmatrix von Versuch 5.1\" /> | <img src=\"../daten/abbildungen/trainingshistorieLossVersuch5_1.png\" alt=\"Konfusionmatrix von Versuch 5.1\" /> \n",
    "Abbildung 2: Accuracy l.S. und Loss r.S. des Versuchs 5.1\n",
    "\n",
    "<img src=\"../daten/abbildungen/konfmatrixVersuch5_1.png\" alt=\"Konfusionmatrix von Versuch 5.1\" /> \n",
    "Abbildung 3: Konfusionmatrix von Versuch 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuch 5.2: Binäre Anzahl an Klassen\n",
    "\n",
    "### Versuchsbeschreibung\n",
    "\n",
    "In diesem Versuch wurde der Versuch 4.8 wiederholt nur mit den Datensätzen 43 und 45 bis 51. Auch hier wurde erwartet das die Test Accuracy höher ist als im Versuch 4.8. Bei den Versuch gibt es zwei Klassen \"gute\" oder \"schlechte\" Fahrqualität.\n",
    "\n",
    "### Ergebnis\n",
    "\n",
    "Auf Tab. 1 ist zu sehen, dass die Test Accuracy mit $87,5\\%$ deutlich höher ist als im Versuch  4.8 mit $78,7\\%$. Dies sollte daran liegen, dass die Anzahl der Trainingsdaten höher ist und eine Route wiederholt befahren  wurde. \n",
    "\n",
    "<img src=\"../daten/abbildungen/konfmatrixVersuch5_2.png\" alt=\"Konfusionmatrix von Versuch 5.2\" /> \n",
    "Abbildung 2: Konfusionsmatrix von Versuch 5.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versuch 5.3: Hypertuning mit 3 Klassen\n",
    "\n",
    "#### Hypothese\n",
    "\n",
    "Die Hypothese war, dass durch anpassen der Parameter eine höhere Test Accuracy erreicht werden kann als in Versuch 5.2 (siehe Tab. 1). \n",
    "\n",
    "#### Versuchsbeschreibung\n",
    "\n",
    "In diesem Versuch wurde nochmal nach bessere Parametern für das Modell aus Versuch 4.4 gesucht mit Hyperas. Die Daten wurden in Fuzzy Logik Versuch 6 gelabelt. Dabei wurde wie in Versuch 4.3 die Dropout Rate, die Anzahl der Faltungsschichten bei diesem Versuch von 3 bis 5 und die Optimierungsfunktion sowie weitere Parameter mit Hyperopt gesucht. Die Anzahl an Durchläufe mit Hyperopt waren 100-mal.\n",
    "\n",
    "\n",
    "\n",
    "#### Ergebnis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisse\n",
    "\n",
    "Versuch Nr. | Trainings Accuracy | Trainings Loss | Validierungs Accuracy | Validierungs Loss | Test Accuracy | Test Loss \n",
    "--- | --- | --- | --- | --- \n",
    "5.1   | 0.5524 | 0.9188 | 0.6030 | 0.8369 | 0.5939 | 0.8477\n",
    "5.2   | 0.8426 | 0.3926 | 0.8766 | 0.3584 | 0.875  | 0.3552\n",
    "Tabelle 1: Ergebnisse ver Versuche  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T14:38:15.558538Z",
     "start_time": "2018-07-10T14:38:11.786563Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, rand\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import uniform, choice\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T14:38:15.646524Z",
     "start_time": "2018-07-10T14:38:15.597681Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras import initializers\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import load_model\n",
    "import keras.callbacks as cb\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDf = pandas.read_csv(filepath_or_buffer=\"../daten/merkmale_datensatz_43_45_bis_51/merkmaleMitLabelnFuzzyVersuch6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nummer des aktuellen Versuchs\n",
    "experimentNumber = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier können die Datensätze ausgewählt werden\n",
    "datasets = ['43','45','46','47','48','49','50','51']\n",
    "# Die Pfade zu den Ordnern in welchem sich die Bilder befinden\n",
    "paths = []\n",
    "# Liste mit Pfaden zu den Bildern\n",
    "imagePaths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/bachelor/daten/43/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "E:/bachelor/daten/45/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "E:/bachelor/daten/46/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "Ordner der geladen wird: 11\n",
      "E:/bachelor/daten/47/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "E:/bachelor/daten/48/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "E:/bachelor/daten/49/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "E:/bachelor/daten/50/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "E:/bachelor/daten/51/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for dataset in datasets: # Für jeden Datensatz merke Pfad\n",
    "    paths.append(\"E:/bachelor/daten/\" + dataset + \"/zugeschnitten/\")\n",
    "for path in paths: # Für jeden Pfad hole die Namen der Ordner\n",
    "    folders = os.listdir(path)\n",
    "    folders = sorted(folders, key=int) #sortiert die Reihenfolge de Ordner aufsteifend\n",
    "    print(path)\n",
    "    print(\"Bilder aus folgenden Ordnern werden geladen: \" + str(folders))\n",
    "    for folder in folders: # Aus der Liste der Ordner wird ein Ordner ausgewählt\n",
    "        filesPath = path + folder + \"/\"\n",
    "        files = os.listdir(filesPath)\n",
    "        print(\"Ordner der geladen wird: \" + str(folder))\n",
    "        for name in files: # Ein Dateiname aus diesem Ordner\n",
    "            if \"jpg\" not in name:\n",
    "                continue\n",
    "            if featuresDf['Klasse'].iloc[i] != 1: \n",
    "                imagePaths.append(filesPath + name)\n",
    "            i = i + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "classNames = ['gut','schlecht'] # Namen der Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23401\n",
       "1    22536\n",
       "Name: Klasse, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDf[\"Klasse\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDf = featuresDf[featuresDf['Klasse'] != 1]\n",
    "featuresDf[featuresDf['Klasse'] == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLabels = np_utils.to_categorical(featuresDf[\"Klasse\"], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzten des RandomState um reproduzierbare Ergebnisse zu erzielen.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mischen der Trainingsdaten\n",
    "xShuffle, yShuffle = shuffle(imagePaths,yLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22536"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Zelle Normiert die Anzahl der Repräsentanten pro Klasse\n",
    "class1Number = 0\n",
    "class2Number = 0 \n",
    "class3Number = 0\n",
    "maxClasses = featuresDf[\"Klasse\"].value_counts().min()\n",
    "indexToDelete = [] \n",
    "i = -1\n",
    "for label in yShuffle:\n",
    "    i = i + 1\n",
    "    labelNumber = np.argmax(label,axis=0)\n",
    "    if labelNumber == 0 and class1Number < maxClasses:\n",
    "        class1Number = class1Number + 1\n",
    "        continue\n",
    "    elif labelNumber == 0:\n",
    "        indexToDelete.append(i)\n",
    "    if labelNumber == 1 and class2Number < maxClasses:\n",
    "        class2Number = class2Number + 1\n",
    "        continue\n",
    "    elif labelNumber == 1:\n",
    "        indexToDelete.append(i)\n",
    "    if labelNumber == 2 and class3Number < maxClasses:\n",
    "        class3Number = class3Number + 1\n",
    "        continue\n",
    "    elif labelNumber == 2:\n",
    "        indexToDelete.append(i)\n",
    "    if labelNumber == 3 and class4Number < maxClasses:\n",
    "        class4Number = class4Number + 1\n",
    "        continue        \n",
    "xShuffle = [i for j, i in enumerate(xShuffle) if j not in indexToDelete]\n",
    "yShuffle = [i for j, i in enumerate(yShuffle) if j not in indexToDelete]\n",
    "yShuffle = np.asarray(yShuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mischen der Trainingsdaten\n",
    "xShuffle, yShuffle = shuffle(xShuffle,yShuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilung in Trainings, Validation und Testdaten\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(xShuffle, yShuffle, test_size=0.10)\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 16216, 1: 16235})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(np.argmax(yTrain, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diese Funktion läd Bilder in den Hauptspeicher\n",
    "# imagesPaths: Liste mit Pfaden zu den Bildern != null\n",
    "def imageLoader(imagePaths):\n",
    "    images = []\n",
    "    for path in imagePaths:\n",
    "        images.append(cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB))\n",
    "    imagesNp = np.array(images)\n",
    "    imagesNp = imagesNp.astype('float32')\n",
    "    # Transfomierung der Bildpunkte auf den Wetebereich von 0 bis 1\n",
    "    imagesNp /= 255\n",
    "    return imagesNp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Läd Trainingsdaten in batches\n",
    "def dataLoader(imagePaths, features, batchSize):\n",
    "    imagesCount = len(imagePaths)  \n",
    "    while True:\n",
    "        batchStart = 0\n",
    "        batchEnd = batchSize\n",
    "        while batchStart < imagesCount:\n",
    "            limit = min(batchEnd, imagesCount)\n",
    "            x = imageLoader(imagePaths[batchStart:limit])\n",
    "            y = features[batchStart:limit]\n",
    "            yield (x,y) \n",
    "            batchStart += batchSize   \n",
    "            batchEnd += batchSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter für das CNN\n",
    "inputShape     = (368, 70, 3)   # Eingangs Array-Form \n",
    "numNeuronsC1   = 32                # Anzahl der Filter / 1 Faltungsschicht\n",
    "numNeuronsC2   = 32                # Anzahl der Filter / 2 Faltungsschicht\n",
    "numNeuronsC3   = 64                # Anzahl der Filter / 3 Faltungsschicht\n",
    "numNeuronsC4   = 256\n",
    "numNeuronsD1   = 64                # Anzahl der Neuronen des Fully connected layer - vollverbundene Schicht\n",
    "poolSize       = 2                 # Größe der Pooling-Layer\n",
    "convKernelSize = 3                 # Größe des Faltungskern n*n\n",
    "batchSize      = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2028/2028 [==============================] - 145s 72ms/step - loss: 4.0808 - acc: 0.5422 - val_loss: 0.5906 - val_acc: 0.7427\n",
      "Epoch 2/20\n",
      "2028/2028 [==============================] - 143s 71ms/step - loss: 0.5358 - acc: 0.7367 - val_loss: 0.3807 - val_acc: 0.8465\n",
      "Epoch 3/20\n",
      "2028/2028 [==============================] - 143s 71ms/step - loss: 0.4305 - acc: 0.8187 - val_loss: 0.3783 - val_acc: 0.8481\n",
      "Epoch 4/20\n",
      "2028/2028 [==============================] - 143s 71ms/step - loss: 0.4075 - acc: 0.8341 - val_loss: 0.3718 - val_acc: 0.8528\n",
      "Epoch 5/20\n",
      "2028/2028 [==============================] - 146s 72ms/step - loss: 0.4020 - acc: 0.8380 - val_loss: 0.3409 - val_acc: 0.8706\n",
      "Epoch 6/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3926 - acc: 0.8426 - val_loss: 0.3584 - val_acc: 0.8766\n",
      "Epoch 7/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3883 - acc: 0.8476 - val_loss: 0.5014 - val_acc: 0.8417\n",
      "Epoch 8/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3873 - acc: 0.8477 - val_loss: 0.3657 - val_acc: 0.8633\n",
      "Epoch 9/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3800 - acc: 0.8495 - val_loss: 0.4781 - val_acc: 0.8556\n",
      "Epoch 10/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3830 - acc: 0.8497 - val_loss: 0.3652 - val_acc: 0.8675\n",
      "Epoch 11/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3822 - acc: 0.8518 - val_loss: 0.5235 - val_acc: 0.8234\n",
      "Epoch 12/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3805 - acc: 0.8499 - val_loss: 0.4839 - val_acc: 0.8703\n",
      "Epoch 13/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3836 - acc: 0.8504 - val_loss: 0.3619 - val_acc: 0.8581\n",
      "Epoch 14/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3815 - acc: 0.8517 - val_loss: 0.3412 - val_acc: 0.8704\n",
      "Epoch 15/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3773 - acc: 0.8524 - val_loss: 0.5151 - val_acc: 0.8534\n",
      "Epoch 16/20\n",
      "2028/2028 [==============================] - 144s 71ms/step - loss: 0.3800 - acc: 0.8492 - val_loss: 0.5943 - val_acc: 0.8446\n",
      "Epoch 00016: early stopping\n",
      "Test score: 0.619245771842\n",
      "Test accuracy: 0.844306049822\n"
     ]
    }
   ],
   "source": [
    "modelCNN = Sequential()\n",
    "modelCNN.add(Conv2D(numNeuronsC1, (convKernelSize, convKernelSize), padding='same', input_shape=inputShape,kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "modelCNN.add(Activation(\"elu\"))\n",
    "modelCNN.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "modelCNN.add(Dropout(0.11))\n",
    "modelCNN.add(Conv2D(numNeuronsC2, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "modelCNN.add(Activation(\"elu\"))\n",
    "modelCNN.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "modelCNN.add(Dropout(0.38))\n",
    "modelCNN.add(Conv2D(numNeuronsC3, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "modelCNN.add(Activation(\"elu\"))\n",
    "modelCNN.add(MaxPooling2D(pool_size=(poolSize, poolSize)))       \n",
    "modelCNN.add(Dropout(0.30))\n",
    "modelCNN.add(Conv2D(numNeuronsC4, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "modelCNN.add(Activation(\"elu\"))\n",
    "modelCNN.add(MaxPooling2D(pool_size=(poolSize, poolSize)))       \n",
    "modelCNN.add(Dropout(0.49))\n",
    "modelCNN.add(Flatten())\n",
    "modelCNN.add(Dense(numNeuronsD1, kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "modelCNN.add(Activation(\"elu\"))\n",
    "modelCNN.add(Dropout(0.36)) \n",
    "modelCNN.add(Dense(2, kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "modelCNN.add(Activation('softmax'))\n",
    "            \n",
    "modelCNN.compile(loss='categorical_crossentropy', optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "earlyStopping  = cb.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')\n",
    "checkpointSafe = cb.ModelCheckpoint('ergebnisse_versuch5/modell_versuch5_' + experimentNumber, monitor='val_acc', save_best_only=True)   \n",
    "hist = modelCNN.fit_generator(dataLoader(xTrain, yTrain, batchSize), epochs=20, steps_per_epoch=(int(len(xTrain)/batchSize)),\n",
    "              validation_data=dataLoader(xVal, yVal, batchSize), validation_steps=(int(len(xVal)/batchSize)), callbacks=[earlyStopping,checkpointSafe])\n",
    "\n",
    "score, acc = modelCNN.evaluate_generator( dataLoader(xTest, yTest, batchSize), steps=(int(len(xTest)/batchSize)))\n",
    "print('Test score: '    +  str(score))\n",
    "print('Test accuracy: ' +  str(acc)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Modell Historie Loss und Accuracy\n",
    "plt.figure(1)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Trainingshistorie: Loss')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['Training', 'Validation'])\n",
    "plt.xlim(0,15)\n",
    "plt.grid(True)\n",
    "plt.savefig(\"trainingshistorieLossVersuch5_\" + experimentNumber + \".png\")\n",
    "plt.xticks(np.arange(0, 15.1, step=1))\n",
    "plt.figure(2)\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Trainingshistorie: Accuracy')\n",
    "plt.xticks()\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.legend(['Training', 'Validation'], loc='right')\n",
    "plt.xlim(0,15)\n",
    "plt.xticks(np.arange(0, 15.1, step=1))\n",
    "plt.grid(True)\n",
    "plt.savefig(\"trainingshistorieAccuracyVersuch5_\" + experimentNumber + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Läd Modell\n",
    "modell1 = load_model('ergebnisse_versuch5/modell_versuch5_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35521340508053734, 0.875]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modell1.evaluate_generator( dataLoader(xTest, yTest, 16), steps=int(len(xTest)/16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bei der Verwendung von predict_generator werden die daten gemischt \n",
    "validPreds = []\n",
    "imageList = []\n",
    "for path in xTest:\n",
    "    imageList = []   \n",
    "    img = cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB)\n",
    "    img = np.array(img)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255\n",
    "    imageList.append(img)\n",
    "    validPreds.append(modell1.predict(np.asarray(imageList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2044  162]\n",
      " [ 400 1902]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Konfusionsmatrix\n",
    "validPredArray = np.argmax(np.vstack(validPreds), axis=1)\n",
    "yTestMax = np.argmax(yTest,axis=1)\n",
    "cnfMatrix = confusion_matrix(yTestMax, validPredArray)\n",
    "print(cnfMatrix)\n",
    "fig, ax = plt.subplots(figsize=(6,6)) \n",
    "ax = sns.heatmap(cnfMatrix, fmt=\"d\", cmap=plt.cm.Blues, ax=ax , annot=True)\n",
    "ax.set_xticklabels(classNames)\n",
    "ax.set_yticklabels(classNames)\n",
    "plt.title('Konfusionsmatrix Versuch 5.2')\n",
    "plt.ylabel('Wahre Klasse')\n",
    "plt.xlabel('Vorhergesagte Klasse')\n",
    "plt.savefig('konfmatrixVersuch5_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T14:38:30.844033Z",
     "start_time": "2018-07-10T14:38:30.808651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Eine Funktion die das zu optimierende Keras-Modell beschreibt\n",
    "# Die vorgehensweise mit einer Funktion ist nach der Dokumentation von Hyperas vorgegeben \n",
    "# siehe https://github.com/maxpumperla/hyperas\n",
    "def model(xTrain, xVal, yTrain, yVal):\n",
    "    # Parameter für das CNN\n",
    "    inputShape     = (368, 70, 3)   # Eingangs Array-Form \n",
    "    numNeuronsC1   = 32                # Anzahl der Filter / 1 Faltungsschicht\n",
    "    poolSize       = 2                 # Größe der Pooling-Layer\n",
    "    convKernelSize = 3                 # Größe des Faltungskern n*n\n",
    "    batchSize      = {{choice([8, 16, 32])}}\n",
    "    print(\"Stapelgroesse (batchSize): \" + str(batchSize))\n",
    "    \n",
    "    model = Sequential()\n",
    "    layerCountTuning = {{choice(['3Layer','4Layer','5Layer'])}}\n",
    "    print(\"Anzahl der Faltungsschichten: \" + layerCountTuning)\n",
    "    af = {{choice(['relu', 'elu'])}}\n",
    "    print(\"Aktivierungsfunktion: \" + af)\n",
    "    optf = {{choice(['RMSprop','Adam'])}}\n",
    "    print(\"Optimierungsfunktion: \" + optf)\n",
    "    model.add(Conv2D(numNeuronsC1, (convKernelSize, convKernelSize), padding='same', input_shape=inputShape,kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "    model.add(Activation(af))\n",
    "    model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "    dropoutrate1 = {{uniform(0, 0.70)}}\n",
    "    print(\"Dropout-Rate Faltungsschicht 1: \" + str(dropoutrate1))\n",
    "    model.add(Dropout(dropoutrate1))\n",
    "    \n",
    "    filterCount2 = {{choice([32, 64])}}\n",
    "    print(\"Anzahl der Filter-Maps Faltungsschicht 2: \" + str(filterCount2))\n",
    "    model.add(Conv2D(filterCount2, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "    model.add(Activation(af))\n",
    "    model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "    dropoutrate2 = {{uniform(0, 0.70)}}        \n",
    "    print(\"Dropout-Rate Faltungsschicht 2: \" + str(dropoutrate2))\n",
    "    model.add(Dropout(dropoutrate2))\n",
    "    \n",
    "    if layerCountTuning == '3Layer' or layerCountTuning == '4Layer' or layerCountTuning == '5Layer':\n",
    "        print(\"Anzahl der Faltungsschichten: \" + layerCountTuning)\n",
    "        filterCount3 = {{choice([64, 128])}}\n",
    "        print(\"Anzahl der Filter-Maps Faltungsschicht 3: \" + str(filterCount3))\n",
    "        model.add(Conv2D(filterCount3, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "        model.add(Activation(af))\n",
    "        model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "        dropoutrate3 = {{uniform(0, 0.70)}}        \n",
    "        print(\"Dropout-Rate Faltungsschicht 3: \" + str(dropoutrate3))\n",
    "        model.add(Dropout(dropoutrate3))\n",
    "\n",
    "    if layerCountTuning == '4Layer' or layerCountTuning == '5Layer':\n",
    "        filterCount4 = {{choice([64, 128])}}\n",
    "        print(\"Anzahl der Filter-Maps Faltungsschicht 4: \" + str(filterCount4))\n",
    "        model.add(Conv2D(filterCount4, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "        model.add(Activation(af))\n",
    "        model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "        dropoutrate4 = {{uniform(0, 0.70)}}        \n",
    "        print(\"Dropout-Rate Faltungsschicht 4: \" + str(dropoutrate4))\n",
    "        model.add(Dropout(dropoutrate4)) \n",
    "    \n",
    "    if layerCountTuning == '5Layer':\n",
    "        filterCount5 = {{choice([64, 128])}}\n",
    "        print(\"Anzahl der Filter-Maps Faltungsschicht 5: \" + str(filterCount5))\n",
    "        model.add(Conv2D(filterCount5, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "        model.add(Activation(af))\n",
    "        model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
    "        dropoutrate5 = {{uniform(0, 0.70)}}        \n",
    "        print(\"Dropout-Rate Faltungsschicht 5: \" + str(dropoutrate5))\n",
    "        model.add(Dropout(dropoutrate5)) \n",
    "\n",
    "    model.add(Flatten())\n",
    "    dims4 = {{choice([64, 128])}}\n",
    "    print(\"Anzahl der Neuronen des Fully Connected Layer: \" + str(dims4))    \n",
    "    model.add(Dense(dims4, kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "    model.add(Activation(af))\n",
    "    dropoutFull = {{uniform(0, 0.70)}}  \n",
    "    print(\"Dropout-Rate Fully Connected Layer: \" + str(dropoutFull))\n",
    "    model.add(Dropout(dropoutFull)) \n",
    "    model.add(Dense(3, kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # Diese Funktion läd Bilder in den Hauptspeicher\n",
    "    # imagesPaths: Liste mit Pfaden zu den Bildern != null\n",
    "    def imageLoader(imagePaths):\n",
    "        images = []\n",
    "        for path in imagePaths:\n",
    "            images.append(cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB))    \n",
    "        imagesNp = np.array(images)\n",
    "        imagesNp = imagesNp.astype('float32')\n",
    "        imagesNp /= 255\n",
    "        return imagesNp\n",
    "\n",
    "    # Läd Trainingsdaten in batches\n",
    "    def dataLoader(imagePaths, features, batchSize):\n",
    "        imagesCount= len(imagePaths)  \n",
    "        while True:\n",
    "            batchStart = 0\n",
    "            batchEnd = batchSize\n",
    "            while batchStart < imagesCount:\n",
    "                limit = min(batchEnd, imagesCount)\n",
    "                x = imageLoader(imagePaths[batchStart:limit])\n",
    "                y = features[batchStart:limit]\n",
    "                yield (x,y) \n",
    "                batchStart += batchSize   \n",
    "                batchEnd += batchSize\n",
    "                \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optf, metrics=[\"accuracy\"])\n",
    "    print('Faltungsnetz wird trainiert...')\n",
    "    # Early Stopping unterbricht das Training, wenn nach 10 Epochen die Kostenfunktion nicht weiter minimiert werden konnte \n",
    "    earlyStopping = cb.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')\n",
    "    checkpointSafe = cb.ModelCheckpoint('ergebnisse_versuch5/modell_versuch5_3', monitor='val_acc', save_best_only=True)   \n",
    "    model.fit_generator(dataLoader(xTrain, yTrain, batchSize), epochs=10, steps_per_epoch=(int(len(xTrain)/batchSize)),\n",
    "              validation_data=dataLoader(xVal, yVal, batchSize), validation_steps=(int(len(xVal)/batchSize)), callbacks=[earlyStopping,checkpointSafe])\n",
    "    score, acc = model.evaluate_generator( dataLoader(xVal, yVal, batchSize), steps=(int(len(xVal)/batchSize)))\n",
    "    print('Test score: ' + str(score))\n",
    "    print('Test accuracy: ' +  str(acc))\n",
    "    # Die Rückgabewerte werden verarbeitet von Hyperas\n",
    "    # loss ist die Kostenfunktion welche minimiert werden soll mit Hyperas\n",
    "    # status (STATUS_OK) gibt an das, dass Modell erfolgreich ausgeführt wurde\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T14:38:31.644985Z",
     "start_time": "2018-07-10T14:38:31.632990Z"
    }
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "    # Hier können die Datensätze ausgewählt werden\n",
    "    datasets = ['43','45','46','47','48','49','50','51']\n",
    "    # Die Pfade zu den Ordnern in welchem sich die Bilder befinden\n",
    "    paths = []\n",
    "    # Liste mit Pfaden zu den Bildern\n",
    "    imagePaths = []\n",
    "    for dataset in datasets: # Für jeden Datensatz merke Pfad\n",
    "        paths.append(\"C:/Users/morro/Documents/datenRoh/\" + dataset + \"/zugeschnitten/\")\n",
    "    for path in paths: # Für jeden Pfad hole die Namen der Ordner\n",
    "        folders = os.listdir(path)\n",
    "        folders = sorted(folders, key=int) #sortiert die Reihenfolge de Ordner aufsteifend\n",
    "        print(path)\n",
    "        print(\"Bilder aus folgenden Ordnern werden geladen: \" + str(folders))\n",
    "        for folder in folders: # Aus der Liste der Ordner wird ein Ordner ausgewählt\n",
    "            filesPath = path + folder + \"/\"\n",
    "            files = os.listdir(filesPath)\n",
    "            print(\"Ordner der geladen wird: \" + str(folder))\n",
    "            for name in files: # Ein Dateiname aus diesem Ordner\n",
    "                if \"jpg\" not in name:\n",
    "                    continue\n",
    "                imagePaths.append(filesPath + name)\n",
    "    # Y Klassen Labels zuweisen\n",
    "    featuresDf = pandas.read_csv(filepath_or_buffer=\"../daten/merkmale_datensatz_43_45_bis_51/merkmaleMitLabelnFuzzyVersuch6.csv\")\n",
    "    yLabels = np_utils.to_categorical(featuresDf['Klasse'], 0)\n",
    "    # Setzten des RandomState um reproduzierbare Ergebnisse zu erzielen.\n",
    "    np.random.seed(42)\n",
    "    # Mischen der Trainingsdaten\n",
    "    xShuffle, yShuffle = shuffle(imagePaths,yLabels)\n",
    "    class1Number = 0\n",
    "    class2Number = 0 \n",
    "    class3Number = 0\n",
    "    class4Number = 0\n",
    "    class5Number = 0\n",
    "    class6Number = 0\n",
    "    class7Number = 0\n",
    "    class8Number = 0\n",
    "    maxClasses = featuresDf[\"Klasse\"].value_counts().min()\n",
    "    indexToDelete = [] \n",
    "    i = -1\n",
    "    for label in yShuffle:\n",
    "        i = i + 1\n",
    "        labelNumber = np.argmax(label,axis=0)\n",
    "        if labelNumber == 0 and class1Number < maxClasses:\n",
    "            class1Number = class1Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 0:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 1 and class2Number < maxClasses:\n",
    "            class2Number = class2Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 1:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 2 and class3Number < maxClasses:\n",
    "            class3Number = class3Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 2:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 3 and class4Number < maxClasses:\n",
    "            class4Number = class4Number + 1\n",
    "            continue        \n",
    "        elif labelNumber == 3:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 4 and class5Number < maxClasses:\n",
    "            class5Number = class5Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 4:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 5 and class6Number < maxClasses:\n",
    "            class6Number = class6Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 5:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 6 and class7Number < maxClasses:\n",
    "            class7Number = class7Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 6:\n",
    "            indexToDelete.append(i)\n",
    "        if labelNumber == 7 and class8Number < maxClasses:\n",
    "            class8Number = class8Number + 1\n",
    "            continue\n",
    "        elif labelNumber == 7:\n",
    "            indexToDelete.append(i)\n",
    "\n",
    "    xShuffle = [i for j, i in enumerate(xShuffle) if j not in indexToDelete]\n",
    "    yShuffle = [i for j, i in enumerate(yShuffle) if j not in indexToDelete]\n",
    "    yShuffle = np.asarray(yShuffle)\n",
    "    xShuffle, yShuffle = shuffle(xShuffle,yShuffle)\n",
    "    # Aufteilung in Trainings und Testdaten\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(xShuffle, yShuffle, test_size=0.1)\n",
    "    xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.2)\n",
    "    return xTrain, xVal, yTrain, yVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-07-10T14:38:32.507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, rand\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform, choice\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.lines as mlines\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from mpl_toolkits.axes_grid1 import ImageGrid\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import cv2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import initializers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import load_model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras.callbacks as cb\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.utils import shuffle\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import collections\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'batchSize': hp.choice('batchSize', [8, 16, 32]),\n",
      "        'layerCountTuning': hp.choice('layerCountTuning', ['3Layer','4Layer','5Layer']),\n",
      "        'af': hp.choice('af', ['relu', 'elu']),\n",
      "        'optf': hp.choice('optf', ['RMSprop','Adam']),\n",
      "        'dropoutrate1': hp.uniform('dropoutrate1', 0, 0.70),\n",
      "        'filterCount2': hp.choice('filterCount2', [32, 64]),\n",
      "        'dropoutrate1_1': hp.uniform('dropoutrate1_1', 0, 0.70),\n",
      "        'filterCount3': hp.choice('filterCount3', [64, 128]),\n",
      "        'dropoutrate1_2': hp.uniform('dropoutrate1_2', 0, 0.70),\n",
      "        'filterCount3_1': hp.choice('filterCount3_1', [64, 128]),\n",
      "        'dropoutrate1_3': hp.uniform('dropoutrate1_3', 0, 0.70),\n",
      "        'filterCount3_2': hp.choice('filterCount3_2', [64, 128]),\n",
      "        'dropoutrate1_4': hp.uniform('dropoutrate1_4', 0, 0.70),\n",
      "        'filterCount3_3': hp.choice('filterCount3_3', [64, 128]),\n",
      "        'dropoutrate1_5': hp.uniform('dropoutrate1_5', 0, 0.70),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: # Hier können die Datensätze ausgewählt werden\n",
      "   3: datasets = ['43','45','46','47','48','49','50','51']\n",
      "   4: # Die Pfade zu den Ordnern in welchem sich die Bilder befinden\n",
      "   5: paths = []\n",
      "   6: # Liste mit Pfaden zu den Bildern\n",
      "   7: imagePaths = []\n",
      "   8: for dataset in datasets: # Für jeden Datensatz merke Pfad\n",
      "   9:     paths.append(\"C:/Users/morro/Documents/datenRoh/\" + dataset + \"/zugeschnitten/\")\n",
      "  10: for path in paths: # Für jeden Pfad hole die Namen der Ordner\n",
      "  11:     folders = os.listdir(path)\n",
      "  12:     folders = sorted(folders, key=int) #sortiert die Reihenfolge de Ordner aufsteifend\n",
      "  13:     print(path)\n",
      "  14:     print(\"Bilder aus folgenden Ordnern werden geladen: \" + str(folders))\n",
      "  15:     for folder in folders: # Aus der Liste der Ordner wird ein Ordner ausgewählt\n",
      "  16:         filesPath = path + folder + \"/\"\n",
      "  17:         files = os.listdir(filesPath)\n",
      "  18:         print(\"Ordner der geladen wird: \" + str(folder))\n",
      "  19:         for name in files: # Ein Dateiname aus diesem Ordner\n",
      "  20:             if \"jpg\" not in name:\n",
      "  21:                 continue\n",
      "  22:             imagePaths.append(filesPath + name)\n",
      "  23: # Y Klassen Labels zuweisen\n",
      "  24: featuresDf = pandas.read_csv(filepath_or_buffer=\"../daten/merkmale_datensatz_43_45_bis_51/merkmaleMitLabelnFuzzyVersuch6.csv\")\n",
      "  25: yLabels = np_utils.to_categorical(featuresDf['Klasse'], 0)\n",
      "  26: # Setzten des RandomState um reproduzierbare Ergebnisse zu erzielen.\n",
      "  27: np.random.seed(42)\n",
      "  28: # Mischen der Trainingsdaten\n",
      "  29: xShuffle, yShuffle = shuffle(imagePaths,yLabels)\n",
      "  30: class1Number = 0\n",
      "  31: class2Number = 0 \n",
      "  32: class3Number = 0\n",
      "  33: class4Number = 0\n",
      "  34: class5Number = 0\n",
      "  35: class6Number = 0\n",
      "  36: class7Number = 0\n",
      "  37: class8Number = 0\n",
      "  38: maxClasses = featuresDf[\"Klasse\"].value_counts().min()\n",
      "  39: indexToDelete = [] \n",
      "  40: i = -1\n",
      "  41: for label in yShuffle:\n",
      "  42:     i = i + 1\n",
      "  43:     labelNumber = np.argmax(label,axis=0)\n",
      "  44:     if labelNumber == 0 and class1Number < maxClasses:\n",
      "  45:         class1Number = class1Number + 1\n",
      "  46:         continue\n",
      "  47:     elif labelNumber == 0:\n",
      "  48:         indexToDelete.append(i)\n",
      "  49:     if labelNumber == 1 and class2Number < maxClasses:\n",
      "  50:         class2Number = class2Number + 1\n",
      "  51:         continue\n",
      "  52:     elif labelNumber == 1:\n",
      "  53:         indexToDelete.append(i)\n",
      "  54:     if labelNumber == 2 and class3Number < maxClasses:\n",
      "  55:         class3Number = class3Number + 1\n",
      "  56:         continue\n",
      "  57:     elif labelNumber == 2:\n",
      "  58:         indexToDelete.append(i)\n",
      "  59:     if labelNumber == 3 and class4Number < maxClasses:\n",
      "  60:         class4Number = class4Number + 1\n",
      "  61:         continue        \n",
      "  62:     elif labelNumber == 3:\n",
      "  63:         indexToDelete.append(i)\n",
      "  64:     if labelNumber == 4 and class5Number < maxClasses:\n",
      "  65:         class5Number = class5Number + 1\n",
      "  66:         continue\n",
      "  67:     elif labelNumber == 4:\n",
      "  68:         indexToDelete.append(i)\n",
      "  69:     if labelNumber == 5 and class6Number < maxClasses:\n",
      "  70:         class6Number = class6Number + 1\n",
      "  71:         continue\n",
      "  72:     elif labelNumber == 5:\n",
      "  73:         indexToDelete.append(i)\n",
      "  74:     if labelNumber == 6 and class7Number < maxClasses:\n",
      "  75:         class7Number = class7Number + 1\n",
      "  76:         continue\n",
      "  77:     elif labelNumber == 6:\n",
      "  78:         indexToDelete.append(i)\n",
      "  79:     if labelNumber == 7 and class8Number < maxClasses:\n",
      "  80:         class8Number = class8Number + 1\n",
      "  81:         continue\n",
      "  82:     elif labelNumber == 7:\n",
      "  83:         indexToDelete.append(i)\n",
      "  84: \n",
      "  85: xShuffle = [i for j, i in enumerate(xShuffle) if j not in indexToDelete]\n",
      "  86: yShuffle = [i for j, i in enumerate(yShuffle) if j not in indexToDelete]\n",
      "  87: yShuffle = np.asarray(yShuffle)\n",
      "  88: xShuffle, yShuffle = shuffle(xShuffle,yShuffle)\n",
      "  89: # Aufteilung in Trainings und Testdaten\n",
      "  90: xTrain, xTest, yTrain, yTest = train_test_split(xShuffle, yShuffle, test_size=0.1)\n",
      "  91: xTrain, xVal, yTrain, yVal = train_test_split(xTrain, yTrain, test_size=0.2)\n",
      "  92: \n",
      "  93: \n",
      "  94: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     # Parameter für das CNN\n",
      "   4:     inputShape     = (368, 70, 3)   # Eingangs Array-Form \n",
      "   5:     numNeuronsC1   = 32                # Anzahl der Filter / 1 Faltungsschicht\n",
      "   6:     poolSize       = 2                 # Größe der Pooling-Layer\n",
      "   7:     convKernelSize = 3                 # Größe des Faltungskern n*n\n",
      "   8:     batchSize      = space['batchSize']\n",
      "   9:     print(\"Stapelgroesse (batchSize): \" + str(batchSize))\n",
      "  10:     \n",
      "  11:     model = Sequential()\n",
      "  12:     layerCountTuning = space['layerCountTuning']\n",
      "  13:     print(\"Anzahl der Faltungsschichten: \" + layerCountTuning)\n",
      "  14:     af = space['af']\n",
      "  15:     print(\"Aktivierungsfunktion: \" + af)\n",
      "  16:     optf = space['optf']\n",
      "  17:     print(\"Optimierungsfunktion: \" + optf)\n",
      "  18:     model.add(Conv2D(numNeuronsC1, (convKernelSize, convKernelSize), padding='same', input_shape=inputShape,kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
      "  19:     model.add(Activation(af))\n",
      "  20:     model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  21:     dropoutrate1 = space['dropoutrate1']\n",
      "  22:     print(\"Dropout-Rate Faltungsschicht 1: \" + str(dropoutrate1))\n",
      "  23:     model.add(Dropout(dropoutrate1))\n",
      "  24:     \n",
      "  25:     filterCount2 = space['filterCount2']\n",
      "  26:     print(\"Anzahl der Filter-Maps Faltungsschicht 2: \" + str(filterCount2))\n",
      "  27:     model.add(Conv2D(filterCount2, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
      "  28:     model.add(Activation(af))\n",
      "  29:     model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  30:     dropoutrate2 = space['dropoutrate1_1']        \n",
      "  31:     print(\"Dropout-Rate Faltungsschicht 2: \" + str(dropoutrate2))\n",
      "  32:     model.add(Dropout(dropoutrate2))\n",
      "  33:     \n",
      "  34:     if layerCountTuning == '3Layer' or layerCountTuning == '4Layer' or layerCountTuning == '5Layer':\n",
      "  35:         print(\"Anzahl der Faltungsschichten: \" + layerCountTuning)\n",
      "  36:         filterCount3 = space['filterCount3']\n",
      "  37:         print(\"Anzahl der Filter-Maps Faltungsschicht 3: \" + str(filterCount3))\n",
      "  38:         model.add(Conv2D(filterCount3, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
      "  39:         model.add(Activation(af))\n",
      "  40:         model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  41:         dropoutrate3 = space['dropoutrate1_2']        \n",
      "  42:         print(\"Dropout-Rate Faltungsschicht 3: \" + str(dropoutrate3))\n",
      "  43:         model.add(Dropout(dropoutrate3))\n",
      "  44: \n",
      "  45:     if layerCountTuning == '4Layer' or layerCountTuning == '5Layer':\n",
      "  46:         filterCount4 = space['filterCount3_1']\n",
      "  47:         print(\"Anzahl der Filter-Maps Faltungsschicht 4: \" + str(filterCount4))\n",
      "  48:         model.add(Conv2D(filterCount4, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
      "  49:         model.add(Activation(af))\n",
      "  50:         model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  51:         dropoutrate4 = space['dropoutrate1_3']        \n",
      "  52:         print(\"Dropout-Rate Faltungsschicht 4: \" + str(dropoutrate4))\n",
      "  53:         model.add(Dropout(dropoutrate4)) \n",
      "  54:     \n",
      "  55:     if layerCountTuning == '5Layer':\n",
      "  56:         filterCount5 = space['filterCount3_2']\n",
      "  57:         print(\"Anzahl der Filter-Maps Faltungsschicht 5: \" + str(filterCount5))\n",
      "  58:         model.add(Conv2D(filterCount5, (convKernelSize, convKernelSize), padding='same', kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
      "  59:         model.add(Activation(af))\n",
      "  60:         model.add(MaxPooling2D(pool_size=(poolSize, poolSize)))\n",
      "  61:         dropoutrate5 = space['dropoutrate1_4']        \n",
      "  62:         print(\"Dropout-Rate Faltungsschicht 5: \" + str(dropoutrate5))\n",
      "  63:         model.add(Dropout(dropoutrate5)) \n",
      "  64: \n",
      "  65:     model.add(Flatten())\n",
      "  66:     dims4 = space['filterCount3_3']\n",
      "  67:     print(\"Anzahl der Neuronen des Fully Connected Layer: \" + str(dims4))    \n",
      "  68:     model.add(Dense(dims4, kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
      "  69:     model.add(Activation(af))\n",
      "  70:     dropoutFull = space['dropoutrate1_5']  \n",
      "  71:     print(\"Dropout-Rate Fully Connected Layer: \" + str(dropoutFull))\n",
      "  72:     model.add(Dropout(dropoutFull)) \n",
      "  73:     model.add(Dense(3, kernel_initializer=initializers.glorot_uniform(seed=42)))\n",
      "  74:     model.add(Activation('softmax'))\n",
      "  75:     \n",
      "  76:     # Diese Funktion läd Bilder in den Hauptspeicher\n",
      "  77:     # imagesPaths: Liste mit Pfaden zu den Bildern != null\n",
      "  78:     def imageLoader(imagePaths):\n",
      "  79:         images = []\n",
      "  80:         for path in imagePaths:\n",
      "  81:             images.append(cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2RGB))    \n",
      "  82:         imagesNp = np.array(images)\n",
      "  83:         imagesNp = imagesNp.astype('float32')\n",
      "  84:         imagesNp /= 255\n",
      "  85:         return imagesNp\n",
      "  86: \n",
      "  87:     # Läd Trainingsdaten in batches\n",
      "  88:     def dataLoader(imagePaths, features, batchSize):\n",
      "  89:         imagesCount= len(imagePaths)  \n",
      "  90:         while True:\n",
      "  91:             batchStart = 0\n",
      "  92:             batchEnd = batchSize\n",
      "  93:             while batchStart < imagesCount:\n",
      "  94:                 limit = min(batchEnd, imagesCount)\n",
      "  95:                 x = imageLoader(imagePaths[batchStart:limit])\n",
      "  96:                 y = features[batchStart:limit]\n",
      "  97:                 yield (x,y) \n",
      "  98:                 batchStart += batchSize   \n",
      "  99:                 batchEnd += batchSize\n",
      " 100:                 \n",
      " 101:     model.compile(loss='categorical_crossentropy', optimizer=optf, metrics=[\"accuracy\"])\n",
      " 102:     print('Faltungsnetz wird trainiert...')\n",
      " 103:     # Early Stopping unterbricht das Training, wenn nach 10 Epochen die Kostenfunktion nicht weiter minimiert werden konnte \n",
      " 104:     earlyStopping = cb.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='max')\n",
      " 105:     checkpointSafe = cb.ModelCheckpoint('ergebnisse_versuch5/modell_versuch5_3', monitor='val_acc', save_best_only=True)   \n",
      " 106:     model.fit_generator(dataLoader(xTrain, yTrain, batchSize), epochs=10, steps_per_epoch=(int(len(xTrain)/batchSize)),\n",
      " 107:               validation_data=dataLoader(xVal, yVal, batchSize), validation_steps=(int(len(xVal)/batchSize)), callbacks=[earlyStopping,checkpointSafe])\n",
      " 108:     score, acc = model.evaluate_generator( dataLoader(xVal, yVal, batchSize), steps=(int(len(xVal)/batchSize)))\n",
      " 109:     print('Test score: ' + str(score))\n",
      " 110:     print('Test accuracy: ' +  str(acc))\n",
      " 111:     # Die Rückgabewerte werden verarbeitet von Hyperas\n",
      " 112:     # loss ist die Kostenfunktion welche minimiert werden soll mit Hyperas\n",
      " 113:     # status (STATUS_OK) gibt an das, dass Modell erfolgreich ausgeführt wurde\n",
      " 114:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      " 115: \n",
      "C:/Users/morro/Documents/datenRoh/43/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "C:/Users/morro/Documents/datenRoh/45/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "C:/Users/morro/Documents/datenRoh/46/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "Ordner der geladen wird: 11\n",
      "C:/Users/morro/Documents/datenRoh/47/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "C:/Users/morro/Documents/datenRoh/48/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "Ordner der geladen wird: 10\n",
      "C:/Users/morro/Documents/datenRoh/49/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Ordner der geladen wird: 6\n",
      "Ordner der geladen wird: 7\n",
      "Ordner der geladen wird: 8\n",
      "Ordner der geladen wird: 9\n",
      "C:/Users/morro/Documents/datenRoh/50/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "C:/Users/morro/Documents/datenRoh/51/zugeschnitten/\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.36650111313577477\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.5910892819828057\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.31073308941714595\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.02787756283401593\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.22452694320321762\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 108s 71ms/step - loss: 1.2174 - acc: 0.3969 - val_loss: 1.0893 - val_acc: 0.4145\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 143s 94ms/step - loss: 1.0000 - acc: 0.4847 - val_loss: 0.9058 - val_acc: 0.5399\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 173s 114ms/step - loss: 0.9269 - acc: 0.5401 - val_loss: 1.1243 - val_acc: 0.3870\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 105s 69ms/step - loss: 0.9000 - acc: 0.5576 - val_loss: 0.8534 - val_acc: 0.5890\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 105s 69ms/step - loss: 0.8841 - acc: 0.5681 - val_loss: 0.8903 - val_acc: 0.5624\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 105s 69ms/step - loss: 0.8758 - acc: 0.5797 - val_loss: 1.1957 - val_acc: 0.4783\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 105s 69ms/step - loss: 0.8672 - acc: 0.5807 - val_loss: 0.9035 - val_acc: 0.6017\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 105s 69ms/step - loss: 0.8626 - acc: 0.5843 - val_loss: 1.0176 - val_acc: 0.5696\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 105s 69ms/step - loss: 0.8636 - acc: 0.5834 - val_loss: 1.1003 - val_acc: 0.5476\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 105s 69ms/step - loss: 0.8587 - acc: 0.5880 - val_loss: 0.9441 - val_acc: 0.6005\n",
      "Test score: 0.9450120011442587\n",
      "Test accuracy: 0.6002467105263158\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.3823049904758277\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.04027144697613922\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.11001387944772216\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.3809694643867013\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.3038288829951559\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.48825528701971843\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0654 - acc: 0.4259 - val_loss: 0.9995 - val_acc: 0.4756\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 138s 23ms/step - loss: 1.0450 - acc: 0.4697 - val_loss: 1.0295 - val_acc: 0.4346\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 136s 22ms/step - loss: 1.0672 - acc: 0.4602 - val_loss: 1.1404 - val_acc: 0.3376\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 136s 22ms/step - loss: 1.0892 - acc: 0.4414 - val_loss: 1.1144 - val_acc: 0.3393\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 135s 22ms/step - loss: 1.0950 - acc: 0.4430 - val_loss: 1.1337 - val_acc: 0.3336\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 135s 22ms/step - loss: 1.0928 - acc: 0.4549 - val_loss: 1.1301 - val_acc: 0.3496\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 137s 23ms/step - loss: 1.1431 - acc: 0.4543 - val_loss: 1.0707 - val_acc: 0.4120\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 137s 23ms/step - loss: 2.5590 - acc: 0.4345 - val_loss: 10.7321 - val_acc: 0.3342\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 136s 22ms/step - loss: 10.7494 - acc: 0.3331 - val_loss: 10.7335 - val_acc: 0.3341\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 136s 22ms/step - loss: 10.7457 - acc: 0.3333 - val_loss: 10.7321 - val_acc: 0.3342\n",
      "Test score: 10.732150633973092\n",
      "Test accuracy: 0.334155161078238\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.4930316398594563\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.5337907116491443\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.48407428062707253\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.6068703632453584\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.6803014606088199\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.10160055304815652\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 125s 41ms/step - loss: 1.0797 - acc: 0.4143 - val_loss: 1.0112 - val_acc: 0.4655\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 124s 41ms/step - loss: 1.0341 - acc: 0.4486 - val_loss: 1.0249 - val_acc: 0.4699\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 128s 42ms/step - loss: 1.0109 - acc: 0.4744 - val_loss: 1.1377 - val_acc: 0.3840\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 129s 42ms/step - loss: 0.9997 - acc: 0.4947 - val_loss: 1.0241 - val_acc: 0.4103\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 127s 42ms/step - loss: 0.9893 - acc: 0.5016 - val_loss: 0.9399 - val_acc: 0.5420\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 124s 41ms/step - loss: 0.9811 - acc: 0.5047 - val_loss: 0.9524 - val_acc: 0.4707\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 124s 41ms/step - loss: 0.9680 - acc: 0.5132 - val_loss: 0.9800 - val_acc: 0.5176\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 124s 41ms/step - loss: 0.9557 - acc: 0.5227 - val_loss: 0.9143 - val_acc: 0.5691\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 124s 41ms/step - loss: 0.9535 - acc: 0.5233 - val_loss: 0.9815 - val_acc: 0.5237\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 124s 41ms/step - loss: 0.9457 - acc: 0.5276 - val_loss: 0.9239 - val_acc: 0.5506\n",
      "Test score: 0.9238097608873719\n",
      "Test accuracy: 0.5508223684210526\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.5510035245500235\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.1532124532686945\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.17944072462772032\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.08445402539120138\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.08210828672230966\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 1.0787 - acc: 0.3852 - val_loss: 1.0160 - val_acc: 0.4714\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 1.0064 - acc: 0.4737 - val_loss: 0.9918 - val_acc: 0.4863\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 114s 38ms/step - loss: 0.9796 - acc: 0.4936 - val_loss: 1.0061 - val_acc: 0.4633\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 114s 37ms/step - loss: 0.9616 - acc: 0.5083 - val_loss: 0.9940 - val_acc: 0.4930\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 113s 37ms/step - loss: 0.9510 - acc: 0.5154 - val_loss: 1.0409 - val_acc: 0.4408\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 113s 37ms/step - loss: 0.9280 - acc: 0.5363 - val_loss: 1.1132 - val_acc: 0.3883\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 114s 37ms/step - loss: 0.9119 - acc: 0.5474 - val_loss: 1.1050 - val_acc: 0.4045\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 114s 37ms/step - loss: 0.8943 - acc: 0.5599 - val_loss: 1.1845 - val_acc: 0.3817\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 114s 37ms/step - loss: 0.8801 - acc: 0.5712 - val_loss: 1.1841 - val_acc: 0.3589\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 113s 37ms/step - loss: 0.8690 - acc: 0.5763 - val_loss: 1.2188 - val_acc: 0.3736\n",
      "Test score: 1.2191633364871928\n",
      "Test accuracy: 0.37351973684210527\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.26045732045458037\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.5553204526749792\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.3761602688998059\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.023263294966867562\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 1.1056 - acc: 0.4323 - val_loss: 2.3848 - val_acc: 0.4178\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 94s 62ms/step - loss: 1.0081 - acc: 0.4726 - val_loss: 1.9240 - val_acc: 0.3503\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.9892 - acc: 0.4841 - val_loss: 1.7529 - val_acc: 0.4871\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.9783 - acc: 0.4915 - val_loss: 1.7475 - val_acc: 0.3976\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 94s 62ms/step - loss: 0.9961 - acc: 0.4619 - val_loss: 0.9394 - val_acc: 0.5386\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 94s 62ms/step - loss: 0.9046 - acc: 0.5462 - val_loss: 0.9279 - val_acc: 0.5616\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.8805 - acc: 0.5635 - val_loss: 0.8440 - val_acc: 0.5937\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 94s 62ms/step - loss: 0.8744 - acc: 0.5680 - val_loss: 0.8664 - val_acc: 0.5972\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.8553 - acc: 0.5804 - val_loss: 0.8428 - val_acc: 0.6017\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.8477 - acc: 0.5876 - val_loss: 0.8555 - val_acc: 0.5975\n",
      "Test score: 0.8553494884779579\n",
      "Test accuracy: 0.5974506578947368\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.6861024010168819\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.649927584574656\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.399162292849581\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.4385232152116758\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.13328636172166075\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.05644691958057099\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 148s 24ms/step - loss: 1.1037 - acc: 0.4086 - val_loss: 1.1131 - val_acc: 0.4117\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 1.0367 - acc: 0.4574 - val_loss: 0.9948 - val_acc: 0.4933\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 153s 25ms/step - loss: 1.0219 - acc: 0.4752 - val_loss: 0.9996 - val_acc: 0.5344\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 1.0222 - acc: 0.4762 - val_loss: 1.3516 - val_acc: 0.3851\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 153s 25ms/step - loss: 1.0314 - acc: 0.4709 - val_loss: 1.1399 - val_acc: 0.3868\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 155s 26ms/step - loss: 1.0241 - acc: 0.4815 - val_loss: 1.1868 - val_acc: 0.3906\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 147s 24ms/step - loss: 1.0276 - acc: 0.4776 - val_loss: 4.4679 - val_acc: 0.4458\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 149s 24ms/step - loss: 1.0386 - acc: 0.4746 - val_loss: 2.7179 - val_acc: 0.4393\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 148s 24ms/step - loss: 1.0412 - acc: 0.4756 - val_loss: 3.8056 - val_acc: 0.4218\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 201s 33ms/step - loss: 1.0376 - acc: 0.4755 - val_loss: 7.1466 - val_acc: 0.3428\n",
      "Test score: 7.145932047168022\n",
      "Test accuracy: 0.3428665351742275\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.3355825176936589\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.2666132242226218\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.2965316398645662\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.15986691790317023\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 166s 55ms/step - loss: 1.0726 - acc: 0.4375 - val_loss: 1.0835 - val_acc: 0.3900\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 0.9759 - acc: 0.4934 - val_loss: 0.9151 - val_acc: 0.5355\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 0.9158 - acc: 0.5424 - val_loss: 0.8812 - val_acc: 0.5500\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 0.8866 - acc: 0.5615 - val_loss: 0.8708 - val_acc: 0.5476\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 0.8665 - acc: 0.5734 - val_loss: 1.2010 - val_acc: 0.4517\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 0.8489 - acc: 0.5836 - val_loss: 0.8936 - val_acc: 0.5722\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 0.8303 - acc: 0.5897 - val_loss: 0.9416 - val_acc: 0.5667\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 0.8153 - acc: 0.5991 - val_loss: 0.9194 - val_acc: 0.5602\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 0.7988 - acc: 0.6069 - val_loss: 1.1296 - val_acc: 0.5299\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.7823 - acc: 0.6177 - val_loss: 0.9882 - val_acc: 0.5555\n",
      "Test score: 0.988474285837851\n",
      "Test accuracy: 0.5553453947368421\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.5248675502930554\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.6521929535480597\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.26105331432376633\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.6957910099955584\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.21781501997478092\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521/1521 [==============================] - 85s 56ms/step - loss: 1.0669 - acc: 0.4209 - val_loss: 1.0403 - val_acc: 0.4282\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 1.0219 - acc: 0.4654 - val_loss: 1.0378 - val_acc: 0.4424\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 82s 54ms/step - loss: 1.0058 - acc: 0.4817 - val_loss: 1.0554 - val_acc: 0.4093\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 81s 53ms/step - loss: 0.9927 - acc: 0.4914 - val_loss: 1.0571 - val_acc: 0.4268\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 81s 53ms/step - loss: 0.9836 - acc: 0.5029 - val_loss: 1.0247 - val_acc: 0.4509\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 81s 53ms/step - loss: 0.9732 - acc: 0.5121 - val_loss: 1.0696 - val_acc: 0.3978\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 81s 53ms/step - loss: 0.9717 - acc: 0.5151 - val_loss: 1.0801 - val_acc: 0.3997\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 81s 53ms/step - loss: 0.9607 - acc: 0.5216 - val_loss: 1.1391 - val_acc: 0.3509\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 81s 53ms/step - loss: 0.9576 - acc: 0.5229 - val_loss: 1.0624 - val_acc: 0.4076\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 81s 53ms/step - loss: 1.1343 - acc: 0.5213 - val_loss: 1.0462 - val_acc: 0.4253\n",
      "Test score: 1.046307374929127\n",
      "Test accuracy: 0.4252467105263158\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.2888234898361773\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.23421018558252513\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.6236168941633805\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.45319110742946134\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 128\n",
      "Dropout-Rate Faltungsschicht 5: 0.5711831948196173\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.5509464626270063\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 109s 36ms/step - loss: 1.0861 - acc: 0.3775 - val_loss: 1.0567 - val_acc: 0.4133\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0414 - acc: 0.4534 - val_loss: 1.0377 - val_acc: 0.4620\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0306 - acc: 0.4731 - val_loss: 1.1059 - val_acc: 0.3921\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0210 - acc: 0.4900 - val_loss: 1.0836 - val_acc: 0.4339\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0152 - acc: 0.4942 - val_loss: 1.0947 - val_acc: 0.4219\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0335 - acc: 0.4954 - val_loss: 1.0540 - val_acc: 0.4485\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0296 - acc: 0.4960 - val_loss: 1.0560 - val_acc: 0.3617\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0571 - acc: 0.5004 - val_loss: 1.1364 - val_acc: 0.3774\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0278 - acc: 0.4973 - val_loss: 1.1721 - val_acc: 0.3455\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 1.0172 - acc: 0.4964 - val_loss: 1.1942 - val_acc: 0.3645\n",
      "Test score: 1.1940337749688248\n",
      "Test accuracy: 0.36463815789473686\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.1411873881737138\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.43940119562733904\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.6827140018946355\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.5212403354707789\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 86s 57ms/step - loss: 1.0631 - acc: 0.4466 - val_loss: 1.0066 - val_acc: 0.4583: 5s - loss: 1\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 405s 266ms/step - loss: 0.9914 - acc: 0.4871 - val_loss: 0.9325 - val_acc: 0.5371\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 141s 93ms/step - loss: 0.9486 - acc: 0.5180 - val_loss: 0.8693 - val_acc: 0.5791\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.9146 - acc: 0.5455 - val_loss: 0.8649 - val_acc: 0.5821\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8935 - acc: 0.5576 - val_loss: 0.8608 - val_acc: 0.5867\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8842 - acc: 0.5644 - val_loss: 0.8476 - val_acc: 0.5914\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8766 - acc: 0.5695 - val_loss: 0.8311 - val_acc: 0.6072\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8749 - acc: 0.5694 - val_loss: 0.8381 - val_acc: 0.6030\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8713 - acc: 0.5737 - val_loss: 0.8228 - val_acc: 0.6064\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8710 - acc: 0.5755 - val_loss: 0.8329 - val_acc: 0.5973\n",
      "Test score: 0.8331705294157329\n",
      "Test accuracy: 0.5971217105263158\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.5618022521290307\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.43180700701104185\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.6300135909702449\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.3705274468787073\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.0007036970434920242\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 1.0484 - acc: 0.4412 - val_loss: 1.0298 - val_acc: 0.4631\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 1.0028 - acc: 0.4745 - val_loss: 1.0190 - val_acc: 0.4735\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.9650 - acc: 0.5061 - val_loss: 0.9512 - val_acc: 0.5228\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.9361 - acc: 0.5317 - val_loss: 0.9677 - val_acc: 0.5599\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 83s 55ms/step - loss: 0.9164 - acc: 0.5429 - val_loss: 0.9301 - val_acc: 0.5348\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8996 - acc: 0.5548 - val_loss: 1.1168 - val_acc: 0.4887\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8858 - acc: 0.5636 - val_loss: 0.8574 - val_acc: 0.5895\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8748 - acc: 0.5706 - val_loss: 0.8966 - val_acc: 0.5831\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 83s 55ms/step - loss: 0.8666 - acc: 0.5759 - val_loss: 0.8579 - val_acc: 0.5912\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 84s 55ms/step - loss: 0.8606 - acc: 0.5795 - val_loss: 0.9831 - val_acc: 0.5683\n",
      "Test score: 0.9832243426849968\n",
      "Test accuracy: 0.5679276315789473\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.22696402957324682\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.15295936298124646\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.04614877235030587\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.18949638026428298\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6084/6084 [==============================] - 155s 26ms/step - loss: 10.7428 - acc: 0.3332 - val_loss: 10.7322 - val_acc: 0.3342\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7490 - acc: 0.3331 - val_loss: 10.7335 - val_acc: 0.3341\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7494 - acc: 0.3331 - val_loss: 10.7361 - val_acc: 0.3339\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7361 - val_acc: 0.3339\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7500 - acc: 0.3330 - val_loss: 10.7348 - val_acc: 0.3340\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7494 - acc: 0.3331 - val_loss: 10.7348 - val_acc: 0.3340\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7494 - acc: 0.3331 - val_loss: 10.7308 - val_acc: 0.3342\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7348 - val_acc: 0.3340\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7321 - val_acc: 0.3342\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7361 - val_acc: 0.3339\n",
      "Test score: 10.732150633973092\n",
      "Test accuracy: 0.334155161078238\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.502566005987901\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.1998550853505832\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.3759860620037276\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.5196250585612635\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.008207557723527914\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 117s 38ms/step - loss: 1.1192 - acc: 0.3521 - val_loss: 1.1120 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 1.1132 - acc: 0.3300 - val_loss: 1.1105 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 1.1133 - acc: 0.3291 - val_loss: 1.1119 - val_acc: 0.3325\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 1.1127 - acc: 0.3284 - val_loss: 1.1081 - val_acc: 0.3325\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 1.1120 - acc: 0.3296 - val_loss: 1.1049 - val_acc: 0.3323\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 1.1117 - acc: 0.3304 - val_loss: 1.1019 - val_acc: 0.3323\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 1.1108 - acc: 0.3323 - val_loss: 1.1007 - val_acc: 0.3323\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 1.1114 - acc: 0.3331 - val_loss: 1.0998 - val_acc: 0.3323\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 116s 38ms/step - loss: 1.1111 - acc: 0.3290 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 115s 38ms/step - loss: 1.1108 - acc: 0.3318 - val_loss: 1.0989 - val_acc: 0.3337\n",
      "Test score: 1.0989086941668862\n",
      "Test accuracy: 0.3335526315789474\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.20482279996588446\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.5455088012568097\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.5763085244479565\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.5310129254705536\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.004221254827684406\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 102s 33ms/step - loss: 1.2013 - acc: 0.4181 - val_loss: 1.0200 - val_acc: 0.4454\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 100s 33ms/step - loss: 1.0288 - acc: 0.4651 - val_loss: 0.9104 - val_acc: 0.5439\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 101s 33ms/step - loss: 0.9536 - acc: 0.5269 - val_loss: 0.9624 - val_acc: 0.4843\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 100s 33ms/step - loss: 0.9220 - acc: 0.5434 - val_loss: 1.1371 - val_acc: 0.4627\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 100s 33ms/step - loss: 0.9079 - acc: 0.5553 - val_loss: 0.9897 - val_acc: 0.4613\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 101s 33ms/step - loss: 0.9044 - acc: 0.5554 - val_loss: 0.8598 - val_acc: 0.5930\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 101s 33ms/step - loss: 0.9007 - acc: 0.5577 - val_loss: 0.9805 - val_acc: 0.5606\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 101s 33ms/step - loss: 0.9028 - acc: 0.5574 - val_loss: 0.9284 - val_acc: 0.5383\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 101s 33ms/step - loss: 0.9044 - acc: 0.5554 - val_loss: 0.9108 - val_acc: 0.5561\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 101s 33ms/step - loss: 0.9034 - acc: 0.5578 - val_loss: 0.8931 - val_acc: 0.5538\n",
      "Test score: 0.8932697055371184\n",
      "Test accuracy: 0.5537006578947369\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.6859801490268133\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.3567663629232832\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.6398422280118664\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.3468418591094041\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 161s 26ms/step - loss: 1.1058 - acc: 0.3347 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 1.0988 - acc: 0.3330 - val_loss: 1.0988 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 1.0988 - acc: 0.3330 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 1.0989 - acc: 0.3319 - val_loss: 1.0989 - val_acc: 0.3323\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Test score: 1.0988241953727527\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.5307933999683194\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.1449955280636636\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.04730330293000361\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.37732292891116026\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.10028084027027029\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 1.0990 - acc: 0.3322 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 102s 34ms/step - loss: 1.0987 - acc: 0.3334 - val_loss: 1.0988 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 102s 34ms/step - loss: 1.0987 - acc: 0.3339 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 102s 34ms/step - loss: 1.0987 - acc: 0.3337 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 102s 34ms/step - loss: 1.0987 - acc: 0.3337 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 102s 34ms/step - loss: 1.0987 - acc: 0.3337 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 103s 34ms/step - loss: 1.0987 - acc: 0.3337 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 102s 34ms/step - loss: 1.0987 - acc: 0.3338 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 102s 34ms/step - loss: 1.0987 - acc: 0.3337 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 103s 34ms/step - loss: 1.0987 - acc: 0.3338 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Test score: 1.0987519544990438\n",
      "Test accuracy: 0.3323190789473684\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.4831880841923193\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.4218928627980383\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.4360259891153708\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.4074207844976787\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.5411342377700985\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 105s 34ms/step - loss: 1.0582 - acc: 0.4389 - val_loss: 1.0110 - val_acc: 0.4437\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 1.0256 - acc: 0.4574 - val_loss: 1.0219 - val_acc: 0.4442\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 1.0143 - acc: 0.4719 - val_loss: 0.9639 - val_acc: 0.5209\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 103s 34ms/step - loss: 0.9919 - acc: 0.4864 - val_loss: 0.9873 - val_acc: 0.4055\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 0.9850 - acc: 0.4905 - val_loss: 0.9750 - val_acc: 0.4695\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 0.9814 - acc: 0.4938 - val_loss: 0.8979 - val_acc: 0.5662\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 0.9811 - acc: 0.4921 - val_loss: 0.9779 - val_acc: 0.5186\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 0.9856 - acc: 0.4845 - val_loss: 1.0374 - val_acc: 0.4282\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 0.9919 - acc: 0.4798 - val_loss: 0.9703 - val_acc: 0.4708\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 104s 34ms/step - loss: 0.9970 - acc: 0.4751 - val_loss: 2.5703 - val_acc: 0.3865\n",
      "Test score: 2.5708897152229357\n",
      "Test accuracy: 0.38626644736842103\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.004402839931825553\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.0016145402093660887\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.0908218196803085\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.2833657173581164\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 148s 24ms/step - loss: 1.0991 - acc: 0.3342 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 147s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 147s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 147s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 147s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 147s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 147s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Test score: 1.0988241953727527\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.16247928184812713\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.5862336116278009\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.3396749535127678\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.271304795333835\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 153s 25ms/step - loss: 10.7386 - acc: 0.3336 - val_loss: 10.7414 - val_acc: 0.3336\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7501 - acc: 0.3330 - val_loss: 10.7414 - val_acc: 0.3336\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7508 - acc: 0.3330 - val_loss: 10.7414 - val_acc: 0.3336\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7462 - acc: 0.3331 - val_loss: 10.7414 - val_acc: 0.3336\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7099 - acc: 0.3354 - val_loss: 10.7321 - val_acc: 0.3342\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7494 - acc: 0.3331 - val_loss: 10.7361 - val_acc: 0.3339\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7313 - acc: 0.3342 - val_loss: 10.7613 - val_acc: 0.3323\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7367 - acc: 0.3339 - val_loss: 10.7600 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7361 - acc: 0.3339 - val_loss: 10.7600 - val_acc: 0.3324\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7570 - acc: 0.3325 - val_loss: 10.7348 - val_acc: 0.3340\n",
      "Test score: 10.732150633973092\n",
      "Test accuracy: 0.334155161078238\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.4610984734470713\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.16081779868236015\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.08805334360109915\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.6708566424053988\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.6710317480025905\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.5758588201404047\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 1.0682 - acc: 0.4294 - val_loss: 1.0246 - val_acc: 0.4584\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 100s 65ms/step - loss: 0.9934 - acc: 0.4879 - val_loss: 0.9054 - val_acc: 0.5486\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 99s 65ms/step - loss: 0.9388 - acc: 0.5286 - val_loss: 0.8705 - val_acc: 0.5648\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 99s 65ms/step - loss: 0.9218 - acc: 0.5430 - val_loss: 0.8608 - val_acc: 0.5792\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 99s 65ms/step - loss: 0.9191 - acc: 0.5406 - val_loss: 0.8794 - val_acc: 0.5704\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 100s 65ms/step - loss: 0.9204 - acc: 0.5420 - val_loss: 0.8384 - val_acc: 0.5832\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 100s 65ms/step - loss: 0.9243 - acc: 0.5415 - val_loss: 0.8425 - val_acc: 0.5799\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 100s 65ms/step - loss: 0.9252 - acc: 0.5410 - val_loss: 0.8397 - val_acc: 0.5955\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 100s 65ms/step - loss: 0.9270 - acc: 0.5388 - val_loss: 0.8675 - val_acc: 0.5935\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 100s 65ms/step - loss: 0.9280 - acc: 0.5405 - val_loss: 0.8334 - val_acc: 0.6059\n",
      "Test score: 0.8335627453891854\n",
      "Test accuracy: 0.6059210526315789\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.6427027259508195\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.4169443998086015\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.18710814475088694\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.13477514402321533\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.3423376321763028\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 1.0483 - acc: 0.4486 - val_loss: 0.9845 - val_acc: 0.4867\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9907 - acc: 0.4888 - val_loss: 0.9219 - val_acc: 0.5291\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9425 - acc: 0.5291 - val_loss: 0.9552 - val_acc: 0.5060\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9164 - acc: 0.5468 - val_loss: 0.9187 - val_acc: 0.5344\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.8953 - acc: 0.5596 - val_loss: 0.9177 - val_acc: 0.5339\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.8884 - acc: 0.5653 - val_loss: 0.9549 - val_acc: 0.5520\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.8777 - acc: 0.5723 - val_loss: 1.0137 - val_acc: 0.5543\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.8701 - acc: 0.5750 - val_loss: 0.9515 - val_acc: 0.5781\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.8652 - acc: 0.5743 - val_loss: 1.0182 - val_acc: 0.5359\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.8591 - acc: 0.5785 - val_loss: 0.9136 - val_acc: 0.5857\n",
      "Test score: 0.9139016013396414\n",
      "Test accuracy: 0.5855263157894737\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.15659987172287998\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.2129190258346184\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.442275237188643\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.13420926237033706\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.40227014875377326\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.07500448226106743\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 1.0318 - acc: 0.4482 - val_loss: 0.9615 - val_acc: 0.5008\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 86s 56ms/step - loss: 0.9443 - acc: 0.5232 - val_loss: 0.8557 - val_acc: 0.5830\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 86s 56ms/step - loss: 0.8860 - acc: 0.5623 - val_loss: 0.8573 - val_acc: 0.5744\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 86s 56ms/step - loss: 0.8579 - acc: 0.5833 - val_loss: 0.8502 - val_acc: 0.5737\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.8448 - acc: 0.5920 - val_loss: 0.8667 - val_acc: 0.5947\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 86s 56ms/step - loss: 0.8349 - acc: 0.5995 - val_loss: 0.8991 - val_acc: 0.5808\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 86s 56ms/step - loss: 0.8296 - acc: 0.6030 - val_loss: 0.8624 - val_acc: 0.6032\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 86s 56ms/step - loss: 0.8262 - acc: 0.6042 - val_loss: 0.8031 - val_acc: 0.6228\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.8173 - acc: 0.6082 - val_loss: 0.7961 - val_acc: 0.6269\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 86s 56ms/step - loss: 0.8148 - acc: 0.6086 - val_loss: 0.7944 - val_acc: 0.6231\n",
      "Test score: 0.7944222856509058\n",
      "Test accuracy: 0.6231085526315789\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.03784859630175669\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.6475624675409367\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.07605493406267955\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.36656570380794323\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.3645909423573867\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.4688951121094675\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 1.0996 - acc: 0.3337 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 1.0988 - acc: 0.3320 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 95s 63ms/step - loss: 1.0987 - acc: 0.3319 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 95s 63ms/step - loss: 1.0987 - acc: 0.3318 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 95s 63ms/step - loss: 1.0987 - acc: 0.3328 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 95s 63ms/step - loss: 1.0987 - acc: 0.3325 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 95s 63ms/step - loss: 1.0987 - acc: 0.3324 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 95s 63ms/step - loss: 1.0987 - acc: 0.3322 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 95s 63ms/step - loss: 1.0987 - acc: 0.3325 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 95s 63ms/step - loss: 1.0987 - acc: 0.3325 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Test score: 1.0986950698651765\n",
      "Test accuracy: 0.3323190789473684\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.4063029446461945\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.04103941739720152\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.5298945883736625\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.1126017636345988\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 128\n",
      "Dropout-Rate Faltungsschicht 5: 0.1951722566868454\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.6301271821968158\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 1.0762 - acc: 0.4135 - val_loss: 0.9976 - val_acc: 0.4824\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 1.0234 - acc: 0.4743 - val_loss: 0.9937 - val_acc: 0.4802\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9810 - acc: 0.5086 - val_loss: 0.9948 - val_acc: 0.5046\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9649 - acc: 0.5217 - val_loss: 1.0470 - val_acc: 0.4467\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9588 - acc: 0.5343 - val_loss: 0.9032 - val_acc: 0.5624\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9391 - acc: 0.5441 - val_loss: 0.9486 - val_acc: 0.5248\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9338 - acc: 0.5505 - val_loss: 0.9198 - val_acc: 0.5455\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9378 - acc: 0.5449 - val_loss: 0.9984 - val_acc: 0.4666\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9445 - acc: 0.5476 - val_loss: 1.1074 - val_acc: 0.3908\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 0.9398 - acc: 0.5450 - val_loss: 0.9674 - val_acc: 0.5526\n",
      "Test score: 0.9676417040197473\n",
      "Test accuracy: 0.5525493421052632\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.6117517831509787\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.07874046469699175\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.38879746602236\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.10165264323193196\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.30294519188552504\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.1448 - acc: 0.4293 - val_loss: 1.0504 - val_acc: 0.4509\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9728 - acc: 0.5048 - val_loss: 0.9170 - val_acc: 0.5436\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9453 - acc: 0.5272 - val_loss: 1.1011 - val_acc: 0.4846\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9416 - acc: 0.5306 - val_loss: 0.9562 - val_acc: 0.5065\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9381 - acc: 0.5336 - val_loss: 0.9248 - val_acc: 0.5368\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9408 - acc: 0.5354 - val_loss: 1.1272 - val_acc: 0.5056\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9475 - acc: 0.5304 - val_loss: 0.8805 - val_acc: 0.5861\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9557 - acc: 0.5196 - val_loss: 0.9508 - val_acc: 0.4935\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9521 - acc: 0.5214 - val_loss: 0.9309 - val_acc: 0.5573\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 119s 39ms/step - loss: 0.9602 - acc: 0.5146 - val_loss: 1.1408 - val_acc: 0.4751\n",
      "Test score: 1.140751149309309\n",
      "Test accuracy: 0.4752467105263158\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.2636404947056047\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.6836210943752541\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.22966076346119307\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.6582916558341014\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.3055128722061833\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 106s 70ms/step - loss: 1.0632 - acc: 0.4315 - val_loss: 1.0696 - val_acc: 0.3931\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 1.0264 - acc: 0.4675 - val_loss: 1.0037 - val_acc: 0.4858\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9995 - acc: 0.4917 - val_loss: 1.0496 - val_acc: 0.4595\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9841 - acc: 0.5047 - val_loss: 1.0282 - val_acc: 0.4797\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9694 - acc: 0.5191 - val_loss: 0.9679 - val_acc: 0.5188\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9621 - acc: 0.5287 - val_loss: 0.9850 - val_acc: 0.5000\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9484 - acc: 0.5333 - val_loss: 0.9769 - val_acc: 0.4925\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9500 - acc: 0.5362 - val_loss: 1.0261 - val_acc: 0.4497\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9523 - acc: 0.5366 - val_loss: 1.0203 - val_acc: 0.4538\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9466 - acc: 0.5406 - val_loss: 0.9873 - val_acc: 0.5175\n",
      "Test score: 0.9873156003261867\n",
      "Test accuracy: 0.5174342105263158\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.04094223486538234\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.5501173450933593\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.24209449821680215\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.47065615224871427\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.3212478490516954\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 144s 24ms/step - loss: 10.7476 - acc: 0.3329 - val_loss: 10.7414 - val_acc: 0.3336\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 10.7501 - acc: 0.3330 - val_loss: 10.7401 - val_acc: 0.3337\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 10.7508 - acc: 0.3330 - val_loss: 10.7414 - val_acc: 0.3336\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 10.7504 - acc: 0.3330 - val_loss: 10.7414 - val_acc: 0.3336\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 10.7733 - acc: 0.3315 - val_loss: 10.7308 - val_acc: 0.3342\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 10.7721 - acc: 0.3316 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 10.7508 - acc: 0.3330 - val_loss: 10.7401 - val_acc: 0.3337\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 10.7498 - acc: 0.3331 - val_loss: 10.7401 - val_acc: 0.3337\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 10.7504 - acc: 0.3330 - val_loss: 10.7414 - val_acc: 0.3336\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 10.7504 - acc: 0.3330 - val_loss: 10.7401 - val_acc: 0.3337\n",
      "Test score: 10.741423042568229\n",
      "Test accuracy: 0.33357988165680474\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.1611811624500729\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.26908596491655257\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.034636694400194755\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.6907288802727536\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.13406699491026297\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.10524234787979274\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 123s 41ms/step - loss: 1.0499 - acc: 0.4482 - val_loss: 0.9863 - val_acc: 0.4961\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 0.9862 - acc: 0.5074 - val_loss: 0.9347 - val_acc: 0.5422\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 0.9663 - acc: 0.5188 - val_loss: 0.9681 - val_acc: 0.5244\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 0.9625 - acc: 0.5266 - val_loss: 0.9434 - val_acc: 0.5613\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 0.9599 - acc: 0.5292 - val_loss: 0.9766 - val_acc: 0.5221\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 0.9579 - acc: 0.5310 - val_loss: 1.0370 - val_acc: 0.5120\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 0.9642 - acc: 0.5290 - val_loss: 1.0147 - val_acc: 0.5318\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 0.9740 - acc: 0.5277 - val_loss: 1.0407 - val_acc: 0.4742\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 3.6360 - acc: 0.4692 - val_loss: 1.0534 - val_acc: 0.4190\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 0.9769 - acc: 0.5183 - val_loss: 0.9985 - val_acc: 0.4961\n",
      "Test score: 0.9984505639264458\n",
      "Test accuracy: 0.49613486842105264\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.5430043368754298\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.06715690813728312\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.1964720930822093\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.5045534914382528\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 125s 41ms/step - loss: 1.2157 - acc: 0.3352 - val_loss: 1.0979 - val_acc: 0.3405\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 123s 41ms/step - loss: 1.1069 - acc: 0.3312 - val_loss: 1.0989 - val_acc: 0.3336\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 123s 41ms/step - loss: 1.1069 - acc: 0.3298 - val_loss: 1.0993 - val_acc: 0.3335\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 123s 41ms/step - loss: 1.1145 - acc: 0.3319 - val_loss: 1.0995 - val_acc: 0.3335\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 123s 40ms/step - loss: 1.1070 - acc: 0.3306 - val_loss: 1.1003 - val_acc: 0.3335\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 123s 41ms/step - loss: 1.1069 - acc: 0.3313 - val_loss: 1.1005 - val_acc: 0.3336\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 123s 41ms/step - loss: 1.1067 - acc: 0.3321 - val_loss: 1.1005 - val_acc: 0.3334\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 123s 41ms/step - loss: 1.1067 - acc: 0.3319 - val_loss: 1.1014 - val_acc: 0.3337\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 123s 40ms/step - loss: 1.1070 - acc: 0.3314 - val_loss: 1.1012 - val_acc: 0.3337\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 123s 41ms/step - loss: 1.1072 - acc: 0.3295 - val_loss: 1.1019 - val_acc: 0.3337\n",
      "Test score: 1.101934928172513\n",
      "Test accuracy: 0.3335526315789474\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.4161322928479168\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.07400274876473123\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.5207759314862476\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.2108262930092021\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.3102813339921929\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 100s 66ms/step - loss: 1.0506 - acc: 0.4258 - val_loss: 1.0350 - val_acc: 0.4490\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 1.0082 - acc: 0.4688 - val_loss: 1.0301 - val_acc: 0.4502\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.9921 - acc: 0.4856 - val_loss: 1.0138 - val_acc: 0.4565\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.9786 - acc: 0.4961 - val_loss: 0.9828 - val_acc: 0.4942\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.9568 - acc: 0.5144 - val_loss: 1.0000 - val_acc: 0.4883\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.9395 - acc: 0.5271 - val_loss: 1.0226 - val_acc: 0.4627\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.9209 - acc: 0.5420 - val_loss: 1.0006 - val_acc: 0.4868\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.9050 - acc: 0.5554 - val_loss: 0.9671 - val_acc: 0.5143\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.8942 - acc: 0.5592 - val_loss: 1.0089 - val_acc: 0.4814\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.8864 - acc: 0.5665 - val_loss: 1.0394 - val_acc: 0.4585\n",
      "Test score: 1.0398296306007786\n",
      "Test accuracy: 0.4586348684210526\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.33451399159802375\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.25767222312424426\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.36484964265506686\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.4207538587369814\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 98s 32ms/step - loss: 1.0518 - acc: 0.4436 - val_loss: 1.0106 - val_acc: 0.4676\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9885 - acc: 0.5013 - val_loss: 0.9928 - val_acc: 0.4707\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9662 - acc: 0.5167 - val_loss: 0.9830 - val_acc: 0.4844\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9627 - acc: 0.5244 - val_loss: 0.9866 - val_acc: 0.4787\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9557 - acc: 0.5265 - val_loss: 1.0501 - val_acc: 0.3993\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9494 - acc: 0.5306 - val_loss: 0.9687 - val_acc: 0.5005\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9501 - acc: 0.5280 - val_loss: 0.9489 - val_acc: 0.5220\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9498 - acc: 0.5268 - val_loss: 0.9717 - val_acc: 0.4835\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9510 - acc: 0.5296 - val_loss: 0.9978 - val_acc: 0.4459\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 95s 31ms/step - loss: 0.9554 - acc: 0.5306 - val_loss: 0.9912 - val_acc: 0.4460\n",
      "Test score: 0.9913722431973407\n",
      "Test accuracy: 0.44564144736842104\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.5898991773841765\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.15111715163692865\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.0037666668932191723\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.23702840408628864\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 173s 114ms/step - loss: 1.0611 - acc: 0.4398 - val_loss: 0.9999 - val_acc: 0.4726\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521/1521 [==============================] - 123s 81ms/step - loss: 1.0067 - acc: 0.4783 - val_loss: 0.9713 - val_acc: 0.5002\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 0.9818 - acc: 0.5005 - val_loss: 0.9715 - val_acc: 0.4992\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 0.9593 - acc: 0.5211 - val_loss: 0.9602 - val_acc: 0.5231\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 0.9392 - acc: 0.5337 - val_loss: 0.9319 - val_acc: 0.5543\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 88s 58ms/step - loss: 0.9311 - acc: 0.5416 - val_loss: 0.9338 - val_acc: 0.5478\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 88s 58ms/step - loss: 0.9168 - acc: 0.5499 - val_loss: 0.9647 - val_acc: 0.5096\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 0.9126 - acc: 0.5559 - val_loss: 0.9750 - val_acc: 0.4991\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 0.9077 - acc: 0.5563 - val_loss: 0.9300 - val_acc: 0.5661\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 0.9068 - acc: 0.5605 - val_loss: 0.9012 - val_acc: 0.5651\n",
      "Test score: 0.9011892619885896\n",
      "Test accuracy: 0.5652960526315789\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.6258522155693698\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.12809110971442503\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.3483976272358616\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.46689731505582\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.6432023455140354\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 124s 41ms/step - loss: 1.0592 - acc: 0.4376 - val_loss: 1.0152 - val_acc: 0.4484\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0323 - acc: 0.4532 - val_loss: 1.1137 - val_acc: 0.4302\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0286 - acc: 0.4595 - val_loss: 1.0162 - val_acc: 0.4120\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0242 - acc: 0.4581 - val_loss: 0.9987 - val_acc: 0.3833\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0234 - acc: 0.4573 - val_loss: 0.9683 - val_acc: 0.5005\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0336 - acc: 0.4489 - val_loss: 1.0739 - val_acc: 0.3651\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0364 - acc: 0.4469 - val_loss: 0.9936 - val_acc: 0.4963\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0395 - acc: 0.4433 - val_loss: 1.0334 - val_acc: 0.4401\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0478 - acc: 0.4317 - val_loss: 1.0651 - val_acc: 0.3818\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 121s 40ms/step - loss: 1.0558 - acc: 0.4248 - val_loss: 1.0140 - val_acc: 0.4314\n",
      "Test score: 1.0140524523822885\n",
      "Test accuracy: 0.43116776315789473\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.6719647718091494\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.4334039533095252\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.3852434388296144\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.05792646430464581\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 128\n",
      "Dropout-Rate Faltungsschicht 5: 0.6201374941396659\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.057200250266939485\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 108s 36ms/step - loss: 1.1545 - acc: 0.4220 - val_loss: 1.1245 - val_acc: 0.4169\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 1.0064 - acc: 0.4852 - val_loss: 1.0680 - val_acc: 0.4448\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9908 - acc: 0.4959 - val_loss: 1.2316 - val_acc: 0.4600\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9813 - acc: 0.5031 - val_loss: 1.0822 - val_acc: 0.4164\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9770 - acc: 0.5064 - val_loss: 0.9839 - val_acc: 0.4306\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9787 - acc: 0.5086 - val_loss: 1.4179 - val_acc: 0.4737\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9793 - acc: 0.5038 - val_loss: 1.0846 - val_acc: 0.5188\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9777 - acc: 0.5034 - val_loss: 1.2037 - val_acc: 0.4999\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9786 - acc: 0.5042 - val_loss: 0.9833 - val_acc: 0.5549\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9836 - acc: 0.5045 - val_loss: 0.9231 - val_acc: 0.5286\n",
      "Test score: 0.9235436964191889\n",
      "Test accuracy: 0.5282894736842105\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.3389652104130198\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.1104098405551635\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.5296528997881041\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.13987297505909094\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 110s 36ms/step - loss: 10.7411 - acc: 0.3333 - val_loss: 10.7326 - val_acc: 0.3341\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7339 - val_acc: 0.3340\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7510 - acc: 0.3330 - val_loss: 10.7339 - val_acc: 0.3340\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7500 - acc: 0.3330 - val_loss: 10.7339 - val_acc: 0.3340\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7507 - acc: 0.3330 - val_loss: 10.7326 - val_acc: 0.3341\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7326 - val_acc: 0.3341\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7507 - acc: 0.3330 - val_loss: 10.7299 - val_acc: 0.3343\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7514 - acc: 0.3330 - val_loss: 10.7299 - val_acc: 0.3343\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7379 - val_acc: 0.3338\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7507 - acc: 0.3330 - val_loss: 10.7366 - val_acc: 0.3339\n",
      "Test score: 10.732583765607131\n",
      "Test accuracy: 0.3341282894736842\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.19303830922066545\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.0840127538592151\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.4642820273620739\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.09875567645458869\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.6570201177778964\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521/1521 [==============================] - 107s 70ms/step - loss: 1.1086 - acc: 0.4226 - val_loss: 0.9242 - val_acc: 0.5343\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9278 - acc: 0.5384 - val_loss: 0.8901 - val_acc: 0.5444\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.9014 - acc: 0.5574 - val_loss: 0.9102 - val_acc: 0.4960\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.8913 - acc: 0.5646 - val_loss: 0.8546 - val_acc: 0.5732\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.8850 - acc: 0.5691 - val_loss: 0.8387 - val_acc: 0.5987\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.8809 - acc: 0.5731 - val_loss: 0.9636 - val_acc: 0.5258\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.8799 - acc: 0.5731 - val_loss: 0.8485 - val_acc: 0.6052\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.8818 - acc: 0.5750 - val_loss: 0.8655 - val_acc: 0.5843\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.8820 - acc: 0.5752 - val_loss: 0.8415 - val_acc: 0.6050\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 104s 68ms/step - loss: 0.8821 - acc: 0.5746 - val_loss: 0.8229 - val_acc: 0.6147\n",
      "Test score: 0.8230994994703092\n",
      "Test accuracy: 0.6147203947368421\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.0790967978439296\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.5028747003251189\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.317826785536165\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.007773182337481476\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.6840469439004162\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.5558192810676943\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 1.0891 - acc: 0.4054 - val_loss: 0.9994 - val_acc: 0.4720\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 94s 61ms/step - loss: 0.9817 - acc: 0.5001 - val_loss: 0.9274 - val_acc: 0.5219\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 93s 61ms/step - loss: 0.9201 - acc: 0.5458 - val_loss: 0.8562 - val_acc: 0.5982\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 93s 61ms/step - loss: 0.9039 - acc: 0.5592 - val_loss: 0.8308 - val_acc: 0.6097\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 93s 61ms/step - loss: 0.8991 - acc: 0.5631 - val_loss: 0.8329 - val_acc: 0.6023\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 93s 61ms/step - loss: 0.8970 - acc: 0.5623 - val_loss: 0.8690 - val_acc: 0.5592\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 93s 61ms/step - loss: 0.8979 - acc: 0.5626 - val_loss: 0.8198 - val_acc: 0.6144\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 93s 61ms/step - loss: 0.8990 - acc: 0.5605 - val_loss: 0.9058 - val_acc: 0.5578\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 94s 61ms/step - loss: 0.9010 - acc: 0.5581 - val_loss: 0.9686 - val_acc: 0.5443\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 93s 61ms/step - loss: 0.9029 - acc: 0.5588 - val_loss: 0.8369 - val_acc: 0.5978\n",
      "Test score: 0.8367964957889757\n",
      "Test accuracy: 0.5979440789473685\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.1318344215856727\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.17097711507589985\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.13585476438335367\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.0016035241808834422\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.19487524692545927\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 93s 61ms/step - loss: 10.7223 - acc: 0.3340 - val_loss: 10.7617 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7355 - acc: 0.3339 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7362 - acc: 0.3339 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7372 - acc: 0.3338 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7349 - acc: 0.3340 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7355 - acc: 0.3339 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7375 - acc: 0.3338 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7355 - acc: 0.3339 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7359 - acc: 0.3339 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 90s 59ms/step - loss: 10.7359 - acc: 0.3339 - val_loss: 10.7587 - val_acc: 0.3325\n",
      "Test score: 10.76174474264446\n",
      "Test accuracy: 0.3323190789473684\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.13872893014276017\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.3829173687339869\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.07484323080037802\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.1051655735427622\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 128\n",
      "Dropout-Rate Faltungsschicht 5: 0.682767227755717\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.5310225268328831\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 149s 24ms/step - loss: 1.0992 - acc: 0.3319 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3344 - val_loss: 1.0988 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Test score: 1.0988241953727527\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.3069084930878262\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.37556917170016396\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.3627725845511256\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.01796643755811378\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.21273340082487735\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 88s 58ms/step - loss: 1.0317 - acc: 0.4521 - val_loss: 0.9688 - val_acc: 0.4936\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.9774 - acc: 0.4965 - val_loss: 0.9296 - val_acc: 0.5235\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.9127 - acc: 0.5476 - val_loss: 0.9145 - val_acc: 0.5537\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.8767 - acc: 0.5712 - val_loss: 0.8829 - val_acc: 0.5727\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.8584 - acc: 0.5843 - val_loss: 0.9264 - val_acc: 0.5671\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.8422 - acc: 0.5926 - val_loss: 0.8925 - val_acc: 0.5793\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.8266 - acc: 0.6045 - val_loss: 0.8873 - val_acc: 0.5923\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.8128 - acc: 0.6110 - val_loss: 0.8749 - val_acc: 0.5963\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.7954 - acc: 0.6228 - val_loss: 0.9075 - val_acc: 0.5823\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 85s 56ms/step - loss: 0.7829 - acc: 0.6257 - val_loss: 0.9202 - val_acc: 0.5970\n",
      "Test score: 0.9202187770291379\n",
      "Test accuracy: 0.5972039473684211\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.3941294727270916\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.35096049291960096\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.5756135869158329\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.16966042548763868\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 164s 27ms/step - loss: 10.7412 - acc: 0.3333 - val_loss: 10.7322 - val_acc: 0.3342\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7490 - acc: 0.3331 - val_loss: 10.7335 - val_acc: 0.3341\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7494 - acc: 0.3331 - val_loss: 10.7335 - val_acc: 0.3341\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7321 - val_acc: 0.3342\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7500 - acc: 0.3330 - val_loss: 10.7335 - val_acc: 0.3341\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7494 - acc: 0.3331 - val_loss: 10.7335 - val_acc: 0.3341\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7494 - acc: 0.3331 - val_loss: 10.7308 - val_acc: 0.3342\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7361 - val_acc: 0.3339\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7361 - val_acc: 0.3339\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7497 - acc: 0.3331 - val_loss: 10.7361 - val_acc: 0.3339\n",
      "Test score: 10.732150633973092\n",
      "Test accuracy: 0.334155161078238\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.6376219441266817\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.22525415691307785\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.204913954813469\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.3863542731207837\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.019006025011648452\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 155s 26ms/step - loss: 7.6646 - acc: 0.3365 - val_loss: 10.7626 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7371 - acc: 0.3339 - val_loss: 10.7586 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7361 - acc: 0.3339 - val_loss: 10.7613 - val_acc: 0.3323\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7361 - acc: 0.3339 - val_loss: 10.7613 - val_acc: 0.3323\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7357 - acc: 0.3339 - val_loss: 10.7640 - val_acc: 0.3322\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7367 - acc: 0.3339 - val_loss: 10.7600 - val_acc: 0.3324\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7361 - acc: 0.3339 - val_loss: 10.7600 - val_acc: 0.3324\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7367 - acc: 0.3339 - val_loss: 10.7600 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7361 - acc: 0.3339 - val_loss: 10.7613 - val_acc: 0.3323\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 10.7361 - acc: 0.3339 - val_loss: 10.7600 - val_acc: 0.3324\n",
      "Test score: 10.762617119357117\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.025863278157258317\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.09769179708236805\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.34928374397389894\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.2827461472638423\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 1.0457 - acc: 0.4586 - val_loss: 0.9385 - val_acc: 0.5318\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 98s 65ms/step - loss: 0.9139 - acc: 0.5435 - val_loss: 0.8549 - val_acc: 0.5876\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 98s 65ms/step - loss: 0.8554 - acc: 0.5851 - val_loss: 0.8285 - val_acc: 0.6052\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 0.8158 - acc: 0.6124 - val_loss: 0.8515 - val_acc: 0.5975\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 0.7554 - acc: 0.6473 - val_loss: 0.8934 - val_acc: 0.5849\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 0.6925 - acc: 0.6822 - val_loss: 0.9650 - val_acc: 0.5609\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 98s 65ms/step - loss: 0.6278 - acc: 0.7157 - val_loss: 1.0624 - val_acc: 0.5774\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 0.5847 - acc: 0.7436 - val_loss: 1.1098 - val_acc: 0.5552\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 0.5359 - acc: 0.7699 - val_loss: 1.1037 - val_acc: 0.5536\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 0.4973 - acc: 0.7873 - val_loss: 1.2783 - val_acc: 0.5568\n",
      "Test score: 1.278306133025571\n",
      "Test accuracy: 0.5564144736842105\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.34423045967715427\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.5220785099718168\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.6787324686833386\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.07605034525389257\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 10.7502 - acc: 0.3329 - val_loss: 9.5530 - val_acc: 0.3336\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6084/6084 [==============================] - 156s 26ms/step - loss: 3.8370 - acc: 0.3999 - val_loss: 1.0619 - val_acc: 0.4286\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 156s 26ms/step - loss: 1.0516 - acc: 0.4450 - val_loss: 1.0702 - val_acc: 0.4328\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 156s 26ms/step - loss: 1.0474 - acc: 0.4495 - val_loss: 1.0613 - val_acc: 0.3848\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 155s 26ms/step - loss: 1.0419 - acc: 0.4587 - val_loss: 1.0994 - val_acc: 0.3351\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 155s 26ms/step - loss: 1.0482 - acc: 0.4636 - val_loss: 1.1160 - val_acc: 0.3334\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 155s 26ms/step - loss: 1.0406 - acc: 0.4610 - val_loss: 1.1133 - val_acc: 0.3337\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 155s 25ms/step - loss: 1.0400 - acc: 0.4591 - val_loss: 1.1087 - val_acc: 0.3337\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 155s 25ms/step - loss: 1.0417 - acc: 0.4611 - val_loss: 1.1144 - val_acc: 0.3338\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 155s 26ms/step - loss: 1.0440 - acc: 0.4619 - val_loss: 1.1234 - val_acc: 0.3342\n",
      "Test score: 1.1234502656768608\n",
      "Test accuracy: 0.33407297830374755\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.574501349360165\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.6881741885335925\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.13519528146110238\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.23283440746125775\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 10.7502 - acc: 0.3329 - val_loss: 10.7396 - val_acc: 0.3336\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 10.7501 - acc: 0.3330 - val_loss: 10.7422 - val_acc: 0.3334\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 10.7508 - acc: 0.3330 - val_loss: 10.7396 - val_acc: 0.3336\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 10.7504 - acc: 0.3330 - val_loss: 10.7396 - val_acc: 0.3336\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 10.7504 - acc: 0.3330 - val_loss: 10.7396 - val_acc: 0.3336\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 10.7501 - acc: 0.3330 - val_loss: 10.7422 - val_acc: 0.3334\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 10.7508 - acc: 0.3330 - val_loss: 10.7422 - val_acc: 0.3334\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 10.7498 - acc: 0.3331 - val_loss: 10.7382 - val_acc: 0.3337\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 10.7504 - acc: 0.3330 - val_loss: 10.7382 - val_acc: 0.3337\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 10.7504 - acc: 0.3330 - val_loss: 10.7396 - val_acc: 0.3336\n",
      "Test score: 10.739573832956449\n",
      "Test accuracy: 0.33357988165680474\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.47100000809439185\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.27609439041357026\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.1983065174980258\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.10491229892012294\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.6381767709036781\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 117s 38ms/step - loss: 1.0519 - acc: 0.4439 - val_loss: 0.9926 - val_acc: 0.4602\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 114s 38ms/step - loss: 0.9846 - acc: 0.4930 - val_loss: 0.9212 - val_acc: 0.5169\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 114s 38ms/step - loss: 0.9421 - acc: 0.5257 - val_loss: 0.9049 - val_acc: 0.5108\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 114s 38ms/step - loss: 0.9312 - acc: 0.5349 - val_loss: 0.8897 - val_acc: 0.5403\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 114s 37ms/step - loss: 0.9353 - acc: 0.5291 - val_loss: 0.8962 - val_acc: 0.5750\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 114s 38ms/step - loss: 0.9384 - acc: 0.5230 - val_loss: 0.8723 - val_acc: 0.5662\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 114s 38ms/step - loss: 0.9414 - acc: 0.5199 - val_loss: 0.8963 - val_acc: 0.5786\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 114s 37ms/step - loss: 0.9448 - acc: 0.5208 - val_loss: 0.9381 - val_acc: 0.4908\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 114s 37ms/step - loss: 0.9506 - acc: 0.5099 - val_loss: 0.8764 - val_acc: 0.5876\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 114s 37ms/step - loss: 0.9567 - acc: 0.5060 - val_loss: 0.9291 - val_acc: 0.5346\n",
      "Test score: 0.929176218650843\n",
      "Test accuracy: 0.5344572368421052\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.14159238265557203\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.6135572308481826\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.5760079672729373\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.696122414469801\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 128\n",
      "Dropout-Rate Faltungsschicht 5: 0.10918026514337834\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.6415234621121069\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 98s 65ms/step - loss: 1.1134 - acc: 0.3988 - val_loss: 1.0344 - val_acc: 0.4458\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 1.0395 - acc: 0.4471 - val_loss: 1.0270 - val_acc: 0.4223\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 1.0292 - acc: 0.4579 - val_loss: 0.9838 - val_acc: 0.4764\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 1.0210 - acc: 0.4665 - val_loss: 1.0263 - val_acc: 0.4530\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 1.0073 - acc: 0.4771 - val_loss: 1.0095 - val_acc: 0.4706\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.9864 - acc: 0.4981 - val_loss: 0.9718 - val_acc: 0.5476\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.9783 - acc: 0.5043 - val_loss: 0.9728 - val_acc: 0.5130\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.9731 - acc: 0.5097 - val_loss: 0.8627 - val_acc: 0.5858\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.9692 - acc: 0.5118 - val_loss: 0.8944 - val_acc: 0.5589\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 95s 62ms/step - loss: 0.9713 - acc: 0.5100 - val_loss: 0.8540 - val_acc: 0.5798\n",
      "Test score: 0.8541821313531776\n",
      "Test accuracy: 0.5799342105263158\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.42664357921515855\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.35339644344344656\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.4514951691589727\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.5503352154343591\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 128\n",
      "Dropout-Rate Faltungsschicht 5: 0.038754255841003525\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.015249081192082901\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 105s 69ms/step - loss: 1.1180 - acc: 0.4117 - val_loss: 1.0364 - val_acc: 0.4278\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 102s 67ms/step - loss: 1.0030 - acc: 0.4795 - val_loss: 0.9917 - val_acc: 0.4712\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 0.9516 - acc: 0.5236 - val_loss: 1.3049 - val_acc: 0.3628\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 0.9230 - acc: 0.5412 - val_loss: 0.8984 - val_acc: 0.5400\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 0.9073 - acc: 0.5518 - val_loss: 0.8548 - val_acc: 0.5809\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 0.8937 - acc: 0.5643 - val_loss: 0.9704 - val_acc: 0.4938\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 102s 67ms/step - loss: 0.8812 - acc: 0.5700 - val_loss: 0.8990 - val_acc: 0.5770\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 0.8747 - acc: 0.5759 - val_loss: 0.9366 - val_acc: 0.5380\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 0.8709 - acc: 0.5762 - val_loss: 0.9932 - val_acc: 0.5007\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 101s 67ms/step - loss: 0.8680 - acc: 0.5782 - val_loss: 0.8353 - val_acc: 0.6123\n",
      "Test score: 0.8353744627613771\n",
      "Test accuracy: 0.6124177631578948\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.2213089568208069\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.23756832394413926\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.49086307725000733\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.32436239488469354\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 136s 45ms/step - loss: 1.1017 - acc: 0.3342 - val_loss: 1.0989 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 1.0866 - acc: 0.3618 - val_loss: 1.0147 - val_acc: 0.4747\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 1.0090 - acc: 0.4798 - val_loss: 0.9582 - val_acc: 0.5174\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 0.9520 - acc: 0.5268 - val_loss: 0.9485 - val_acc: 0.5324\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 0.9266 - acc: 0.5427 - val_loss: 0.9728 - val_acc: 0.5186\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 0.9106 - acc: 0.5509 - val_loss: 1.0108 - val_acc: 0.5059\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 0.8987 - acc: 0.5610 - val_loss: 0.9845 - val_acc: 0.5097\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 0.8871 - acc: 0.5667 - val_loss: 0.9495 - val_acc: 0.5352\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 0.8808 - acc: 0.5721 - val_loss: 0.9674 - val_acc: 0.5190\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 133s 44ms/step - loss: 0.8732 - acc: 0.5770 - val_loss: 1.0028 - val_acc: 0.5027\n",
      "Test score: 1.0028241872003203\n",
      "Test accuracy: 0.5029605263157895\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.5333709865046569\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.018979800917943133\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.21477056697604296\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.412194001775003\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.42627434890842325\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 96s 63ms/step - loss: 1.0996 - acc: 0.3350 - val_loss: 1.0987 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 92s 60ms/step - loss: 1.0987 - acc: 0.3324 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 91s 60ms/step - loss: 1.0987 - acc: 0.3343 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 91s 60ms/step - loss: 1.0987 - acc: 0.3334 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 91s 60ms/step - loss: 1.0987 - acc: 0.3332 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 91s 60ms/step - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 92s 60ms/step - loss: 1.0987 - acc: 0.3328 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 91s 60ms/step - loss: 1.0987 - acc: 0.3326 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 91s 60ms/step - loss: 1.0987 - acc: 0.3325 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 91s 60ms/step - loss: 1.0987 - acc: 0.3325 - val_loss: 1.0987 - val_acc: 0.3325\n",
      "Test score: 1.0986950698651765\n",
      "Test accuracy: 0.3323190789473684\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.359044909299503\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.024657376746418068\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.5453216256406395\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.6560403219765505\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 161s 26ms/step - loss: 1.2559 - acc: 0.4127 - val_loss: 0.9715 - val_acc: 0.4942\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 1.0382 - acc: 0.4792 - val_loss: 1.0532 - val_acc: 0.4778\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0389 - acc: 0.4841 - val_loss: 0.9375 - val_acc: 0.5030\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0401 - acc: 0.4797 - val_loss: 0.9060 - val_acc: 0.5308\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0527 - acc: 0.4777 - val_loss: 1.0554 - val_acc: 0.4771\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0575 - acc: 0.4788 - val_loss: 0.9768 - val_acc: 0.4966\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 1.0620 - acc: 0.4715 - val_loss: 0.9467 - val_acc: 0.4738\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0688 - acc: 0.4700 - val_loss: 0.9503 - val_acc: 0.5670\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0776 - acc: 0.4652 - val_loss: 0.9733 - val_acc: 0.5221\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0868 - acc: 0.4648 - val_loss: 0.9295 - val_acc: 0.5016\n",
      "Test score: 0.9294394445920915\n",
      "Test accuracy: 0.5014792899408284\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.25538765350136594\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.6620047902547548\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.08908946831009872\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.5913692508775148\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 128\n",
      "Dropout-Rate Faltungsschicht 5: 0.4335169964924364\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.6689639674061256\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6084/6084 [==============================] - 145s 24ms/step - loss: 1.1177 - acc: 0.3915 - val_loss: 1.0376 - val_acc: 0.4553\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1067 - acc: 0.3991 - val_loss: 1.0639 - val_acc: 0.4436\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1257 - acc: 0.3702 - val_loss: 2.4993 - val_acc: 0.3919\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 140s 23ms/step - loss: 1.1281 - acc: 0.3411 - val_loss: 1.1033 - val_acc: 0.3704\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1173 - acc: 0.3331 - val_loss: 1.1090 - val_acc: 0.3322\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1137 - acc: 0.3336 - val_loss: 1.1247 - val_acc: 0.3308\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1144 - acc: 0.3309 - val_loss: 1.1009 - val_acc: 0.3323\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1136 - acc: 0.3303 - val_loss: 1.0997 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1139 - acc: 0.3325 - val_loss: 1.2360 - val_acc: 0.2906\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1134 - acc: 0.3326 - val_loss: 1.2763 - val_acc: 0.3666\n",
      "Test score: 1.276227374636445\n",
      "Test accuracy: 0.36653517422748194\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.10708794110871896\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.16857689755736183\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.5916376099174318\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.36718406309428453\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 128\n",
      "Dropout-Rate Faltungsschicht 5: 0.4829262941054116\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.02407284845771257\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 110s 36ms/step - loss: 1.0546 - acc: 0.4333 - val_loss: 1.0122 - val_acc: 0.4558\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9970 - acc: 0.4758 - val_loss: 0.8915 - val_acc: 0.5607\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.9121 - acc: 0.5472 - val_loss: 0.8934 - val_acc: 0.5488\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.8821 - acc: 0.5663 - val_loss: 0.8371 - val_acc: 0.5945\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.8712 - acc: 0.5720 - val_loss: 0.8333 - val_acc: 0.5995\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.8662 - acc: 0.5762 - val_loss: 0.8402 - val_acc: 0.5779\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.8620 - acc: 0.5779 - val_loss: 1.0499 - val_acc: 0.5611\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.8560 - acc: 0.5812 - val_loss: 0.8624 - val_acc: 0.5825\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.8581 - acc: 0.5789 - val_loss: 0.8670 - val_acc: 0.6075\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 0.8531 - acc: 0.5840 - val_loss: 0.8675 - val_acc: 0.5939\n",
      "Test score: 0.867403960071112\n",
      "Test accuracy: 0.5938322368421053\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.21698475914963355\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.17289511557392406\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.09436418717566777\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.20311099523053433\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.271046632669442\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.42707347385220085\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 122s 40ms/step - loss: 1.0504 - acc: 0.4441 - val_loss: 0.9306 - val_acc: 0.5327\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9274 - acc: 0.5397 - val_loss: 0.8552 - val_acc: 0.5885\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9043 - acc: 0.5558 - val_loss: 0.8988 - val_acc: 0.5255\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9021 - acc: 0.5576 - val_loss: 0.8434 - val_acc: 0.5959\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9034 - acc: 0.5603 - val_loss: 0.8856 - val_acc: 0.5222\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9069 - acc: 0.5543 - val_loss: 0.9279 - val_acc: 0.5457\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9089 - acc: 0.5531 - val_loss: 0.8454 - val_acc: 0.6076\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9166 - acc: 0.5502 - val_loss: 0.8778 - val_acc: 0.5871\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9221 - acc: 0.5475 - val_loss: 0.8903 - val_acc: 0.5716\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 118s 39ms/step - loss: 0.9310 - acc: 0.5409 - val_loss: 0.8718 - val_acc: 0.5565\n",
      "Test score: 0.8720221004203746\n",
      "Test accuracy: 0.5563322368421053\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.1258157021033706\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.13527286629130778\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.6382370746797458\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.050726060935707945\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.6740138303454847\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.187900543570194\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 143s 23ms/step - loss: 1.0991 - acc: 0.3327 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3337 - val_loss: 1.0989 - val_acc: 0.3323\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3313 - val_loss: 1.0988 - val_acc: 0.3325\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 139s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Test score: 1.0988241953727527\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.4951734864524238\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.578122650697853\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.3900306299971166\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.3955417566913732\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 102s 33ms/step - loss: 1.0599 - acc: 0.4339 - val_loss: 1.0732 - val_acc: 0.3743\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 98s 32ms/step - loss: 1.0267 - acc: 0.4659 - val_loss: 1.0825 - val_acc: 0.3810\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 98s 32ms/step - loss: 0.9989 - acc: 0.4898 - val_loss: 1.1141 - val_acc: 0.3624\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 98s 32ms/step - loss: 0.9901 - acc: 0.4956 - val_loss: 1.1093 - val_acc: 0.3666\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 97s 32ms/step - loss: 0.9875 - acc: 0.5022 - val_loss: 1.1372 - val_acc: 0.3451\n",
      "Epoch 6/10\n",
      "3042/3042 [==============================] - 98s 32ms/step - loss: 0.9865 - acc: 0.5029 - val_loss: 1.1672 - val_acc: 0.3369\n",
      "Epoch 7/10\n",
      "3042/3042 [==============================] - 98s 32ms/step - loss: 0.9909 - acc: 0.5002 - val_loss: 1.1061 - val_acc: 0.3627\n",
      "Epoch 8/10\n",
      "3042/3042 [==============================] - 97s 32ms/step - loss: 0.9937 - acc: 0.4985 - val_loss: 1.1506 - val_acc: 0.3338\n",
      "Epoch 9/10\n",
      "3042/3042 [==============================] - 97s 32ms/step - loss: 0.9866 - acc: 0.5017 - val_loss: 1.1169 - val_acc: 0.3626\n",
      "Epoch 10/10\n",
      "3042/3042 [==============================] - 98s 32ms/step - loss: 0.9869 - acc: 0.5021 - val_loss: 1.0783 - val_acc: 0.3832\n",
      "Test score: 1.078309458729468\n",
      "Test accuracy: 0.38330592105263156\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.13222469701785414\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.46155967454661834\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.36375913271863597\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.5908070034329119\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.1004 - acc: 0.3330 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3318 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Test score: 1.0988241953727527\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.6792231737343013\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.3093562096369121\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.4315036240930641\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.4751575788425747\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.06147997220119776\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.5038170608472976\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 156s 26ms/step - loss: 1.0960 - acc: 0.4082 - val_loss: 1.0286 - val_acc: 0.4346\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 1.0660 - acc: 0.4304 - val_loss: 1.0189 - val_acc: 0.4356\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 1.0692 - acc: 0.4284 - val_loss: 1.0743 - val_acc: 0.4688\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 151s 25ms/step - loss: 1.0711 - acc: 0.4312 - val_loss: 6.5568 - val_acc: 0.3390\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 152s 25ms/step - loss: 1.0784 - acc: 0.4268 - val_loss: 7.0282 - val_acc: 0.3897\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 224s 37ms/step - loss: 1.0879 - acc: 0.4236 - val_loss: 7.6749 - val_acc: 0.3881\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 160s 26ms/step - loss: 6.2796 - acc: 0.3695 - val_loss: 10.7640 - val_acc: 0.3322\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 151s 25ms/step - loss: 10.7371 - acc: 0.3339 - val_loss: 10.7600 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 153s 25ms/step - loss: 10.7367 - acc: 0.3339 - val_loss: 10.7613 - val_acc: 0.3323\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 154s 25ms/step - loss: 10.7377 - acc: 0.3338 - val_loss: 10.7600 - val_acc: 0.3324\n",
      "Test score: 10.762617119357117\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.30708821143141685\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.425181051865627\n",
      "Anzahl der Faltungsschichten: 5Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.14062459552915882\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.590648620829584\n",
      "Anzahl der Filter-Maps Faltungsschicht 5: 64\n",
      "Dropout-Rate Faltungsschicht 5: 0.33525070377372224\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.46580928432226254\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 150s 25ms/step - loss: 1.0994 - acc: 0.3339 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0989 - acc: 0.3327 - val_loss: 1.0988 - val_acc: 0.3325\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 144s 24ms/step - loss: 1.0988 - acc: 0.3366 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 145s 24ms/step - loss: 1.0988 - acc: 0.3322 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 145s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 143s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3322\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 145s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 143s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 143s 23ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 143s 24ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3324\n",
      "Test score: 1.0988241953727527\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.5248153728682362\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.013771620713159093\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.06296007551272016\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 64\n",
      "Dropout-Rate Faltungsschicht 4: 0.4130000695689919\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.5014865063866658\n",
      "Faltungsnetz wird trainiert...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 104s 69ms/step - loss: 1.0363 - acc: 0.4526 - val_loss: 0.9934 - val_acc: 0.4921\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 99s 65ms/step - loss: 0.9568 - acc: 0.5175 - val_loss: 0.9295 - val_acc: 0.5018\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 100s 66ms/step - loss: 0.9039 - acc: 0.5530 - val_loss: 0.8530 - val_acc: 0.5838\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 100s 66ms/step - loss: 0.8884 - acc: 0.5649 - val_loss: 0.8625 - val_acc: 0.5937\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 101s 66ms/step - loss: 0.8793 - acc: 0.5687 - val_loss: 0.8339 - val_acc: 0.6100\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 100s 66ms/step - loss: 0.8703 - acc: 0.5756 - val_loss: 0.9249 - val_acc: 0.5659\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 100s 66ms/step - loss: 0.8676 - acc: 0.5761 - val_loss: 0.8247 - val_acc: 0.6163\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 100s 66ms/step - loss: 0.8655 - acc: 0.5748 - val_loss: 0.9428 - val_acc: 0.5602\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 100s 66ms/step - loss: 0.8604 - acc: 0.5779 - val_loss: 0.8197 - val_acc: 0.6139\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 100s 66ms/step - loss: 0.8614 - acc: 0.5779 - val_loss: 0.9364 - val_acc: 0.5755\n",
      "Test score: 0.936642724746152\n",
      "Test accuracy: 0.5757401315789473\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.06307711151849073\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.20382445694216605\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.12248203532640545\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.6866387698783794\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 163s 27ms/step - loss: 1.0883 - acc: 0.4074 - val_loss: 1.0784 - val_acc: 0.4647\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 159s 26ms/step - loss: 1.0619 - acc: 0.4464 - val_loss: 1.0335 - val_acc: 0.4391\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 1.0698 - acc: 0.4417 - val_loss: 1.0663 - val_acc: 0.4113\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 1.0861 - acc: 0.4334 - val_loss: 1.0981 - val_acc: 0.4171\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 1.0820 - acc: 0.4377 - val_loss: 1.0952 - val_acc: 0.3439\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 1.0936 - acc: 0.4367 - val_loss: 1.0980 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0812 - acc: 0.4325 - val_loss: 1.1060 - val_acc: 0.3457\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0919 - acc: 0.4384 - val_loss: 1.1063 - val_acc: 0.3337\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 158s 26ms/step - loss: 1.0943 - acc: 0.4309 - val_loss: 1.1143 - val_acc: 0.3337\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 157s 26ms/step - loss: 1.0932 - acc: 0.4323 - val_loss: 1.1891 - val_acc: 0.3340\n",
      "Test score: 1.1891658110182823\n",
      "Test accuracy: 0.3339086127547666\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.36856104697946446\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.5417435612067958\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 128\n",
      "Dropout-Rate Faltungsschicht 3: 0.006998887818033605\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.378686634478515\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 168s 28ms/step - loss: 1.1034 - acc: 0.3327 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 164s 27ms/step - loss: 1.0989 - acc: 0.3320 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 164s 27ms/step - loss: 1.0988 - acc: 0.3319 - val_loss: 1.0988 - val_acc: 0.3325\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 163s 27ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 163s 27ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 163s 27ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 163s 27ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 164s 27ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 163s 27ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 163s 27ms/step - loss: 1.0988 - acc: 0.3321 - val_loss: 1.0988 - val_acc: 0.3323\n",
      "Test score: 1.0988241953727527\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 8\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.34597742155086353\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.6186099992277365\n",
      "Anzahl der Faltungsschichten: 4Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.13728851926848906\n",
      "Anzahl der Filter-Maps Faltungsschicht 4: 128\n",
      "Dropout-Rate Faltungsschicht 4: 0.13883546240860023\n",
      "Anzahl der Neuronen des Fully Connected Layer: 64\n",
      "Dropout-Rate Fully Connected Layer: 0.44849361739763\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 146s 24ms/step - loss: 1.0764 - acc: 0.4290 - val_loss: 1.0140 - val_acc: 0.4649\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 143s 23ms/step - loss: 1.0248 - acc: 0.4605 - val_loss: 0.9890 - val_acc: 0.4840\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 0.9979 - acc: 0.4818 - val_loss: 0.9164 - val_acc: 0.5212\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.0005 - acc: 0.4734 - val_loss: 0.9408 - val_acc: 0.5308\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 231s 38ms/step - loss: 1.0042 - acc: 0.4647 - val_loss: 1.8098 - val_acc: 0.4454\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 163s 27ms/step - loss: 1.0342 - acc: 0.4310 - val_loss: 1.1010 - val_acc: 0.3343\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 142s 23ms/step - loss: 1.1104 - acc: 0.3314 - val_loss: 1.1014 - val_acc: 0.3322\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1095 - acc: 0.3316 - val_loss: 1.1007 - val_acc: 0.3324\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 140s 23ms/step - loss: 1.1097 - acc: 0.3333 - val_loss: 1.1005 - val_acc: 0.3323\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 141s 23ms/step - loss: 1.1096 - acc: 0.3292 - val_loss: 1.1012 - val_acc: 0.3324\n",
      "Test score: 1.1012044905989207\n",
      "Test accuracy: 0.33226495726495725\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.39369408404795847\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.04882610210582032\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.06540654020186992\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.2192185143600429\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 92s 61ms/step - loss: 10.7455 - acc: 0.3329 - val_loss: 10.7419 - val_acc: 0.3336\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1521/1521 [==============================] - 87s 57ms/step - loss: 10.7486 - acc: 0.3331 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 10.7480 - acc: 0.3332 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 10.7473 - acc: 0.3332 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 10.7490 - acc: 0.3331 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 10.7477 - acc: 0.3332 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 87s 58ms/step - loss: 10.7473 - acc: 0.3332 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 88s 58ms/step - loss: 10.7486 - acc: 0.3331 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 87s 57ms/step - loss: 10.7493 - acc: 0.3331 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 88s 58ms/step - loss: 10.7490 - acc: 0.3331 - val_loss: 10.7441 - val_acc: 0.3334\n",
      "Test score: 10.74186221674869\n",
      "Test accuracy: 0.3335526315789474\n",
      "Stapelgroesse (batchSize): 32\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: relu\n",
      "Optimierungsfunktion: Adam\n",
      "Dropout-Rate Faltungsschicht 1: 0.4938729716239127\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 64\n",
      "Dropout-Rate Faltungsschicht 2: 0.3577944426633437\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.648938910990447\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.09833143896930721\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "1521/1521 [==============================] - 103s 68ms/step - loss: 1.0908 - acc: 0.3653 - val_loss: 1.0192 - val_acc: 0.4586\n",
      "Epoch 2/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 1.0201 - acc: 0.4638 - val_loss: 1.0127 - val_acc: 0.4680\n",
      "Epoch 3/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.9945 - acc: 0.4834 - val_loss: 1.0275 - val_acc: 0.4507\n",
      "Epoch 4/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.9801 - acc: 0.4911 - val_loss: 0.9819 - val_acc: 0.4976\n",
      "Epoch 5/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 0.9649 - acc: 0.5057 - val_loss: 0.9819 - val_acc: 0.4885\n",
      "Epoch 6/10\n",
      "1521/1521 [==============================] - 99s 65ms/step - loss: 0.9480 - acc: 0.5221 - val_loss: 0.9864 - val_acc: 0.4967\n",
      "Epoch 7/10\n",
      "1521/1521 [==============================] - 98s 65ms/step - loss: 0.9314 - acc: 0.5359 - val_loss: 1.0021 - val_acc: 0.4988\n",
      "Epoch 8/10\n",
      "1521/1521 [==============================] - 98s 65ms/step - loss: 0.9180 - acc: 0.5438 - val_loss: 0.9714 - val_acc: 0.5081\n",
      "Epoch 9/10\n",
      "1521/1521 [==============================] - 98s 64ms/step - loss: 0.9076 - acc: 0.5527 - val_loss: 1.0126 - val_acc: 0.4810\n",
      "Epoch 10/10\n",
      "1521/1521 [==============================] - 97s 64ms/step - loss: 0.8962 - acc: 0.5597 - val_loss: 0.9989 - val_acc: 0.4797\n",
      "Test score: 0.9990403600429234\n",
      "Test accuracy: 0.47952302631578947\n",
      "Stapelgroesse (batchSize): 16\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Aktivierungsfunktion: elu\n",
      "Optimierungsfunktion: RMSprop\n",
      "Dropout-Rate Faltungsschicht 1: 0.0030492067550873855\n",
      "Anzahl der Filter-Maps Faltungsschicht 2: 32\n",
      "Dropout-Rate Faltungsschicht 2: 0.36724989130755226\n",
      "Anzahl der Faltungsschichten: 3Layer\n",
      "Anzahl der Filter-Maps Faltungsschicht 3: 64\n",
      "Dropout-Rate Faltungsschicht 3: 0.09099759210319268\n",
      "Anzahl der Neuronen des Fully Connected Layer: 128\n",
      "Dropout-Rate Fully Connected Layer: 0.3253263629327289\n",
      "Faltungsnetz wird trainiert...\n",
      "Epoch 1/10\n",
      "3042/3042 [==============================] - 111s 36ms/step - loss: 10.7487 - acc: 0.3329 - val_loss: 10.7419 - val_acc: 0.3336\n",
      "Epoch 2/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 10.7498 - acc: 0.3331 - val_loss: 10.7432 - val_acc: 0.3335\n",
      "Epoch 3/10\n",
      "3042/3042 [==============================] - 105s 35ms/step - loss: 10.7498 - acc: 0.3331 - val_loss: 10.7432 - val_acc: 0.3335\n",
      "Epoch 4/10\n",
      "3042/3042 [==============================] - 106s 35ms/step - loss: 10.7498 - acc: 0.3331 - val_loss: 10.7432 - val_acc: 0.3335\n",
      "Epoch 5/10\n",
      "3042/3042 [==============================] - 107s 35ms/step - loss: 10.7403 - acc: 0.3336 - val_loss: 10.7339 - val_acc: 0.3340\n",
      "Epoch 6/10\n",
      "1611/3042 [==============>...............] - ETA: 42s - loss: 10.7435 - acc: 0.3334"
     ]
    }
   ],
   "source": [
    "# Die Hyperas Methode optim sucht im Suchraum die Parameter \n",
    "# Bei einer Änderung des Methodenrumpf der Methode model() muss der Notebook Kernel neu gestartet werden\n",
    "bestRun, bestModel = optim.minimize(model=model,               \n",
    "                                          data=data,\n",
    "                                          algo=rand.suggest,   # Algorithmus: Random Search\n",
    "                                          max_evals=100,          \n",
    "                                          trials=Trials(),      # eine Liste von Verzeichnissen, die alles über die Suche enthalten.\n",
    "                                          notebook_name='CNN_experiment5')  # Der Name des Notebooks sollte als String angegeben werden\n",
    "print(bestRun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anzahl der durchläufe bisher: 64\n",
    "Bestes Ergebnis bisherisher: 0.6269"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
