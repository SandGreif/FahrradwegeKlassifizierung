{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatisierte Vorverarbeitung\n",
    "\n",
    "Das Ziel dieses Jupyter Notebook ist es die Vorverarbeitung eines rohen Datensatz automatisiert durchzufühen. Damit die einzelnen Schritte in einer Pipline abgearbeitet werden können. Die folgenden Schritte werden ausgeführt.  \n",
    "\n",
    "1. Konkatenieren der rohen Merkmal CSV Dateien\n",
    "2. Bildaufnahmen zuschneiden und skalieren\n",
    "3. Überbelichtete und unterbelichtete Bilder aus dem Datensatz entfernen.\n",
    "4. Messwertreihen aus der Merkmal CSV kopieren\n",
    "5. Zusätzliche Merkmale aus den bestehenden berechnen \n",
    "6. Messwertreihen als eigenstädige CSV Dateien und veränderte Merkmal CSV mit den berechneten Merkmalen abspeichern als CSV Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "# Regex Vergleiche\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zu den Datensatz\n",
    "dataset = 52\n",
    "path = \"E:/bachelor/daten/\" + str(dataset) + \"/2018_6_22_18_38/\" \n",
    "outputDir = \"E:/bachelor/daten/\" + str(dataset) + \"/zugeschnitten/\"\n",
    "if not os.path.exists(outputDir):\n",
    "  os.makedirs(outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1\n",
    "# Lesen der Merkmal CSV Dateien\n",
    "files = os.listdir(path)\n",
    "featuresDf = []\n",
    "for file in files:\n",
    "    if re.match('[0-9]', file) is not None:\n",
    "        featuresDf.append(pandas.read_csv(filepath_or_buffer= path + file + \"/merkmaleRoh.csv\"))  \n",
    "# Jeder Panda Dataframe wird konkateniert\n",
    "length = len(featuresDf)\n",
    "if length >= 1:\n",
    "    result = featuresDf[0]\n",
    "    for df in featuresDf[1:]:\n",
    "        frames = [result, df]\n",
    "        result = pandas.concat(frames, ignore_index=True)\n",
    "result.set_index('Zeitstempel in Unixzeit', inplace=True)\n",
    "featuresDf = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9059, 18)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2\n",
    "# Die Funktion schneidet und skaliert einen Datensatz von Bildern\n",
    "# @param path != null / String Pfad zu den Bildern des Datensatz\n",
    "#  outputDir String Pfadname des Ausgabeordners\n",
    "# @return Liste mit den Pfaden zu allen zugeschnittenen Bildern\n",
    "def cropAndScaleImages(path, outputDir):\n",
    "    y = 85\n",
    "    x = 477\n",
    "    # Breite und Höhe des Ausschnits\n",
    "    h = 1475\n",
    "    w = 280\n",
    "    # Größe des neuen Bild\n",
    "    scaleFactor = 0.25\n",
    "    wNew = w * scaleFactor\n",
    "    hNew = h * scaleFactor\n",
    "    i = -1\n",
    "    filesImageNumber = []\n",
    "    dirs = os.listdir(path)\n",
    "    for dirNumber in dirs:\n",
    "        filesImageNumber.append(os.listdir(path + dirNumber))\n",
    "    for files in filesImageNumber:\n",
    "        i = i + 1  \n",
    "        outputDirName = outputDir + dirs[i] \n",
    "        print(outputDirName)\n",
    "        if not os.path.exists(outputDirName):\n",
    "            os.makedirs(outputDirName)\n",
    "        for name in files:\n",
    "            if \"jpg\" not in name:\n",
    "                continue\n",
    "            img = cv2.imread(path + dirs[i] + \"/\" + name)\n",
    "            img = img[y:y+h, x:x+w]\n",
    "            img = cv2.resize(img,(int(wNew),int(hNew))) # Bild wird skaliert\n",
    "            cv2.imwrite( outputDirName + \"/\" + name, img) \n",
    "    # Liste mit den Pfaden zu den Bilder zurückgeben\n",
    "    imagePaths = []\n",
    "    folders = os.listdir(outputDir)\n",
    "    folders = sorted(folders, key=int) #sortiert die Reihenfolge de Ordner aufsteifend\n",
    "    print(\"Bilder aus folgenden Ordnern werden geladen: \" + str(folders))\n",
    "    for folder in folders: # Aus der Liste der Ordner wird ein Ordner ausgewählt\n",
    "        filesPath = outputDir + folder + \"/\"\n",
    "        files = os.listdir(filesPath)\n",
    "        print(\"Ordner der geladen wird: \" + str(folder))\n",
    "        for name in files: # Ein Dateiname aus diesem Ordner\n",
    "            if \"jpg\" not in name:\n",
    "                continue\n",
    "            imagePaths.append(filesPath + name) # Pfad zu den Bild wird zur Liste mit Pfaden hinzugefügt      \n",
    "    return imagePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/bachelor/daten/52/zugeschnitten/1\n",
      "E:/bachelor/daten/52/zugeschnitten/2\n",
      "E:/bachelor/daten/52/zugeschnitten/3\n",
      "E:/bachelor/daten/52/zugeschnitten/4\n",
      "E:/bachelor/daten/52/zugeschnitten/5\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n"
     ]
    }
   ],
   "source": [
    "imagePaths = cropAndScaleImages(path, outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels [ 427  878 1464 3124 3289 4884 5536 5539 6492 7670 7769] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e8570f5deae1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# merkmaleRoh.csv Zeilen mit gefundenen Index löschen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mfeaturesDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m# Die Inecies müssen zurückgesetzt werden nach den Aufruf von drop. Ansonsten kommte es zu KeyValue Fehlern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mfeaturesDf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bachelor\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   2528\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2529\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2530\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bachelor\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2561\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2562\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2564\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\bachelor\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   3742\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'ignore'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[1;32m-> 3744\u001b[1;33m                                  labels[mask])\n\u001b[0m\u001b[0;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3746\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: labels [ 427  878 1464 3124 3289 4884 5536 5539 6492 7670 7769] not contained in axis"
     ]
    }
   ],
   "source": [
    "##### 3\n",
    "# Berechne Indexe für Bilder die unter oder überbelichtet sind\n",
    "indexe = []\n",
    "imagePathsToDelete = [] # String Pfade zu den Bildern welche gelöscht werden \n",
    "i = 0\n",
    "upperThreshold = 204 # obere Grauwert Schwelltwert für überbelichtete Bilder\n",
    "lowerThreshold = 50  # unterer Grauwert Schwellwert für unterbelichtete Bilder\n",
    "for path in imagePaths:\n",
    "    img = cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2GRAY)\n",
    "    img = img.astype('float32')\n",
    "    imgFlat = img.ravel()\n",
    "    mean = imgFlat.sum() / imgFlat.size\n",
    "    if mean > upperThreshold or mean < lowerThreshold:\n",
    "        indexe.append(i)\n",
    "        imagePathsToDelete.append(imagePaths[i])\n",
    "    i = i + 1\n",
    "# merkmaleRoh.csv Zeilen mit gefundenen Index löschen\n",
    "featuresDf.drop(indexe, inplace=True)\n",
    "# Die Inecies müssen zurückgesetzt werden nach den Aufruf von drop. Ansonsten kommte es zu KeyValue Fehlern\n",
    "featuresDf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in imagePathsToDelete:\n",
    "    print(img)\n",
    "    os.remove(img)\n",
    "imagePathsToDelete.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4\n",
    "accYList = featuresDf['Y-Achse Beschleunigungswerte in m/s^2'].str.split(\" \").tolist()\n",
    "accList = []\n",
    "accList.append(pandas.DataFrame(np.array(accYList[0]).astype(float)).transpose())\n",
    "for x in accYList[1:]:\n",
    "    accList.append(pandas.DataFrame(np.array(x).astype(float)).transpose())\n",
    "accYDf = pandas.concat(accList, ignore_index=True)\n",
    "# Konvertiere Beschleunigungssensordaten Z-Achse zu einem DataFrame\n",
    "measuredDataList = featuresDf['Z-Achse Beschleunigungswerte in m/s^2'].str.split(\" \").tolist()\n",
    "accList = []\n",
    "accList.append(pandas.DataFrame(np.array(measuredDataList[0]).astype(float)).transpose())\n",
    "for x in measuredDataList[1:]:\n",
    "    accList.append(pandas.DataFrame(np.array(x).astype(float)).transpose())\n",
    "accZDf = pandas.concat(accList, ignore_index=True)\n",
    "# Konvertiere Nick Messwerte zu DataFrame\n",
    "measuredDataList = featuresDf['Nick Messwerte in rad'].str.split(\" \").tolist()\n",
    "pitchList = []\n",
    "pitchList.append(pandas.DataFrame(np.array(measuredDataList[0]).astype(float)).transpose())\n",
    "for x in measuredDataList[1:]:\n",
    "    pitchList.append(pandas.DataFrame(np.array(x).astype(float)).transpose())\n",
    "nickDf = pandas.concat(pitchList, ignore_index=True)\n",
    "measuredDataList = featuresDf['Zeitstempel der Messwerte in ns'].str.split(\" \").tolist()\n",
    "timestampsList = []\n",
    "timestampsList.append(pandas.DataFrame(np.array(measuredDataList[0]).astype(float)).transpose())\n",
    "for x in measuredDataList[1:]:\n",
    "    timestampsList.append(pandas.DataFrame(np.array(x).astype(float)).transpose())\n",
    "sensorTimestampsDf = pandas.concat(timestampsList, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 5\n",
    "def calcVariance(meansDf, dfValues):\n",
    "    variance = []\n",
    "    for i, values in dfValues.iterrows():\n",
    "        sum = 0\n",
    "        for value in values:\n",
    "            if math.isnan(value) == False:\n",
    "                tempDifference = value-meansDf[i]\n",
    "                sum += tempDifference * tempDifference\n",
    "        variance.append(\"{0:.5f}\".format(round(sum / values.count(),5)))\n",
    "    return np.array(variance).astype(float)\n",
    "def calculateStandardDeviation(varianceDf):\n",
    "    deviation = []\n",
    "    for v in varianceDf:\n",
    "        temp = math.sqrt(np.abs(v))\n",
    "        deviation.append(\"{0:.5f}\".format(round(temp,5)))\n",
    "    return np.array(deviation).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neue Spalten werden erstellt und Mittelwerte zugewiesen\n",
    "featuresDf['Mittelwert Y-Achse Beschleunigung in m/s^2'] = accYDf.T.mean()\n",
    "featuresDf['Mittelwert Z-Achse Beschleunigung in m/s^2'] = accZDf.T.mean()\n",
    "featuresDf['Mittelwert Nick in rad'] = nickDf.T.mean()\n",
    "# Berechnung der Varianz und hinzufügen der Ergebnisse als neue Spalte in dem DataFrame \n",
    "featuresDf['Varianz Y-Achse Beschleunigung in m/s^2'] = calcVariance(featuresDf['Mittelwert Y-Achse Beschleunigung in m/s^2'],accYDf)\n",
    "featuresDf['Varianz Z-Achse Beschleunigung in m/s^2'] = calcVariance(featuresDf['Mittelwert Z-Achse Beschleunigung in m/s^2'],accZDf)\n",
    "featuresDf['Varianz Nick in rad'] = calcVariance(featuresDf['Mittelwert Nick in rad'],nickDf)\n",
    "# Berechne Standardabweichung\n",
    "featuresDf['Standardabweichung Y-Achse Beschleunigung in m/s^2'] = calculateStandardDeviation(featuresDf['Varianz Y-Achse Beschleunigung in m/s^2'])\n",
    "featuresDf['Standardabweichung Z-Achse Beschleunigung in m/s^2'] = calculateStandardDeviation(featuresDf['Varianz Z-Achse Beschleunigung in m/s^2'])\n",
    "featuresDf['Standardabweichung Nick in rad'] = calculateStandardDeviation(featuresDf['Varianz Nick in rad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 6\n",
    "# Änderungen in CSV Datei schreiben\n",
    "featuresDf.set_index('Zeitstempel in Unixzeit', inplace=True)\n",
    "featuresDf.to_csv('../daten/merkmale_datensatz_'+ dataset + '/merkmale.csv')\n",
    "# Speichert die DatenFrames mit den Messwerten in csv Dateien\n",
    "accYDf.index.names = [\"index\"]\n",
    "accYDf.to_csv('../daten/merkmale_datensatz_' + dataset + '/yAchseBeschleunigungswerte.csv')\n",
    "accZDf.index.names = [\"index\"]\n",
    "accZDf.to_csv('../daten/merkmale_datensatz_' + dataset + '/zAchseBeschleunigungswerte.csv')\n",
    "nickDf.index.names = [\"index\"]\n",
    "nickDf.to_csv('../daten/merkmale_datensatz_' + dataset + '/nickMesswerte.csv')\n",
    "sensorTimestampsDf.index.names = [\"index\"]\n",
    "sensorTimestampsDf.to_csv('../daten/merkmale_datensatz_' + dataset + '/sensoreventZeitstempel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "31px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
