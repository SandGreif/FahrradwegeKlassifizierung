{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatisierte Vorverarbeitung\n",
    "\n",
    "Das Ziel dieses Jupyter Notebook ist es die Vorverarbeitung eines rohen Datensatz automatisiert durchzufühen. Damit die einzelnen Schritte in einer Pipline abgearbeitet werden können. Die folgenden Schritte werden ausgeführt.  \n",
    "\n",
    "1. Konkatenieren der rohen Merkmal CSV Dateien\n",
    "2. Bildaufnahmen zuschneiden und skalieren\n",
    "3. Überbelichtete und unterbelichtete Bilder aus dem Datensatz entfernen.\n",
    "4. Messwertreihen aus der Merkmal CSV kopieren\n",
    "5. Zusätzliche Merkmale aus den bestehenden berechnen \n",
    "6. Messwertreihen als eigenstädige CSV Dateien und veränderte Merkmal CSV mit den berechneten Merkmalen abspeichern als CSV Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "# Regex Vergleiche\n",
    "import re\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zu den Datensatz\n",
    "dataset = 53\n",
    "path = \"E:/bachelor/daten/\" + str(dataset) + \"/2018_7_9_13_49/\" \n",
    "outputDir = \"E:/bachelor/daten/\" + str(dataset) + \"/zugeschnitten/\"\n",
    "if not os.path.exists(outputDir):\n",
    "  os.makedirs(outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1\n",
    "# Lesen der Merkmal CSV Dateien\n",
    "files = os.listdir(path)\n",
    "featuresDf = []\n",
    "for file in files:\n",
    "    if re.match('[0-9]', file) is not None:\n",
    "        featuresDf.append(pandas.read_csv(filepath_or_buffer= path + file + \"/merkmaleRoh.csv\"))  \n",
    "# Jeder Panda Dataframe wird konkateniert\n",
    "length = len(featuresDf)\n",
    "if length >= 1:\n",
    "    result = featuresDf[0]\n",
    "    for df in featuresDf[1:]:\n",
    "        frames = [result, df]\n",
    "        result = pandas.concat(frames, ignore_index=True)\n",
    "featuresDf = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2\n",
    "# Die Funktion schneidet und skaliert einen Datensatz von Bildern\n",
    "# @param path != null / String Pfad zu den Bildern des Datensatz\n",
    "#  outputDir String Pfadname des Ausgabeordners\n",
    "# @return Liste mit den Pfaden zu allen zugeschnittenen Bildern\n",
    "def cropAndScaleImages(path, outputDir):\n",
    "    #y = 85\n",
    "    #x = 477\n",
    "    ##### Für Datensatz 53 mit MTB\n",
    "    y = 40 \n",
    "    x = 400\n",
    "    # Breite und Höhe des Ausschnits\n",
    "    h = 1475\n",
    "    w = 280\n",
    "    # Größe des neuen Bild\n",
    "    scaleFactor = 0.25 # 0.26 ist Skalierung angepasst für Xception\n",
    "    wNew = w * scaleFactor\n",
    "    hNew = h * scaleFactor\n",
    "    i = -1\n",
    "    filesImageNumber = []\n",
    "    dirs = os.listdir(path)\n",
    "    for dirNumber in dirs:\n",
    "        filesImageNumber.append(os.listdir(path + dirNumber))\n",
    "    for files in filesImageNumber:\n",
    "        i = i + 1  \n",
    "        outputDirName = outputDir + dirs[i] \n",
    "        print(outputDirName)\n",
    "        if not os.path.exists(outputDirName):\n",
    "            os.makedirs(outputDirName)\n",
    "        for name in files:\n",
    "            if \"jpg\" not in name:\n",
    "                continue\n",
    "            img = cv2.imread(path + dirs[i] + \"/\" + name)\n",
    "            img = img[y:y+h, x:x+w]\n",
    "            img = cv2.resize(img,(int(wNew),int(hNew))) # Bild wird skaliert\n",
    "            cv2.imwrite( outputDirName + \"/\" + name, img) \n",
    "    # Liste mit den Pfaden zu den Bilder zurückgeben\n",
    "    imagePaths = []\n",
    "    folders = os.listdir(outputDir)\n",
    "    folders = sorted(folders, key=int) #sortiert die Reihenfolge de Ordner aufsteifend\n",
    "    print(\"Bilder aus folgenden Ordnern werden geladen: \" + str(folders))\n",
    "    for folder in folders: # Aus der Liste der Ordner wird ein Ordner ausgewählt\n",
    "        filesPath = outputDir + folder + \"/\"\n",
    "        files = os.listdir(filesPath)\n",
    "        print(\"Ordner der geladen wird: \" + str(folder))\n",
    "        for name in files: # Ein Dateiname aus diesem Ordner\n",
    "            if \"jpg\" not in name:\n",
    "                continue\n",
    "            imagePaths.append(filesPath + name) # Pfad zu den Bild wird zur Liste mit Pfaden hinzugefügt      \n",
    "    return imagePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/bachelor/daten/53/zugeschnitten/1\n",
      "E:/bachelor/daten/53/zugeschnitten/2\n",
      "E:/bachelor/daten/53/zugeschnitten/3\n",
      "E:/bachelor/daten/53/zugeschnitten/4\n",
      "E:/bachelor/daten/53/zugeschnitten/5\n",
      "Bilder aus folgenden Ordnern werden geladen: ['1', '2', '3', '4', '5']\n",
      "Ordner der geladen wird: 1\n",
      "Ordner der geladen wird: 2\n",
      "Ordner der geladen wird: 3\n",
      "Ordner der geladen wird: 4\n",
      "Ordner der geladen wird: 5\n"
     ]
    }
   ],
   "source": [
    "imagePaths = cropAndScaleImages(path, outputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 3\n",
    "# Berechne Indexe für Bilder die unter oder überbelichtet sind\n",
    "indexe = []\n",
    "imagePathsToDelete = [] # String Pfade zu den Bildern welche gelöscht werden \n",
    "i = 0\n",
    "upperThreshold = 204 # obere Grauwert Schwelltwert für überbelichtete Bilder\n",
    "lowerThreshold = 50  # unterer Grauwert Schwellwert für unterbelichtete Bilder\n",
    "for path in imagePaths:\n",
    "    img = cv2.cvtColor(cv2.imread(path),cv2.COLOR_BGR2GRAY)\n",
    "    img = img.astype('float32')\n",
    "    imgFlat = img.ravel()\n",
    "    mean = imgFlat.sum() / imgFlat.size\n",
    "    if mean > upperThreshold or mean < lowerThreshold:\n",
    "        indexe.append(i)\n",
    "        imagePathsToDelete.append(imagePaths[i])\n",
    "    i = i + 1\n",
    "# merkmaleRoh.csv Zeilen mit gefundenen Index löschen\n",
    "featuresDf.drop(indexe, inplace=True)\n",
    "# Die Inecies müssen zurückgesetzt werden nach den Aufruf von drop. Ansonsten kommte es zu KeyValue Fehlern\n",
    "featuresDf.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/bachelor/daten/53/zugeschnitten/3/1533817114855.jpg\n"
     ]
    }
   ],
   "source": [
    "for img in imagePathsToDelete:\n",
    "    print(img)\n",
    "    os.remove(img)\n",
    "imagePathsToDelete.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 4\n",
    "accYList = featuresDf['Y-Achse Beschleunigungswerte in m/s^2'].str.split(\" \").tolist()\n",
    "accList = []\n",
    "accList.append(pandas.DataFrame(np.array(accYList[0]).astype(float)).transpose())\n",
    "for x in accYList[1:]:\n",
    "    accList.append(pandas.DataFrame(np.array(x).astype(float)).transpose())\n",
    "accYDf = pandas.concat(accList, ignore_index=True)\n",
    "# Konvertiere Beschleunigungssensordaten Z-Achse zu einem DataFrame\n",
    "measuredDataList = featuresDf['Z-Achse Beschleunigungswerte in m/s^2'].str.split(\" \").tolist()\n",
    "accList = []\n",
    "accList.append(pandas.DataFrame(np.array(measuredDataList[0]).astype(float)).transpose())\n",
    "for x in measuredDataList[1:]:\n",
    "    accList.append(pandas.DataFrame(np.array(x).astype(float)).transpose())\n",
    "accZDf = pandas.concat(accList, ignore_index=True)\n",
    "# Konvertiere Nick Messwerte zu DataFrame\n",
    "measuredDataList = featuresDf['Nick Messwerte in rad'].str.split(\" \").tolist()\n",
    "pitchList = []\n",
    "pitchList.append(pandas.DataFrame(np.array(measuredDataList[0]).astype(float)).transpose())\n",
    "for x in measuredDataList[1:]:\n",
    "    pitchList.append(pandas.DataFrame(np.array(x).astype(float)).transpose())\n",
    "nickDf = pandas.concat(pitchList, ignore_index=True)\n",
    "measuredDataList = featuresDf['Zeitstempel der Messwerte in ns'].str.split(\" \").tolist()\n",
    "timestampsList = []\n",
    "timestampsList.append(pandas.DataFrame(np.array(measuredDataList[0]).astype(float)).transpose())\n",
    "for x in measuredDataList[1:]:\n",
    "    timestampsList.append(pandas.DataFrame(np.array(x).astype(float)).transpose())\n",
    "sensorTimestampsDf = pandas.concat(timestampsList, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 5\n",
    "def calcVariance(meansDf, dfValues):\n",
    "    variance = []\n",
    "    for i, values in dfValues.iterrows():\n",
    "        sum = 0\n",
    "        for value in values:\n",
    "            if math.isnan(value) == False:\n",
    "                tempDifference = value-meansDf[i]\n",
    "                sum += tempDifference * tempDifference\n",
    "        variance.append(\"{0:.5f}\".format(round(sum / values.count(),5)))\n",
    "    return np.array(variance).astype(float)\n",
    "def calculateStandardDeviation(varianceDf):\n",
    "    deviation = []\n",
    "    for v in varianceDf:\n",
    "        temp = math.sqrt(np.abs(v))\n",
    "        deviation.append(\"{0:.5f}\".format(round(temp,5)))\n",
    "    return np.array(deviation).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neue Spalten werden erstellt und Mittelwerte zugewiesen\n",
    "featuresDf['Mittelwert Y-Achse Beschleunigung in m/s^2'] = accYDf.T.mean()\n",
    "featuresDf['Mittelwert Z-Achse Beschleunigung in m/s^2'] = accZDf.T.mean()\n",
    "featuresDf['Mittelwert Nick in rad'] = nickDf.T.mean()\n",
    "# Berechnung der Varianz und hinzufügen der Ergebnisse als neue Spalte in dem DataFrame \n",
    "featuresDf['Varianz Y-Achse Beschleunigung in m/s^2'] = calcVariance(featuresDf['Mittelwert Y-Achse Beschleunigung in m/s^2'],accYDf)\n",
    "featuresDf['Varianz Z-Achse Beschleunigung in m/s^2'] = calcVariance(featuresDf['Mittelwert Z-Achse Beschleunigung in m/s^2'],accZDf)\n",
    "featuresDf['Varianz Nick in rad'] = calcVariance(featuresDf['Mittelwert Nick in rad'],nickDf)\n",
    "# Berechne Standardabweichung\n",
    "featuresDf['Standardabweichung Y-Achse Beschleunigung in m/s^2'] = calculateStandardDeviation(featuresDf['Varianz Y-Achse Beschleunigung in m/s^2'])\n",
    "featuresDf['Standardabweichung Z-Achse Beschleunigung in m/s^2'] = calculateStandardDeviation(featuresDf['Varianz Z-Achse Beschleunigung in m/s^2'])\n",
    "featuresDf['Standardabweichung Nick in rad'] = calculateStandardDeviation(featuresDf['Varianz Nick in rad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 6\n",
    "# Änderungen in CSV Datei schreiben\n",
    "outputFolder = '../daten/merkmale_datensatz_' + str(dataset) + '/optimiertXception'\n",
    "if not os.path.exists(outputFolder):\n",
    "  os.makedirs(outputFolder)\n",
    "featuresDf.set_index('Zeitstempel in Unixzeit', inplace=True)\n",
    "featuresDf.to_csv( outputFolder + '/merkmale.csv')\n",
    "# Speichert die DatenFrames mit den Messwerten in csv Dateien\n",
    "accYDf.index.names = [\"index\"]\n",
    "accYDf.to_csv(outputFolder + '/yAchseBeschleunigungswerte.csv')\n",
    "accZDf.index.names = [\"index\"]\n",
    "accZDf.to_csv(outputFolder + '/zAchseBeschleunigungswerte.csv')\n",
    "nickDf.index.names = [\"index\"]\n",
    "nickDf.to_csv(outputFolder + '/nickMesswerte.csv')\n",
    "sensorTimestampsDf.index.names = [\"index\"]\n",
    "sensorTimestampsDf.to_csv(outputFolder + '/sensoreventZeitstempel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "31px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
