{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test um Hyperas auszuprobieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T09:01:12.907932Z",
     "start_time": "2018-04-20T08:59:58.000966Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "from __future__ import print_function\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, rand\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import uniform, choice\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.preprocessing import sequence\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import imdb\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.embeddings import Embedding\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.recurrent import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import networkx as n\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: np.random.seed(1337)  # for reproducibility\n",
      "  3: max_features = 20000\n",
      "  4: maxlen = 100\n",
      "  5: \n",
      "  6: (X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
      "  7: X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
      "  8: X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
      "  9: \n",
      " 10: \n",
      " 11: \n",
      " 12: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     embedding_size = 300\n",
      "   4:     pool_length = 4\n",
      "   5:     lstm_output_size = 100\n",
      "   6:     batch_size = 200\n",
      "   7:     nb_epoch = 1\n",
      "   8: \n",
      "   9:     model = Sequential()\n",
      "  10:     model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
      "  11:     model.add(Dropout(space['Dropout']))\n",
      "  12:     # Note that we use unnamed parameters here, which is bad style, but is used here\n",
      "  13:     # to demonstrate that it works. Always prefer named parameters.\n",
      "  14:     model.add(Convolution1D(64,\n",
      "  15:                             6,\n",
      "  16:                             border_mode='valid',\n",
      "  17:                             activation='relu',\n",
      "  18:                             subsample_length=1))\n",
      "  19:     model.add(MaxPooling1D(pool_length=pool_length))\n",
      "  20:     model.add(LSTM(lstm_output_size))\n",
      "  21:     model.add(Dense(1))\n",
      "  22:     model.add(Activation('sigmoid'))\n",
      "  23: \n",
      "  24:     model.compile(loss='binary_crossentropy',\n",
      "  25:                   optimizer='adam',\n",
      "  26:                   metrics=['accuracy'])\n",
      "  27: \n",
      "  28:     print('Train...')\n",
      "  29:     model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
      "  30:               validation_data=(X_test, y_test))\n",
      "  31:     score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
      "  32: \n",
      "  33:     print('Test score:', score)\n",
      "  34:     print('Test accuracy:', acc)\n",
      "  35:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  36: \n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morro\\Documents\\fahrradwegeKlassifizierung\\temp_model.py:94: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 6, activation=\"relu\", strides=1, padding=\"valid\")`\n",
      "C:\\Users\\morro\\Documents\\fahrradwegeKlassifizierung\\temp_model.py:95: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(pool_size=4)`\n",
      "C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\bicycle\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 12s 485us/step - loss: 0.4759 - acc: 0.7581 - val_loss: 0.3574 - val_acc: 0.8416\n",
      "25000/25000 [==============================] - 2s 67us/step\n",
      "Test score: 0.3573707549571991\n",
      "Test accuracy: 0.8415999999046325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morro\\Documents\\fahrradwegeKlassifizierung\\temp_model.py:94: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(64, 8, activation=\"relu\", strides=1, padding=\"valid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 12s 493us/step - loss: 0.4541 - acc: 0.7676 - val_loss: 0.3525 - val_acc: 0.8443\n",
      "25000/25000 [==============================] - 2s 66us/step\n",
      "Test score: 0.35254471242427826\n",
      "Test accuracy: 0.8442800040245056\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 12s 484us/step - loss: 0.4657 - acc: 0.7632 - val_loss: 0.3522 - val_acc: 0.8440\n",
      "25000/25000 [==============================] - 2s 65us/step\n",
      "Test score: 0.35218134808540347\n",
      "Test accuracy: 0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\morro\\Documents\\fahrradwegeKlassifizierung\\temp_model.py:94: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(128, 8, activation=\"relu\", strides=1, padding=\"valid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 12s 500us/step - loss: 0.4304 - acc: 0.7849 - val_loss: 0.3639 - val_acc: 0.8418\n",
      "25000/25000 [==============================] - 2s 64us/step\n",
      "Test score: 0.3638690147399902\n",
      "Test accuracy: 0.8418000020980835\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/1\n",
      "25000/25000 [==============================] - 13s 504us/step - loss: 0.5420 - acc: 0.6998 - val_loss: 0.4143 - val_acc: 0.8293\n",
      "25000/25000 [==============================] - 2s 66us/step\n",
      "Test score: 0.4143452088832855\n",
      "Test accuracy: 0.8293199987411499\n",
      "{'Convolution1D': 0, 'Convolution1D_1': 1, 'Dropout': 0.3838088604298333}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from hyperopt import Trials, STATUS_OK, rand\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import uniform, choice\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n",
    "\n",
    "def data():\n",
    "    np.random.seed(1337)  # for reproducibility\n",
    "    max_features = 20000\n",
    "    maxlen = 100\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "    X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "    X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, maxlen, max_features\n",
    "\n",
    "\n",
    "def model(X_train, X_test, y_train, y_test, maxlen, max_features):\n",
    "    embedding_size = 300\n",
    "    pool_length = 4\n",
    "    lstm_output_size = 100\n",
    "    batch_size = 200\n",
    "    nb_epoch = 1\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    # Note that we use unnamed parameters here, which is bad style, but is used here\n",
    "    # to demonstrate that it works. Always prefer named parameters.\n",
    "    model.add(Convolution1D(64,\n",
    "                            6,\n",
    "                            border_mode='valid',\n",
    "                            activation='relu',\n",
    "                            subsample_length=1))\n",
    "    model.add(MaxPooling1D(pool_length=pool_length))\n",
    "    model.add(LSTM(lstm_output_size))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    print('Train...')\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, y_test))\n",
    "    score, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "    print('Test score:', score)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    best_run, best_model = optim.minimize(model=model,\n",
    "                                          data=data,\n",
    "                                          algo=rand.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                         notebook_name='test')\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-20T08:43:11.015374Z",
     "start_time": "2018-04-20T08:43:10.780005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as n \n",
    "n.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
